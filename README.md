# ⬆️ Microsoft Azure AZ-204 (Developing Solutions for Microsoft Azure) Practice Tests Exams Questions & Answers

![Promotional image](images/promotional.png)

## ❣️ Support

There are many ways to support us; in exchange, you'll get this material in a proper format:

- ❤️ [shop.ditectrev.com, in EPUB or PDF formats, with answers marked](https://shop.ditectrev.com/product/microsoft-azure-az-204-developing-solutions-for-azure-practice-tests-exams-questions-answers),
- ❤️ [shop.ditectrev.com, in EPUB or PDF formats, without answers marked](https://shop.ditectrev.com/product/microsoft-azure-az-204-developing-solutions-for-azure-practice-tests-exams-questions-no-answers),
- 📖 [Udemy is the only one to have explanations for questions](https://www.udemy.com/course/developing-solutions-for-azure-az-204-practice-test-exams/?referralCode=94E823A45873B0E39FE3),
- 📚 [Google Play Books, in PDF format, with answers marked](https://play.google.com/store/books/details?id=vvwcEQAAQBAJ),
- 📚 [Google Play Books, in PDF format, without answers marked](https://play.google.com/store/books/details?id=wPwcEQAAQBAJ),
- 🛍️ [Etsy, in PDF format, with answers marked](https://ditectrev.etsy.com/listing/1506993824),
- 🛍️ [Etsy, in PDF format, without answers marked](https://ditectrev.etsy.com/listing/1521177797),
- 🛒 [eBay, in PDF format, with answers marked](https://www.ebay.com/itm/404899852791?mkcid=16&mkevt=1&mkrid=711-127632-2357-0&ssspo=_ptbuk3gqdw&sssrc=2524149&ssuid=_ptbuk3gqdw&widget_ver=artemis&media=COPY),
- 🛒 [eBay, in PDF format, without answers marked](https://www.ebay.com/itm/405079754203?mkcid=16&mkevt=1&mkrid=711-127632-2357-0&ssspo=_ptbuk3gqdw&sssrc=2524149&ssuid=_ptbuk3gqdw&widget_ver=artemis&media=COPY),
- 🔄 [Patreon subscription allows you to get access to all of the materials in EPUB and PDF formats. You can also buy separate items on Patreon, but the subscription technically allows us to include all updates for EPUB and PDF formats. Hence, you get EPUB and PDF updates when you subscribe to Patreon](https://patreon.com/Ditectrev?utm_medium=unknown&utm_source=join_link&utm_campaign=creatorshare_creator&utm_content=copyLink).

💰 If you work for a company, you could probably easily claim this expense while preparing for your exam. For us, it's about being in the game or not.

⭐ Good ratings & reviews help us to survive. Please don't forget to leave a nice one when you purchase an item.

## 👩‍💻 & 👨‍💻 Interactive Course(s)

It's great to learn these questions as your exam preparation, and, yes, you should pass just based on that. However, we highly recommend more interactive learning if you want to become an expert. Currently, we're recommending those courses:

- 📖 [Educative: text-based, video-free course, including set up out-of-the-box for you Cloud Labs to practice hands-on without the need to set up an environment (and payments). The link includes the highest available discount Educative offers](https://www.educative.io/courses/event-driven-microservices-azure?aff=VALz).

Yes, we have a little commission from that link. Therefore, by using that link, you're supporting us.

## ✨ This course is unlike any Microsoft Azure AZ-204 (Developing Solutions for Azure) course you will find online.

✋ Join a live online community and a course taught by industry experts and pass the Microsoft Azure AZ-204 (Developing Solutions for Azure) confidently. We aim to build an ecosystem of Information Technology (IT) certifications and online courses in cooperation with the technology industry. We believe it will give our students 100% confidence in the pacing market in an open-source environment. We are just at the beginning of our way, so it's even better for you to join now!

[![Join our Discord](images/discord.png 'Join our Discord')](https://discord.gg/RFjtXKfJy3)

## ⌛️ Short and to the point; why should you take the course:

1. Always happy to answer your questions on Udemy's Q&A's and outside :)
2. Failed? Please submit a screenshot of your exam result and request a refund (via our upcoming platform, not possible on Udemy); we'll always accept it.
3. Learn about topics, such as:
   - Access Control;
   - Authentication & Authorization;
   - Azure API Management;
   - Azure App Service;
   - Azure Command Line Interface (Azure CLI);
   - Azure Cosmos DB;
   - Azure Event Hubs;
   - Azure Front Door;
   - Azure Functions;
   - Azure Log Analytics;
   - Azure Logic Apps;
   - Azure Monitor;
   - Azure Policies;
   - Azure Resources;
   - Azure Service Buses;
   - Azure Services;
   - Azure SQL Databases;
   - Azure Storage;
   - Azure Storage Queues;
   - Azure Web Application Firewall (Azure WAF);
   - Azure Web Apps;
   - Inbound Data Traffic & Outbound Data Traffic;
   - Microsoft Entra ID;
   - PowerShell;
   - Public & Private Cloud;
   - Resource Groups;
   - Serverless;
   - Service Level Agreement (SLA);
   - Software as a Service (SaaS);
   - Virtual Machines (VMs);
   - **Much More!**
4. Questions are similar to the actual exam, without duplications (like in other courses ;-)).
5. The Practice Tests Exams simulate the actual exam's content, timing, and percentage required to pass the exam.
6. This course is **not** a Microsoft Azure AZ-204 (Developing Solutions for Azure) Exam Dump. Some people use brain dumps or exam dumps, but that's absurd, which we don't practice.
7. 220 **unique** questions.

## ☝️ Course Updates

**[v1.0.0](../../releases/tag/v1.0.0): July 10, 2023.**

- Launch of the course.

**[v1.0.1](../../releases/tag/v1.0.1): August 7, 2023.**

- Fix 2 wrong answers.

**[v1.1.0](../../releases/tag/v1.1.0): November 10, 2023.**

- Fix all remaining typos with support of automated proofreading software and 4 wrong answers.

**[v1.1.1](../../releases/tag/v1.1.1): February 4, 2024.**

- Update 1 question with deprecated answer.

**[v1.1.1](../../releases/tag/v1.1.1): August 6, 2024.**

- AI-generated explanations (only paid [Udemy](https://www.udemy.com/course/developing-solutions-for-azure-az-204-practice-test-exams/?referralCode=94E823A45873B0E39FE3)).

**[v1.1.2](../../releases/tag/v1.1.2): November 11, 2024.**

- Fix 4 wrong answers.

**[v1.1.3](../../releases/tag/v1.1.3): March 1, 2025.**

- Fix 3 wrong answers.

## 🙋‍♀️ & 🙋‍♂️ Contribution

We are so thankful for every contribution, which makes sure we can deliver top-notch content. Whenever you find a missing resource, broken link in a [Table of Contents](../..#table-of-contents), the wrong answer, please submit an [issue](../../issues). Even better would be a [Pull Request (PR)](../../pulls).

## Who this course is for:

- 👨‍🎓 Students preparing for the Developing Solutions for Azure (AZ-204) Exam;
- 👨‍🎓 Amazon Web Services (AWS) Engineers;
- 👨‍🎓 Azure Engineers;
- 👨‍🎓 Cloud Engineers;
- 👨‍🎓 DevOps Engineers;
- 👨‍🎓 Google Cloud Platform (GCP) Engineers;
- 👨‍🎓 Infrastructure Engineers;
- 👨‍🎓 Lead Engineers;
- 👨‍🎓 Site Reliability Engineers;
- 👨‍🎓 Software Developers/Engineers;
- 👨‍🎓 Team Leaders.

## Requirements

- 🤩 Excitement to learn!
- 0️⃣ Prior knowledge is required;
- ✅ You can pass the Developing Solutions for Azure (AZ-204) Exam solely based on our Practice Tests Exams.

## Table of Contents

| No. | Questions |
| --- | --------------------------- |
| 1   | [You are implementing a software as a service (SaaS) ASP.NET Core web service that will run as an Azure Web App. The web service will use an on-premises SQL Server database for storage. The web service also includes a WebJob that processes data updates. Four customers will use the web service. Each instance of the WebJob processes data for a single customer and must run as a singleton instance. Each deployment must be tested by using deployment slots prior to serving production data. Azure costs must be minimized. Azure resources must be located in an isolated network. You need to configure the App Service plan for the Web App. How should you configure the App Service plan?](#you-are-implementing-a-software-as-a-service-saas-aspnet-core-web-service-that-will-run-as-an-azure-web-app-the-web-service-will-use-an-on-premises-sql-server-database-for-storage-the-web-service-also-includes-a-webjob-that-processes-data-updates-four-customers-will-use-the-web-service-each-instance-of-the-webjob-processes-data-for-a-single-customer-and-must-run-as-a-singleton-instance-each-deployment-must-be-tested-by-using-deployment-slots-prior-to-serving-production-data-azure-costs-must-be-minimized-azure-resources-must-be-located-in-an-isolated-network-you-need-to-configure-the-app-service-plan-for-the-web-app-how-should-you-configure-the-app-service-plan)
| 2   | [You are a developer for a software as a service (SaaS) company that uses an Azure Function to process orders. The Azure Function currently runs on an Azure Function app that is triggered by an Azure Storage queue. You are preparing to migrate the Azure Function to Kubernetes using Kubernetes-based Event Driven Autoscaling (KEDA). You need to configure Kubernetes Custom Resource Definitions (CRD) for the Azure Function. Which CRDs should you configure?](#you-are-a-developer-for-a-software-as-a-service-saas-company-that-uses-an-azure-function-to-process-orders-the-azure-function-currently-runs-on-an-azure-function-app-that-is-triggered-by-an-azure-storage-queue-you-are-preparing-to-migrate-the-azure-function-to-kubernetes-using-kubernetes-based-event-driven-autoscaling-keda-you-need-to-configure-kubernetes-custom-resource-definitions-crd-for-the-azure-function-which-crds-should-you-configure)
| 3   | [You are creating a CLI script that creates an Azure web app and related services in Azure App Service. The web app uses the following variables. You need to automatically deploy code from GitHub to the newly created web app. How should you complete the script?](#you-are-creating-a-cli-script-that-creates-an-azure-web-app-and-related-services-in-azure-app-service-the-web-app-uses-the-following-variables-you-need-to-automatically-deploy-code-from-github-to-the-newly-created-web-app-how-should-you-complete-the-script)
| 4   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Trigger the photo processing from Blob storage events. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-trigger-the-photo-processing-from-blob-storage-events-does-the-solution-meet-the-goal)
| 5   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the web.config file to include the applicationInitialization configuration element. Specify custom initialization actions to run the scripts. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-update-the-webconfig-file-to-include-the-applicationinitialization-configuration-element-specify-custom-initialization-actions-to-run-the-scripts-does-the-solution-meet-the-goal)
| 6   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Enable auto swap for the Testing slot. Deploy the app to the Testing slot. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-enable-auto-swap-for-the-testing-slot-deploy-the-app-to-the-testing-slot-does-the-solution-meet-the-goal)
| 7   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Disable auto swap. Update the app with a method named `statuscheck` to run the scripts. Re-enable auto swap and deploy the app to the Production slot. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-disable-auto-swap-update-the-app-with-a-method-named-statuscheck-to-run-the-scripts-re-enable-auto-swap-and-deploy-the-app-to-the-production-slot-does-the-solution-meet-the-goal)
| 8   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Convert the Azure Storage account to a BlockBlobStorage storage account. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-convert-the-azure-storage-account-to-a-blockblobstorage-storage-account-does-the-solution-meet-the-goal)
| 9   | [You are developing an Azure Web App. You configure TLS mutual authentication for the web app. You need to validate the client certificate in the web app.](#you-are-developing-an-azure-web-app-you-configure-tls-mutual-authentication-for-the-web-app-you-need-to-validate-the-client-certificate-in-the-web-app)
| 10   | [You are developing a Docker/Go using Azure App Service Web App for Containers. You plan to run the container in an App Service on Linux. You identify a Docker container image to use. None of your current resource groups reside in a location that supports Linux. You must minimize the number of resource groups required. You need to create the application and perform an initial deployment. Which three Azure CLI commands should you use to develop the solution?](#you-are-developing-a-dockergo-using-azure-app-service-web-app-for-containers-you-plan-to-run-the-container-in-an-app-service-on-linux-you-identify-a-docker-container-image-to-use-none-of-your-current-resource-groups-reside-in-a-location-that-supports-linux-you-must-minimize-the-number-of-resource-groups-required-you-need-to-create-the-application-and-perform-an-initial-deployment-which-three-azure-cli-commands-should-you-use-to-develop-the-solution)
| 11   | [Fourth Coffee has an ASP.NET Core web app that runs in Docker. The app is mapped to the `www.fourthcoffee.com` domain. Fourth Coffee is migrating this application to Azure. You need to provision an App Service Web App to host this docker image and map the custom domain to the App Service web app. A resource group named `FourthCoffeePublicWebResourceGroup` has been created in the WestUS region that contains an App Service Plan named `AppServiceLinuxDockerPlan`. Which order should the CLI commands be used to develop the solution?](#fourth-coffee-has-an-aspnet-core-web-app-that-runs-in-docker-the-app-is-mapped-to-the-wwwfourthcoffeecom-domain-fourth-coffee-is-migrating-this-application-to-azure-you-need-to-provision-an-app-service-web-app-to-host-this-docker-image-and-map-the-custom-domain-to-the-app-service-web-app-a-resource-group-named-fourthcoffeepublicwebresourcegroup-has-been-created-in-the-westus-region-that-contains-an-app-service-plan-named-appservicelinuxdockerplan-which-order-should-the-cli-commands-be-used-to-develop-the-solution)
| 12   | [You are developing a serverless Java application on Azure. You create a new Azure Key Vault to work with secrets from a new Azure Functions application. The application must meet the following requirements: Reference the Azure Key Vault without requiring any changes to the Java code. Dynamically add and remove instances of the Azure Functions host based on the number of incoming application events. Ensure that instances are perpetually warm to avoid any cold starts. Connect to a VNet. Authentication to the Azure Key Vault instance must be removed if the Azure Function application is deleted. You need to grant the Azure Functions application access to the Azure Key Vault. Which three actions should you perform in sequence?](#you-are-developing-a-serverless-java-application-on-azure-you-create-a-new-azure-key-vault-to-work-with-secrets-from-a-new-azure-functions-application-the-application-must-meet-the-following-requirements-reference-the-azure-key-vault-without-requiring-any-changes-to-the-java-code-dynamically-add-and-remove-instances-of-the-azure-functions-host-based-on-the-number-of-incoming-application-events-ensure-that-instances-are-perpetually-warm-to-avoid-any-cold-starts-connect-to-a-vnet-authentication-to-the-azure-key-vault-instance-must-be-removed-if-the-azure-function-application-is-deleted-you-need-to-grant-the-azure-functions-application-access-to-the-azure-key-vault-which-three-actions-should-you-perform-in-sequence)
| 13   | [You develop a website. You plan to host the website in Azure. You expect the website to experience high traffic volumes after it is published. You must ensure that the website remains available and responsive while minimizing cost. You need to deploy the website. What should you do?](#you-develop-a-website-you-plan-to-host-the-website-in-azure-you-expect-the-website-to-experience-high-traffic-volumes-after-it-is-published-you-must-ensure-that-the-website-remains-available-and-responsive-while-minimizing-cost-you-need-to-deploy-the-website-what-should-you-do)
| 14   | [A company is developing a Java web app. The web app code is hosted in a GitHub repository located at `https://github.com/Contoso/webapp`. The web app must be evaluated before it is moved to production. You must deploy the initial code release to a deployment slot named `staging`. You need to create the web app and deploy the code. How should you complete the commands?](#a-company-is-developing-a-java-web-app-the-web-app-code-is-hosted-in-a-github-repository-located-at-httpsgithubcomcontosowebapp-the-web-app-must-be-evaluated-before-it-is-moved-to-production-you-must-deploy-the-initial-code-release-to-a-deployment-slot-named-staging-you-need-to-create-the-web-app-and-deploy-the-code-how-should-you-complete-the-commands)
| 15   | [You have a web service that is used to pay for food deliveries. The web service uses Azure Cosmos DB as the data store. You plan to add a new feature that allows users to set a tip amount. The new feature requires that a property named tip on the document in Cosmos DB must be present and contain a numeric value. There are many existing websites and mobile apps that use the web service that will not be updated to set the tip property for some time. How should you complete the trigger?](#you-have-a-web-service-that-is-used-to-pay-for-food-deliveries-the-web-service-uses-azure-cosmos-db-as-the-data-store-you-plan-to-add-a-new-feature-that-allows-users-to-set-a-tip-amount-the-new-feature-requires-that-a-property-named-tip-on-the-document-in-cosmos-db-must-be-present-and-contain-a-numeric-value-there-are-many-existing-websites-and-mobile-apps-that-use-the-web-service-that-will-not-be-updated-to-set-the-tip-property-for-some-time-how-should-you-complete-the-trigger)
| 16   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Use the Durable Function async pattern to process the blob data. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-use-the-durable-function-async-pattern-to-process-the-blob-data-does-the-solution-meet-the-goal)
| 17   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Pass the HTTP trigger payload into an Azure Service Bus queue to be processed by a queue trigger function and return an immediate HTTP success response. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-pass-the-http-trigger-payload-into-an-azure-service-bus-queue-to-be-processed-by-a-queue-trigger-function-and-return-an-immediate-http-success-response-does-the-solution-meet-the-goal)
| 18   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Configure the app to use an App Service hosting plan and enable the Always On setting. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-configure-the-app-to-use-an-app-service-hosting-plan-and-enable-the-always-on-setting-does-the-solution-meet-the-goal)
| 19   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Move photo processing to an Azure Function triggered from the blob upload. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-move-photo-processing-to-an-azure-function-triggered-from-the-blob-upload-does-the-solution-meet-the-goal)
| 20   | [You are developing an application that uses Azure Blob storage. The application must read the transaction logs of all the changes that occur to the blobs and the blob metadata in the storage account for auditing purposes. The changes must be in the order in which they occurred, include only create, update, delete, and copy operations and be retained for compliance reasons. You need to process the transaction logs asynchronously. What should you do?](#you-are-developing-an-application-that-uses-azure-blob-storage-the-application-must-read-the-transaction-logs-of-all-the-changes-that-occur-to-the-blobs-and-the-blob-metadata-in-the-storage-account-for-auditing-purposes-the-changes-must-be-in-the-order-in-which-they-occurred-include-only-create-update-delete-and-copy-operations-and-be-retained-for-compliance-reasons-you-need-to-process-the-transaction-logs-asynchronously-what-should-you-do)
| 21   | [You plan to create a Docker image that runs an ASP.NET Core application named `ContosoApp`. You have a setup script named `setupScript.ps1` and a series of application files including `ContosoApp.dll`. You need to create a Dockerfile document that meets the following requirements: Call setupScripts.ps1 when the container is built. Run `ContosoApp.dll` when the container starts. The Dockerfile document must be created in the same folder where `ContosoApp.dll` and `setupScript.ps1` are stored. Which five commands should you use to develop the solution?](#you-plan-to-create-a-docker-image-that-runs-an-aspnet-core-application-named-contosoapp-you-have-a-setup-script-named-setupscriptps1-and-a-series-of-application-files-including-contosoappdll-you-need-to-create-a-dockerfile-document-that-meets-the-following-requirements-call-setupscriptsps1-when-the-container-is-built-run-contosoappdll-when-the-container-starts-the-dockerfile-document-must-be-created-in-the-same-folder-where-contosoappdll-and-setupscriptps1-are-stored-which-five-commands-should-you-use-to-develop-the-solution)
| 22   | [You are developing an Azure Function App that processes images that are uploaded to an Azure Blob container. Images must be processed as quickly as possible after they are uploaded, and the solution must minimize latency. You create code to process images when the Function App is triggered. You need to configure the Function App. What should you do?](#you-are-developing-an-azure-function-app-that-processes-images-that-are-uploaded-to-an-azure-blob-container-images-must-be-processed-as-quickly-as-possible-after-they-are-uploaded-and-the-solution-must-minimize-latency-you-create-code-to-process-images-when-the-function-app-is-triggered-you-need-to-configure-the-function-app-what-should-you-do)
| 23   | [You are configuring a new development environment for a Java application. The environment requires a Virtual Machine Scale Set (VMSS), several storage accounts, and networking components. The VMSS must not be created until the storage accounts have been successfully created and an associated load balancer and virtual network is configured. How should you complete the Azure Resource Manager template?](#you-are-configuring-a-new-development-environment-for-a-java-application-the-environment-requires-a-virtual-machine-scale-set-vmss-several-storage-accounts-and-networking-components-the-vmss-must-not-be-created-until-the-storage-accounts-have-been-successfully-created-and-an-associated-load-balancer-and-virtual-network-is-configured-how-should-you-complete-the-azure-resource-manager-template)
| 24   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 1: The code will log the time that the order was processed from the queue.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-1-the-code-will-log-the-time-that-the-order-was-processed-from-the-queue)
| 25   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 2: When the ProcessOrders function fails, the function will retry up to five times for a given order, including the first try.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-2-when-the-processorders-function-fails-the-function-will-retry-up-to-five-times-for-a-given-order-including-the-first-try)
| 26   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 3: When there are multiple orders in the queue, a batch of orders will be received from the queue and the ProcessOrders function will run multiple instances concurrently to process the orders.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-3-when-there-are-multiple-orders-in-the-queue-a-batch-of-orders-will-be-received-from-the-queue-and-the-processorders-function-will-run-multiple-instances-concurrently-to-process-the-orders)
| 27   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 4: The ProcessOrders function will output the order to an Orders table in Azure Table Storage.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-4-the-processorders-function-will-output-the-order-to-an-orders-table-in-azure-table-storage)
| 28   | [You are developing a solution for a hospital to support the following use cases: The most recent patient status details must be retrieved even if multiple users in different locations have updated the patient record. Patient health monitoring data retrieved must be the current version or the prior version. After a patient is discharged and all charges have been assessed, the patient billing record contains the final charges. You provision a Cosmos DB NoSQL database and set the default consistency level for the database account to Strong. You set the value for Indexing Mode to Consistent. You need to minimize latency and any impact to the availability of the solution. You must override the default consistency level at the query level to meet the required consistency guarantees for the scenarios. Which consistency levels should you implement?](#you-are-developing-a-solution-for-a-hospital-to-support-the-following-use-cases-the-most-recent-patient-status-details-must-be-retrieved-even-if-multiple-users-in-different-locations-have-updated-the-patient-record-patient-health-monitoring-data-retrieved-must-be-the-current-version-or-the-prior-version-after-a-patient-is-discharged-and-all-charges-have-been-assessed-the-patient-billing-record-contains-the-final-charges-you-provision-a-cosmos-db-nosql-database-and-set-the-default-consistency-level-for-the-database-account-to-strong-you-set-the-value-for-indexing-mode-to-consistent-you-need-to-minimize-latency-and-any-impact-to-the-availability-of-the-solution-you-must-override-the-default-consistency-level-at-the-query-level-to-meet-the-required-consistency-guarantees-for-the-scenarios-which-consistency-levels-should-you-implement)
| 29   | [You are configuring a development environment for your team. You deploy the latest Visual Studio image from the Azure Marketplace to your Azure subscription. The development environment requires several software development kits (SDKs) and third-party components to support application development across the organization. You install and customize the deployed virtual machine (VM) for your development team. The customized VM must be saved to allow provisioning of a new team member development environment. You need to save the customized VM for future provisioning. Which tools or services should you use?](#you-are-configuring-a-development-environment-for-your-team-you-deploy-the-latest-visual-studio-image-from-the-azure-marketplace-to-your-azure-subscription-the-development-environment-requires-several-software-development-kits-sdks-and-third-party-components-to-support-application-development-across-the-organization-you-install-and-customize-the-deployed-virtual-machine-vm-for-your-development-team-the-customized-vm-must-be-saved-to-allow-provisioning-of-a-new-team-member-development-environment-you-need-to-save-the-customized-vm-for-future-provisioning-which-tools-or-services-should-you-use)
| 30   | [You are preparing to deploy a website to an Azure Web App from a GitHub repository. The website includes static content generated by a script. You plan to use the Azure Web App continuous deployment feature. You need to run the static generation script before the website starts serving traffic. What are two possible ways to achieve this goal?](#you-are-preparing-to-deploy-a-website-to-an-azure-web-app-from-a-github-repository-the-website-includes-static-content-generated-by-a-script-you-plan-to-use-the-azure-web-app-continuous-deployment-feature-you-need-to-run-the-static-generation-script-before-the-website-starts-serving-traffic-what-are-two-possible-ways-to-achieve-this-goal)
| 31   | [You are developing an application to use Azure Blob storage. You have configured Azure Blob storage to include change feeds. A copy of your storage account must be created in another region. Data must be copied from the current storage account to the new storage account directly between the storage servers. You need to create a copy of the storage account in another region and copy the data. In which order should you perform the actions?](#you-are-developing-an-application-to-use-azure-blob-storage-you-have-configured-azure-blob-storage-to-include-change-feeds-a-copy-of-your-storage-account-must-be-created-in-another-region-data-must-be-copied-from-the-current-storage-account-to-the-new-storage-account-directly-between-the-storage-servers-you-need-to-create-a-copy-of-the-storage-account-in-another-region-and-copy-the-data-in-which-order-should-you-perform-the-actions)
| 32   | [You are preparing to deploy an Azure virtual machine (VM)-based application. The VMs that run the application have the following requirements: When a VM is provisioned the firewall must be automatically configured before it can access Azure resources. Supporting services must be installed by using an Azure PowerShell script that is stored in Azure Storage. You need to ensure that the requirements are met. Which features should you use?](#you-are-preparing-to-deploy-an-azure-virtual-machine-vm-based-application-the-vms-that-run-the-application-have-the-following-requirements-when-a-vm-is-provisioned-the-firewall-must-be-automatically-configured-before-it-can-access-azure-resources-supporting-services-must-be-installed-by-using-an-azure-powershell-script-that-is-stored-in-azure-storage-you-need-to-ensure-that-the-requirements-are-met-which-features-should-you-use)
| 33   | [A company is developing a Node.js web app. The web app code is hosted in a GitHub repository located at `https://github.com/TailSpinToys/webapp`. The web app must be reviewed before it is moved to production. You must deploy the initial code release to a deployment slot named `review`. You need to create the web app and deploy the code. How should you complete the commands?](#a-company-is-developing-a-nodejs-web-app-the-web-app-code-is-hosted-in-a-github-repository-located-at-httpsgithubcomtailspintoyswebapp-the-web-app-must-be-reviewed-before-it-is-moved-to-production-you-must-deploy-the-initial-code-release-to-a-deployment-slot-named-review-you-need-to-create-the-web-app-and-deploy-the-code-how-should-you-complete-the-commands)
| 34   | [You are developing an application that needs access to an Azure virtual machine (VM). The access lifecycle for the application must be associated with the VM service instance. You need to enable managed identity for the VM. How should you complete the PowerShell segment?](#you-are-developing-an-application-that-needs-access-to-an-azure-virtual-machine-vm-the-access-lifecycle-for-the-application-must-be-associated-with-the-vm-service-instance-you-need-to-enable-managed-identity-for-the-vm-how-should-you-complete-the-powershell-segment)
| 35   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Create an Azure Function app that uses the Consumption hosting model and that is triggered from the blob upload. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-create-an-azure-function-app-that-uses-the-consumption-hosting-model-and-that-is-triggered-from-the-blob-upload-does-the-solution-meet-the-goal)
| 36   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the app with a method named `statuscheck` to run the scripts. Update the app settings for the app. Set the `WEBSITE_SWAP_WARMUP_PING_PATH` and `WEBSITE_SWAP_WARMUP_PING_STATUSES` with a path to the new method and appropriate response codes. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-update-the-app-with-a-method-named-statuscheck-to-run-the-scripts-update-the-app-settings-for-the-app-set-the-website_swap_warmup_ping_path-and-website_swap_warmup_ping_statuses-with-a-path-to-the-new-method-and-appropriate-response-codes-does-the-solution-meet-the-goal)
| 37   | [You create the following PowerShell script. Question 1: A log alert is created that sends an email when the CPU percentage is above 60 percent for five minutes.](#you-create-the-following-powershell-script-question-1-a-log-alert-is-created-that-sends-an-email-when-the-cpu-percentage-is-above-60-percent-for-five-minutes)
| 38   | [You create the following PowerShell script. Question 2: A log alert is created that sends an email when the number of machine heartbeats in the past hour is less than five.](#you-create-the-following-powershell-script-question-2-a-log-alert-is-created-that-sends-an-email-when-the-number-of-machine-heartbeats-in-the-past-hour-is-less-than-five)
| 39   | [You create the following PowerShell script. Question 3: The log alert is scheduled to run every two hours.](#you-create-the-following-powershell-script-question-3-the-log-alert-is-scheduled-to-run-every-two-hours)
| 40   | [You are developing an Azure Function app. The app must meet the following requirements: Enable developers to write the functions by using the Rust language. Declaratively connect to an Azure Blob Storage account. You need to implement the app. Which Azure Function app features should you use?](#you-are-developing-an-azure-function-app-the-app-must-meet-the-following-requirements-enable-developers-to-write-the-functions-by-using-the-rust-language-declaratively-connect-to-an-azure-blob-storage-account-you-need-to-implement-the-app-which-azure-function-app-features-should-you-use)
| 41   | [You are developing an ASP.NET Core web application. You plan to deploy the application to Azure Web App for Containers. The application needs to store runtime diagnostic data that must be persisted across application restarts. You have the following code. You need to configure the application settings so that diagnostic data is stored as required. How should you configure the web app's settings?](#you-are-developing-an-aspnet-core-web-application-you-plan-to-deploy-the-application-to-azure-web-app-for-containers-the-application-needs-to-store-runtime-diagnostic-data-that-must-be-persisted-across-application-restarts-you-have-the-following-code-you-need-to-configure-the-application-settings-so-that-diagnostic-data-is-stored-as-required-how-should-you-configure-the-web-apps-settings)
| 42   | [You are developing a web app that is protected by Azure Web Application Firewall (WAF). All traffic to the web app is routed through an Azure Application Gateway instance that is used by multiple web apps. The web app address is `contoso.azurewebsites.net`. All traffic must be secured with SSL. The Azure Application Gateway instance is used by multiple web apps. You need to configure the Azure Application Gateway for the web app. Which two actions should you perform?](#you-are-developing-a-web-app-that-is-protected-by-azure-web-application-firewall-waf-all-traffic-to-the-web-app-is-routed-through-an-azure-application-gateway-instance-that-is-used-by-multiple-web-apps-the-web-app-address-is-contosoazurewebsitesnet-all-traffic-must-be-secured-with-ssl-the-azure-application-gateway-instance-is-used-by-multiple-web-apps-you-need-to-configure-the-azure-application-gateway-for-the-web-app-which-two-actions-should-you-perform)
| 43   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Use the Azure Blob Storage change feed to trigger photo processing. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-use-the-azure-blob-storage-change-feed-to-trigger-photo-processing-does-the-solution-meet-the-goal)
| 44   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 1: SaveScore will work with Cosmos DB.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-1-savescore-will-work-with-cosmos-db)
| 45   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 2: SaveScore will update and replace a record if one already exists with the same playerId and gameId.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-2-savescore-will-update-and-replace-a-record-if-one-already-exists-with-the-same-playerid-and-gameid)
| 46   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 3: Leader board data for the game will be automatically partitioned using gameId.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-3-leader-board-data-for-the-game-will-be-automatically-partitioned-using-gameid)
| 47   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 4: SaveScore will store the values for the gameId and playerId parameters in the database.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-4-savescore-will-store-the-values-for-the-gameid-and-playerid-parameters-in-the-database)
| 48   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 1: The code creates an infinite lease.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-1-the-code-creates-an-infinite-lease)
| 49   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 2: The code at line 06 always creates a new blob.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-2-the-code-at-line-06-always-creates-a-new-blob)
| 50   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 3: The finally block releases the lease.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-3-the-finally-block-releases-the-lease)
| 51   | [You are building a website that uses Azure Blob storage for data storage. You configure Azure Blob storage lifecycle to move all blobs to the archive tier after 30 days. Customers have requested a service-level agreement (SLA) for viewing data older than 30 days. You need to document the minimum SLA for data recovery. Which SLA should you use?](#you-are-building-a-website-that-uses-azure-blob-storage-for-data-storage-you-configure-azure-blob-storage-lifecycle-to-move-all-blobs-to-the-archive-tier-after-30-days-customers-have-requested-a-service-level-agreement-sla-for-viewing-data-older-than-30-days-you-need-to-document-the-minimum-sla-for-data-recovery-which-sla-should-you-use)
| 52   | [You are developing a ticket reservation system for an airline. The storage solution for the application must meet the following requirements: Ensure at least 99.99% availability and provide low latency. Accept reservations even when localized network outages or other unforeseen failures occur. Process reservations in the exact sequence as reservations are submitted to minimize overbooking or selling the same seat to multiple travelers. Allow simultaneous and out-of-order reservations with a maximum five-second tolerance window. You provision a resource group named `airlineResourceGroup` in the Azure South-Central US region. You need to provision a SQL API Cosmos DB account to support the app. How should you complete the Azure CLI commands?](#you-are-developing-a-ticket-reservation-system-for-an-airline-the-storage-solution-for-the-application-must-meet-the-following-requirements-ensure-at-least-9999-availability-and-provide-low-latency-accept-reservations-even-when-localized-network-outages-or-other-unforeseen-failures-occur-process-reservations-in-the-exact-sequence-as-reservations-are-submitted-to-minimize-overbooking-or-selling-the-same-seat-to-multiple-travelers-allow-simultaneous-and-out-of-order-reservations-with-a-maximum-five-second-tolerance-window-you-provision-a-resource-group-named-airlineresourcegroup-in-the-azure-south-central-us-region-you-need-to-provision-a-sql-api-cosmos-db-account-to-support-the-app-how-should-you-complete-the-azure-cli-commands)
| 53   | [You are preparing to deploy a Python website to an Azure Web App using a container. The solution will use multiple containers in the same container group. The Dockerfile that builds the container is as follows. You build a container by using the following command. The Azure Container Registry instance named `images` is a private registry. The user name and password for the registry is admin. The Web App must always run the same version of the website regardless of future builds. You need to create an Azure Web App to run the website. How should you complete the commands?](#you-are-preparing-to-deploy-a-python-website-to-an-azure-web-app-using-a-container-the-solution-will-use-multiple-containers-in-the-same-container-group-the-dockerfile-that-builds-the-container-is-as-follows-you-build-a-container-by-using-the-following-command-the-azure-container-registry-instance-named-images-is-a-private-registry-the-user-name-and-password-for-the-registry-is-admin-the-web-app-must-always-run-the-same-version-of-the-website-regardless-of-future-builds-you-need-to-create-an-azure-web-app-to-run-the-website-how-should-you-complete-the-commands)
| 54   | [You are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue. A rule already exists to scale up the App Service when the average queue length of unprocessed and valid queue messages is greater than 1000. You need to add a new rule that will continuously scale down the App Service as long as the scale up condition is not met. How should you configure the Scale rule?](#you-are-developing-a-back-end-azure-app-service-that-scales-based-on-the-number-of-messages-contained-in-a-service-bus-queue-a-rule-already-exists-to-scale-up-the-app-service-when-the-average-queue-length-of-unprocessed-and-valid-queue-messages-is-greater-than-1000-you-need-to-add-a-new-rule-that-will-continuously-scale-down-the-app-service-as-long-as-the-scale-up-condition-is-not-met-how-should-you-configure-the-scale-rule)
| 55   | [You have an application that uses Azure Blob storage. You need to update the metadata of the blobs. Which three methods should you use to develop the solution?](#you-have-an-application-that-uses-azure-blob-storage-you-need-to-update-the-metadata-of-the-blobs-which-three-methods-should-you-use-to-develop-the-solution)
| 56   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-grid-configure-the-machine-identifier-as-the-partition-key-and-enable-capture-does-the-solution-meet-the-goal)
| 57   | [You develop Azure solutions. A .NET application needs to receive a message each time an Azure virtual machine finishes processing data. The messages must NOT persist after being processed by the receiving application. You need to implement the .NET object that will receive the messages. Which object should you use?](#you-develop-azure-solutions-a-net-application-needs-to-receive-a-message-each-time-an-azure-virtual-machine-finishes-processing-data-the-messages-must-not-persist-after-being-processed-by-the-receiving-application-you-need-to-implement-the-net-object-that-will-receive-the-messages-which-object-should-you-use)
| 58   | [You are maintaining an existing application that uses an Azure Blob GPv1 Premium storage account. Data older than three months is rarely used. Data newer than three months must be available immediately. Data older than a year must be saved but does not need to be available immediately. You need to configure the account to support a lifecycle management rule that moves blob data to archive storage for data not modified in the last year. Which three actions should you perform in sequence?](#you-are-maintaining-an-existing-application-that-uses-an-azure-blob-gpv1-premium-storage-account-data-older-than-three-months-is-rarely-used-data-newer-than-three-months-must-be-available-immediately-data-older-than-a-year-must-be-saved-but-does-not-need-to-be-available-immediately-you-need-to-configure-the-account-to-support-a-lifecycle-management-rule-that-moves-blob-data-to-archive-storage-for-data-not-modified-in-the-last-year-which-three-actions-should-you-perform-in-sequence)
| 59   | [You develop Azure solutions. You must connect to a No-SQL globally-distributed database by using the .NET API. You need to create an object to configure and execute requests in the database. Which code segment should you use?](#you-develop-azure-solutions-you-must-connect-to-a-no-sql-globally-distributed-database-by-using-the-net-api-you-need-to-create-an-object-to-configure-and-execute-requests-in-the-database-which-code-segment-should-you-use)
| 60   | [You have an existing Azure storage account that stores large volumes of data across multiple containers. You need to copy all data from the existing storage account to a new storage account. The copy process must meet the following requirements: Automate data movement. Minimize user input required to perform the operation. Ensure that the data movement process is recoverable. What should you use?](#you-have-an-existing-azure-storage-account-that-stores-large-volumes-of-data-across-multiple-containers-you-need-to-copy-all-data-from-the-existing-storage-account-to-a-new-storage-account-the-copy-process-must-meet-the-following-requirements-automate-data-movement-minimize-user-input-required-to-perform-the-operation-ensure-that-the-data-movement-process-is-recoverable-what-should-you-use)
| 61   | [You are developing a web service that will run on Azure virtual machines that use Azure Storage. You configure all virtual machines to use managed identities. You have the following requirements: Secret-based authentication mechanisms are not permitted for accessing an Azure Storage account. Must use only Azure Instance Metadata Service endpoints. You need to write code to retrieve an access token to access Azure Storage.](#you-are-developing-a-web-service-that-will-run-on-azure-virtual-machines-that-use-azure-storage-you-configure-all-virtual-machines-to-use-managed-identities-you-have-the-following-requirements-secret-based-authentication-mechanisms-are-not-permitted-for-accessing-an-azure-storage-account-must-use-only-azure-instance-metadata-service-endpoints-you-need-to-write-code-to-retrieve-an-access-token-to-access-azure-storage)
| 62   | [You are developing a new page for a website that uses Azure Cosmos DB for data storage. The feature uses documents that have the following format. You must display data for the new page in a specific order. You create the following query for the page. You need to configure a Cosmos DB policy to support the query. How should you configure the policy?](#you-are-developing-a-new-page-for-a-website-that-uses-azure-cosmos-db-for-data-storage-the-feature-uses-documents-that-have-the-following-format-you-must-display-data-for-the-new-page-in-a-specific-order-you-create-the-following-query-for-the-page-you-need-to-configure-a-cosmos-db-policy-to-support-the-query-how-should-you-configure-the-policy)
| 63   | [You are building a traffic monitoring system that monitors traffic along six highways. The system produces time series analysis-based reports for each highway. Data from traffic sensors are stored in Azure Event Hub. Traffic data is consumed by four departments. Each department has an Azure Web App that displays the time series-based reports and contains a WebJob that processes the incoming data from Event Hub. All Web Apps run on App Service Plans with three instances. Data throughput must be maximized. Latency must be minimized. You need to implement the Azure Event Hub. Which settings should you use?](#you-are-building-a-traffic-monitoring-system-that-monitors-traffic-along-six-highways-the-system-produces-time-series-analysis-based-reports-for-each-highway-data-from-traffic-sensors-are-stored-in-azure-event-hub-traffic-data-is-consumed-by-four-departments-each-department-has-an-azure-web-app-that-displays-the-time-series-based-reports-and-contains-a-webjob-that-processes-the-incoming-data-from-event-hub-all-web-apps-run-on-app-service-plans-with-three-instances-data-throughput-must-be-maximized-latency-must-be-minimized-you-need-to-implement-the-azure-event-hub-which-settings-should-you-use)
| 64   | [You are developing a microservices solution. You plan to deploy the solution to a multinode Azure Kubernetes Service (AKS) cluster. You need to deploy a solution that includes the following features: reverse proxy capabilities configurable traffic routing TLS termination with a custom certificate. Which components should you use?](#you-are-developing-a-microservices-solution-you-plan-to-deploy-the-solution-to-a-multinode-azure-kubernetes-service-aks-cluster-you-need-to-deploy-a-solution-that-includes-the-following-features-reverse-proxy-capabilities-configurable-traffic-routing-tls-termination-with-a-custom-certificate-which-components-should-you-use)
| 65   | [You are implementing an order processing system. A point of sale application publishes orders to topics in an Azure Service Bus queue. The Label property for the topic includes the following data. The system has the following requirements for subscriptions. You need to implement filtering and maximize throughput while evaluating filters. Which filter types should you implement?](#you-are-implementing-an-order-processing-system-a-point-of-sale-application-publishes-orders-to-topics-in-an-azure-service-bus-queue-the-label-property-for-the-topic-includes-the-following-data-the-system-has-the-following-requirements-for-subscriptions-you-need-to-implement-filtering-and-maximize-throughput-while-evaluating-filters-which-filter-types-should-you-implement)
| 66   | [Your company has several websites that use a company logo image. You use Azure Content Delivery Network (CDN) to store the static image. You need to determine the correct process of how the CDN and the Point of Presence (POP) server will distribute the image and list the items in the correct order. In which order do the actions occur?](#your-company-has-several-websites-that-use-a-company-logo-image-you-use-azure-content-delivery-network-cdn-to-store-the-static-image-you-need-to-determine-the-correct-process-of-how-the-cdn-and-the-point-of-presence-pop-server-will-distribute-the-image-and-list-the-items-in-the-correct-order-in-which-order-do-the-actions-occur)
| 67   | [You are developing an Azure Cosmos DB solution by using the Azure Cosmos DB SQL API. The data includes millions of documents. Each document may contain hundreds of properties. The properties of the documents do not contain distinct values for partitioning. Azure Cosmos DB must scale individual containers in the database to meet the performance needs of the application by spreading the workload evenly across all partitions over time. You need to select a partition key. Which two partition keys can you use?](#you-are-developing-an-azure-cosmos-db-solution-by-using-the-azure-cosmos-db-sql-api-the-data-includes-millions-of-documents-each-document-may-contain-hundreds-of-properties-the-properties-of-the-documents-do-not-contain-distinct-values-for-partitioning-azure-cosmos-db-must-scale-individual-containers-in-the-database-to-meet-the-performance-needs-of-the-application-by-spreading-the-workload-evenly-across-all-partitions-over-time-you-need-to-select-a-partition-key-which-two-partition-keys-can-you-use)
| 68   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 1: A database named `SalesOrders` is created. The database will include two containers.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-1-a-database-named-salesorders-is-created-the-database-will-include-two-containers)
| 69   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 2: Container1 will contain two items.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-2-container1-will-contain-two-items)
| 70   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 3: Container2 will contain one item.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-3-container2-will-contain-one-item)
| 71   | [You develop an Azure solution that uses Cosmos DB. The current Cosmos DB container must be replicated and must use a partition key that is optimized for queries. You need to implement a change feed processor solution. Which change feed processor components should you use?](#you-develop-an-azure-solution-that-uses-cosmos-db-the-current-cosmos-db-container-must-be-replicated-and-must-use-a-partition-key-that-is-optimized-for-queries-you-need-to-implement-a-change-feed-processor-solution-which-change-feed-processor-components-should-you-use)
| 72   | [You develop a web application. You need to register the application with an active Microsoft Entra ID tenant. Which three actions should you perform in sequence?](#you-develop-a-web-application-you-need-to-register-the-application-with-an-active-microsoft-entra-id-tenant-which-three-actions-should-you-perform-in-sequence)
| 73   | [You have a new Azure subscription. You are developing an internal website for employees to view sensitive data. The website uses Microsoft Entra ID for authentication. You need to implement multifactor authentication for the website. Which two actions should you perform?](#you-have-a-new-azure-subscription-you-are-developing-an-internal-website-for-employees-to-view-sensitive-data-the-website-uses-microsoft-entra-id-for-authentication-you-need-to-implement-multifactor-authentication-for-the-website-which-two-actions-should-you-perform)
| 74   | [You are developing a Java application that uses Cassandra to store key and value data. You plan to use a new Azure Cosmos DB resource and the Cassandra API in the application. You create an Microsoft Entra ID group named Cosmos DB Creators to enable provisioning of Azure Cosmos accounts, databases, and containers. The Microsoft Entra ID group must not be able to access the keys that are required to access the data. You need to restrict access to the Microsoft Entra ID group. Which role-based access control should you use?](#you-are-developing-a-java-application-that-uses-cassandra-to-store-key-and-value-data-you-plan-to-use-a-new-azure-cosmos-db-resource-and-the-cassandra-api-in-the-application-you-create-an-microsoft-entra-id-group-named-cosmos-db-creators-to-enable-provisioning-of-azure-cosmos-accounts-databases-and-containers-the-microsoft-entra-id-group-must-not-be-able-to-access-the-keys-that-are-required-to-access-the-data-you-need-to-restrict-access-to-the-microsoft-entra-id-group-which-role-based-access-control-should-you-use)
| 75   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure the Azure Web App for the website to allow only authenticated requests and require Microsoft Entra ID log on. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-configure-the-azure-web-app-for-the-website-to-allow-only-authenticated-requests-and-require-microsoft-entra-id-log-on-does-the-solution-meet-the-goal)
| 76   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, set value of the `groupMembershipClaims` option to All. In the website, use the value of the groups claim from the JWT for the user to determine permissions. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-create-a-new-microsoft-entra-id-application-in-the-applications-manifest-set-value-of-the-groupmembershipclaims-option-to-all-in-the-website-use-the-value-of-the-groups-claim-from-the-jwt-for-the-user-to-determine-permissions-does-the-solution-meet-the-goal)
| 77   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, define application roles that match the required permission levels for the application. Assign the appropriate Microsoft Entra ID group to each role. In the website, use the value of the roles claim from the JWT for the user to determine permissions. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-create-a-new-microsoft-entra-id-application-in-the-applications-manifest-define-application-roles-that-match-the-required-permission-levels-for-the-application-assign-the-appropriate-microsoft-entra-id-group-to-each-role-in-the-website-use-the-value-of-the-roles-claim-from-the-jwt-for-the-user-to-determine-permissions-does-the-solution-meet-the-goal)
| 78   | [You are developing an application to securely transfer data between on-premises file systems and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault. The application uses the Azure Key Vault APIs. The application must allow recovery of an accidental deletion of the key vault or key vault objects. Key vault objects must be retained for 90 days after deletion. You need to protect the key vault and key vault objects. Which Azure Key Vault feature should you use?](#you-are-developing-an-application-to-securely-transfer-data-between-on-premises-file-systems-and-azure-blob-storage-the-application-stores-keys-secrets-and-certificates-in-azure-key-vault-the-application-uses-the-azure-key-vault-apis-the-application-must-allow-recovery-of-an-accidental-deletion-of-the-key-vault-or-key-vault-objects-key-vault-objects-must-be-retained-for-90-days-after-deletion-you-need-to-protect-the-key-vault-and-key-vault-objects-which-azure-key-vault-feature-should-you-use)
| 79   | [You provide an Azure API Management managed web service to clients. The back-end web service implements HTTP Strict Transport Security (HSTS). Every request to the backend service must include a valid HTTP authorization header. You need to configure the Azure API Management instance with an authentication policy. Which two policies can you use?](#you-provide-an-azure-api-management-managed-web-service-to-clients-the-back-end-web-service-implements-http-strict-transport-security-hsts-every-request-to-the-backend-service-must-include-a-valid-http-authorization-header-you-need-to-configure-the-azure-api-management-instance-with-an-authentication-policy-which-two-policies-can-you-use)
| 80   | [You are developing an ASP.NET Core website that can be used to manage photographs which are stored in Azure Blob Storage containers. Users of the website authenticate by using their Microsoft Entra ID credentials. You implement role-based access control (RBAC) role permissions on the containers that store photographs. You assign users to RBAC roles. You need to configure the website's Microsoft Entra ID Application so that user's permissions can be used with the Azure Blob containers. How should you configure the application?](#you-are-developing-an-aspnet-core-website-that-can-be-used-to-manage-photographs-which-are-stored-in-azure-blob-storage-containers-users-of-the-website-authenticate-by-using-their-microsoft-entra-id-credentials-you-implement-role-based-access-control-rbac-role-permissions-on-the-containers-that-store-photographs-you-assign-users-to-rbac-roles-you-need-to-configure-the-websites-microsoft-entra-id-application-so-that-users-permissions-can-be-used-with-the-azure-blob-containers-how-should-you-configure-the-application)
| 81   | [You are developing an ASP.NET Core app that includes feature flags which are managed by Azure App Configuration. You create an Azure App Configuration store named `AppFeatureFlagStore` that contains a feature flag named `Export`. You need to update the app to meet the following requirements: Use the `Export` feature in the app without requiring a restart of the app. Validate users before users are allowed access to secure resources. Permit users to access secure resources. How should you complete the code segment?](#you-are-developing-an-aspnet-core-app-that-includes-feature-flags-which-are-managed-by-azure-app-configuration-you-create-an-azure-app-configuration-store-named-appfeatureflagstore-that-contains-a-feature-flag-named-export-you-need-to-update-the-app-to-meet-the-following-requirements-use-the-export-feature-in-the-app-without-requiring-a-restart-of-the-app-validate-users-before-users-are-allowed-access-to-secure-resources-permit-users-to-access-secure-resources-how-should-you-complete-the-code-segment)
| 82   | [You have an application that includes an Azure Web app and several Azure Function apps. Application secrets including connection strings and certificates are stored in Azure Key Vault. Secrets must not be stored in the application or application runtime environment. Changes to Microsoft Entra ID must be minimized. You need to design the approach to loading application secrets. What should you do?](#you-have-an-application-that-includes-an-azure-web-app-and-several-azure-function-apps-application-secrets-including-connection-strings-and-certificates-are-stored-in-azure-key-vault-secrets-must-not-be-stored-in-the-application-or-application-runtime-environment-changes-to-microsoft-entra-id-must-be-minimized-you-need-to-design-the-approach-to-loading-application-secrets-what-should-you-do)
| 83   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Key Vault key named `skey`. 2. Encrypt the intake forms using the public key portion of skey. 3. Store the encrypted data in Azure Blob storage. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-1-create-an-azure-key-vault-key-named-skey-2-encrypt-the-intake-forms-using-the-public-key-portion-of-skey-3-store-the-encrypted-data-in-azure-blob-storage-does-the-solution-meet-the-goal)
| 84   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Cosmos DB database with Storage Service Encryption enabled. 2. Store the intake forms in the Azure Cosmos DB database. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-1-create-an-azure-cosmos-db-database-with-storage-service-encryption-enabled-2-store-the-intake-forms-in-the-azure-cosmos-db-database-does-the-solution-meet-the-goal)
| 85   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: Store the intake forms as Azure Key Vault secrets. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-store-the-intake-forms-as-azure-key-vault-secrets-does-the-solution-meet-the-goal)
| 86   | [You plan to deploy a new application to a Linux virtual machine (VM) that is hosted in Azure. The entire VM must be secured at rest by using industry-standard encryption technology to address organizational security and compliance requirements. You need to configure Azure Disk Encryption for the VM. How should you complete the Azure CLI commands?](#you-plan-to-deploy-a-new-application-to-a-linux-virtual-machine-vm-that-is-hosted-in-azure-the-entire-vm-must-be-secured-at-rest-by-using-industry-standard-encryption-technology-to-address-organizational-security-and-compliance-requirements-you-need-to-configure-azure-disk-encryption-for-the-vm-how-should-you-complete-the-azure-cli-commands)
| 87   | [Your company is developing an Azure API hosted in Azure. You need to implement authentication for the Azure API to access other Azure resources. You have the following requirements: All API calls must be authenticated. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?](#your-company-is-developing-an-azure-api-hosted-in-azure-you-need-to-implement-authentication-for-the-azure-api-to-access-other-azure-resources-you-have-the-following-requirements-all-api-calls-must-be-authenticated-callers-to-the-api-must-not-send-credentials-to-the-api-which-authentication-mechanism-should-you-use)
| 88   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 1: The file MIME type is supported by the service.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-1-the-file-mime-type-is-supported-by-the-service)
| 89   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 2: Edge nodes must be purged of all cache assets.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-2-edge-nodes-must-be-purged-of-all-cache-assets)
| 90   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 3: The compression type is supported.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-3-the-compression-type-is-supported)
| 91   | [You are developing an application. You have an Azure user account that has access to two subscriptions. You need to retrieve a storage account key secret from Azure Key Vault. In which order should you arrange the PowerShell commands to develop the solution?](#you-are-developing-an-application-you-have-an-azure-user-account-that-has-access-to-two-subscriptions-you-need-to-retrieve-a-storage-account-key-secret-from-azure-key-vault-in-which-order-should-you-arrange-the-powershell-commands-to-develop-the-solution)
| 92   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use an `X.509` certificate to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-use-an-x509-certificate-to-authenticate-the-vm-with-azure-resource-manager-does-the-solution-meet-the-goal)
| 93   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use the Reader role-based access control (RBAC) role to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-use-the-reader-role-based-access-control-rbac-role-to-authenticate-the-vm-with-azure-resource-manager-does-the-solution-meet-the-goal)
| 94   | [You are building a website that is used to review restaurants. The website will use an Azure CDN to improve performance and add functionality to requests. You build and deploy a mobile app for Apple iPhones. Whenever a user accesses the website from an iPhone, the user must be redirected to the app store. You need to implement an Azure CDN rule that ensures that iPhone users are redirected to the app store. How should you complete the Azure Resource Manager template?](#you-are-building-a-website-that-is-used-to-review-restaurants-the-website-will-use-an-azure-cdn-to-improve-performance-and-add-functionality-to-requests-you-build-and-deploy-a-mobile-app-for-apple-iphones-whenever-a-user-accesses-the-website-from-an-iphone-the-user-must-be-redirected-to-the-app-store-you-need-to-implement-an-azure-cdn-rule-that-ensures-that-iphone-users-are-redirected-to-the-app-store-how-should-you-complete-the-azure-resource-manager-template)
| 95   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure and use Integrated Windows Authentication in the website. In the website, query Microsoft Graph API to load the group to which the user is a member. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-configure-and-use-integrated-windows-authentication-in-the-website-in-the-website-query-microsoft-graph-api-to-load-the-group-to-which-the-user-is-a-member-does-the-solution-meet-the-goal)
| 96   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Run the `Invoke-RestMethod` cmdlet to make a request to the local managed identity for Azure resources endpoint. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-run-the-invoke-restmethod-cmdlet-to-make-a-request-to-the-local-managed-identity-for-azure-resources-endpoint-does-the-solution-meet-the-goal)
| 97   | [Your company's Azure subscription includes an Azure Log Analytics workspace. Your company has a hundred on-premises servers that run either Windows Server 2012 R2 or Windows Server 2016, and is linked to the Azure Log Analytics workspace. The Azure Log Analytics workspace is set up to gather performance counters associated with security from these linked servers. You must configure alerts based on the information gathered by the Azure Log Analytics workspace. You have to make sure that alert rules allow for dimensions, and that alert creation time should be kept to a minimum. Furthermore, a single alert notification must be created when the alert is created and when the alert is resolved. You need to make use of the necessary signal type when creating the alert rules. Which of the following is the option you should use?](#your-companys-azure-subscription-includes-an-azure-log-analytics-workspace-your-company-has-a-hundred-on-premises-servers-that-run-either-windows-server-2012-r2-or-windows-server-2016-and-is-linked-to-the-azure-log-analytics-workspace-the-azure-log-analytics-workspace-is-set-up-to-gather-performance-counters-associated-with-security-from-these-linked-servers-you-must-configure-alerts-based-on-the-information-gathered-by-the-azure-log-analytics-workspace-you-have-to-make-sure-that-alert-rules-allow-for-dimensions-and-that-alert-creation-time-should-be-kept-to-a-minimum-furthermore-a-single-alert-notification-must-be-created-when-the-alert-is-created-and-when-the-alert-is-resolved-you-need-to-make-use-of-the-necessary-signal-type-when-creating-the-alert-rules-which-of-the-following-is-the-option-you-should-use)
| 98   | [You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation. You want the application to allow customers to search the index by using regular expressions. What should you do?](#you-are-developing-a-net-core-mvc-application-that-allows-customers-to-research-independent-holiday-accommodation-providers-you-want-to-implement-azure-search-to-allow-the-application-to-search-the-index-by-using-various-criteria-to-locate-documents-related-to-accommodation-you-want-the-application-to-allow-customers-to-search-the-index-by-using-regular-expressions-what-should-you-do)
| 99   | [You are a developer at your company. You need to update the definitions for an existing Logic App. What should you use?](#you-are-a-developer-at-your-company-you-need-to-update-the-definitions-for-an-existing-logic-app-what-should-you-use)
| 100   | [The cluster uses Azure Monitor for containers to monitor the cluster. The application has sticky sessions enabled on the ingress controller. Some customers report a large number of errors in the application over the last 24 hours. You need to determine on which virtual machines (VMs) the errors are occurring. How should you complete the Azure Monitor query?](#the-cluster-uses-azure-monitor-for-containers-to-monitor-the-cluster-the-application-has-sticky-sessions-enabled-on-the-ingress-controller-some-customers-report-a-large-number-of-errors-in-the-application-over-the-last-24-hours-you-need-to-determine-on-which-virtual-machines-vms-the-errors-are-occurring-how-should-you-complete-the-azure-monitor-query)
| 101   | [You plan to deploy a web app to App Service on Linux. You create an App Service plan. You create and push a custom Docker image that contains the web app to Azure Container Registry. You need to access the console logs generated from inside the container in real-time. How should you complete the Azure CLI command?](#you-plan-to-deploy-a-web-app-to-app-service-on-linux-you-create-an-app-service-plan-you-create-and-push-a-custom-docker-image-that-contains-the-web-app-to-azure-container-registry-you-need-to-access-the-console-logs-generated-from-inside-the-container-in-real-time-how-should-you-complete-the-azure-cli-command)
| 102   | [You develop an app that allows users to upload photos and videos to Azure storage. The app uses a storage REST API call to upload the media to a blob storage account named `Account1`. You have blob storage containers named `Container1` and `Container2`. Uploading of videos occurs on an irregular basis. You need to copy specific blobs from `Container1` to `Container2` when a new video is uploaded. What should you do?](#you-develop-an-app-that-allows-users-to-upload-photos-and-videos-to-azure-storage-the-app-uses-a-storage-rest-api-call-to-upload-the-media-to-a-blob-storage-account-named-account1-you-have-blob-storage-containers-named-container1-and-container2-uploading-of-videos-occurs-on-an-irregular-basis-you-need-to-copy-specific-blobs-from-container1-to-container2-when-a-new-video-is-uploaded-what-should-you-do)
| 103   | [A web service provides customer summary information for e-commerce partners. The web service is implemented as an Azure Function app with an HTTP trigger. Access to the API is provided by an Azure API Management instance. The API Management instance is configured in consumption plan mode. All API calls are authenticated by using OAuth. API calls must be cached. Customers must not be able to view cached data for other customers. You need to configure API Management policies for caching. How should you complete the policy statement?](#a-web-service-provides-customer-summary-information-for-e-commerce-partners-the-web-service-is-implemented-as-an-azure-function-app-with-an-http-trigger-access-to-the-api-is-provided-by-an-azure-api-management-instance-the-api-management-instance-is-configured-in-consumption-plan-mode-all-api-calls-are-authenticated-by-using-oauth-api-calls-must-be-cached-customers-must-not-be-able-to-view-cached-data-for-other-customers-you-need-to-configure-api-management-policies-for-caching-how-should-you-complete-the-policy-statement)
| 104   | [You are developing an ASP.NET Core website that uses Azure FrontDoor. The website is used to build custom weather data sets for researchers. Data sets are downloaded by users as Comma Separated Value (CSV) files. The data is refreshed every 10 hours. Specific files must be purged from the FrontDoor cache based upon Response Header values. You need to purge individual assets from the Front Door cache. Which type of cache purge should you use?](#you-are-developing-an-aspnet-core-website-that-uses-azure-frontdoor-the-website-is-used-to-build-custom-weather-data-sets-for-researchers-data-sets-are-downloaded-by-users-as-comma-separated-value-csv-files-the-data-is-refreshed-every-10-hours-specific-files-must-be-purged-from-the-frontdoor-cache-based-upon-response-header-values-you-need-to-purge-individual-assets-from-the-front-door-cache-which-type-of-cache-purge-should-you-use)
| 105   | [Contoso, Ltd. provides an API to customers by using Azure API Management (APIM). The API authorizes users with a JWT token. You must implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID. You need to add the following policies to the policies file: a set-variable policy to store the detected user identity a cache-lookup-value policy a cache-store-value policy a find-and-replace policy to update the response body with the user profile information To which policy section should you add the policies?](#contoso-ltd-provides-an-api-to-customers-by-using-azure-api-management-apim-the-api-authorizes-users-with-a-jwt-token-you-must-implement-response-caching-for-the-apim-gateway-the-caching-mechanism-must-detect-the-user-id-of-the-client-that-accesses-data-for-a-given-location-and-cache-the-response-for-that-user-id-you-need-to-add-the-following-policies-to-the-policies-file-a-set-variable-policy-to-store-the-detected-user-identity-a-cache-lookup-value-policy-a-cache-store-value-policy-a-find-and-replace-policy-to-update-the-response-body-with-the-user-profile-information-to-which-policy-section-should-you-add-the-policies)
| 106   | [You are developing an application to retrieve user profile information. The application will use the Microsoft Graph SDK. The app must retrieve user profile information by using a Microsoft Graph API call. You need to call the Microsoft Graph API from the application. In which order should you perform the actions?](#you-are-developing-an-application-to-retrieve-user-profile-information-the-application-will-use-the-microsoft-graph-sdk-the-app-must-retrieve-user-profile-information-by-using-a-microsoft-graph-api-call-you-need-to-call-the-microsoft-graph-api-from-the-application-in-which-order-should-you-perform-the-actions)
| 107   | [You develop and deploy an Azure Logic App that calls an Azure Function app. The Azure Function App includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Logic App must use Azure Monitor logs to record and store information about runtime data and events. The logs must be stored in the Azure Blob storage account. You need to set up Azure Monitor logs and collect diagnostics data for the Azure Logic App. Which three actions should you perform in sequence?](#you-develop-and-deploy-an-azure-logic-app-that-calls-an-azure-function-app-the-azure-function-app-includes-an-openapi-swagger-definition-and-uses-an-azure-blob-storage-account-all-resources-are-secured-by-using-microsoft-entra-id-the-logic-app-must-use-azure-monitor-logs-to-record-and-store-information-about-runtime-data-and-events-the-logs-must-be-stored-in-the-azure-blob-storage-account-you-need-to-set-up-azure-monitor-logs-and-collect-diagnostics-data-for-the-azure-logic-app-which-three-actions-should-you-perform-in-sequence)
| 108   | [You develop an application. You plan to host the application on a set of virtual machines (VMs) in Azure. You need to configure Azure Monitor to collect logs from the application. Which four actions should you perform in sequence?](#you-develop-an-application-you-plan-to-host-the-application-on-a-set-of-virtual-machines-vms-in-azure-you-need-to-configure-azure-monitor-to-collect-logs-from-the-application-which-four-actions-should-you-perform-in-sequence)
| 109   | [You have an application that provides weather forecasting data to external partners. You use Azure API Management to publish APIs. You must change the behavior of the API to meet the following requirements: Support alternative input parameters. Remove formatting text from responses. Provide additional context to back-end services. Which types of policies should you implement?](#you-have-an-application-that-provides-weather-forecasting-data-to-external-partners-you-use-azure-api-management-to-publish-apis-you-must-change-the-behavior-of-the-api-to-meet-the-following-requirements-support-alternative-input-parameters-remove-formatting-text-from-responses-provide-additional-context-to-back-end-services-which-types-of-policies-should-you-implement)
| 110   | [Your company is developing an Azure API. You need to implement authentication for the Azure API. You have the following requirements: All API calls must be secure. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?](#your-company-is-developing-an-azure-api-you-need-to-implement-authentication-for-the-azure-api-you-have-the-following-requirements-all-api-calls-must-be-secure-callers-to-the-api-must-not-send-credentials-to-the-api-which-authentication-mechanism-should-you-use)
| 111   | [You are a developer for a SaaS company that offers many web services. All web services for the company must meet the following requirements: Use API Management to access the services Use OpenID Connect for authentication Prevent anonymous usage A recent security audit found that several web services can be called without any authentication. Which API Management policy should you implement?](#you-are-a-developer-for-a-saas-company-that-offers-many-web-services-all-web-services-for-the-company-must-meet-the-following-requirements-use-api-management-to-access-the-services-use-openid-connect-for-authentication-prevent-anonymous-usage-a-recent-security-audit-found-that-several-web-services-can-be-called-without-any-authentication-which-api-management-policy-should-you-implement)
| 112   | [You are developing an Azure App Service REST API. The API must be called by an Azure App Service web app. The API must retrieve and update user profile information stored in Microsoft Entra ID. You need to configure the API to make the updates. Which two tools should you use?](#you-are-developing-an-azure-app-service-rest-api-the-api-must-be-called-by-an-azure-app-service-web-app-the-api-must-retrieve-and-update-user-profile-information-stored-in-microsoft-entra-id-you-need-to-configure-the-api-to-make-the-updates-which-two-tools-should-you-use)
| 113   | [You develop a REST API. You implement a user delegation SAS token to communicate with Azure Blob storage. The token is compromised. You need to revoke the token. What are two possible ways to achieve this goal?](#you-develop-a-rest-api-you-implement-a-user-delegation-sas-token-to-communicate-with-azure-blob-storage-the-token-is-compromised-you-need-to-revoke-the-token-what-are-two-possible-ways-to-achieve-this-goal)
| 114   | [You are developing an Azure-hosted application that must use an on-premises hardware security module (HSM) key. The key must be transferred to your existing Azure Key Vault by using the Bring Your Own Key (BYOK) process. You need to securely transfer the key to Azure Key Vault. Which four actions should you perform in sequence?](#you-are-developing-an-azure-hosted-application-that-must-use-an-on-premises-hardware-security-module-hsm-key-the-key-must-be-transferred-to-your-existing-azure-key-vault-by-using-the-bring-your-own-key-byok-process-you-need-to-securely-transfer-the-key-to-azure-key-vault-which-four-actions-should-you-perform-in-sequence)
| 115   | [You develop and deploy an Azure Logic app that calls an Azure Function app. The Azure Function app includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Azure Logic app must securely access the Azure Blob storage account. Microsoft Entra ID resources must remain if the Azure Logic app is deleted. You need to secure the Azure Logic app. What should you do?](#you-develop-and-deploy-an-azure-logic-app-that-calls-an-azure-function-app-the-azure-function-app-includes-an-openapi-swagger-definition-and-uses-an-azure-blob-storage-account-all-resources-are-secured-by-using-microsoft-entra-id-the-azure-logic-app-must-securely-access-the-azure-blob-storage-account-microsoft-entra-id-resources-must-remain-if-the-azure-logic-app-is-deleted-you-need-to-secure-the-azure-logic-app-what-should-you-do)
| 116   | [You manage several existing Logic Apps. You need to change definitions, add new logic, and optimize these apps on a regular basis. What should you use?](#you-manage-several-existing-logic-apps-you-need-to-change-definitions-add-new-logic-and-optimize-these-apps-on-a-regular-basis-what-should-you-use)
| 117   | [You are developing a solution that will use a multi-partitioned Azure Cosmos DB database. You plan to use the latest Azure Cosmos DB SDK for development. The solution must meet the following requirements: Send insert and update operations to an Azure Blob storage account. Process changes to all partitions immediately. Allow parallelization of change processing. You need to process the Azure Cosmos DB operations. What are two possible ways to achieve this goal?](#you-are-developing-a-solution-that-will-use-a-multi-partitioned-azure-cosmos-db-database-you-plan-to-use-the-latest-azure-cosmos-db-sdk-for-development-the-solution-must-meet-the-following-requirements-send-insert-and-update-operations-to-an-azure-blob-storage-account-process-changes-to-all-partitions-immediately-allow-parallelization-of-change-processing-you-need-to-process-the-azure-cosmos-db-operations-what-are-two-possible-ways-to-achieve-this-goal)
| 118   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 1: The code configures the lock duration for the queue.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-1-the-code-configures-the-lock-duration-for-the-queue)
| 119   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 2: The last message read remains in the queue after the code runs.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-2-the-last-message-read-remains-in-the-queue-after-the-code-runs)
| 120   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 3: The storage queue remains in the storage account after the code runs.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-3-the-storage-queue-remains-in-the-storage-account-after-the-code-runs)
| 121   | [You develop software solutions for a mobile delivery service. You are developing a mobile app that users can use to order from a restaurant in their area. The app uses the following workflow: 1. A driver selects the restaurants for which they will deliver orders. 2. Orders are sent to all available drivers in an area. 3. Only orders for the selected restaurants will appear for the driver. 4. The first driver to accept an order removes it from the list of available orders. You need to implement an Azure Service Bus solution. Which three actions should you perform in sequence?](#you-develop-software-solutions-for-a-mobile-delivery-service-you-are-developing-a-mobile-app-that-users-can-use-to-order-from-a-restaurant-in-their-area-the-app-uses-the-following-workflow-1-a-driver-selects-the-restaurants-for-which-they-will-deliver-orders-2-orders-are-sent-to-all-available-drivers-in-an-area-3-only-orders-for-the-selected-restaurants-will-appear-for-the-driver-4-the-first-driver-to-accept-an-order-removes-it-from-the-list-of-available-orders-you-need-to-implement-an-azure-service-bus-solution-which-three-actions-should-you-perform-in-sequence)
| 122   | [You develop a news and blog content app for Windows devices. A notification must arrive on a user's device when there is a new article available for them to view. You need to implement push notifications. How should you complete the code segment?](#you-develop-a-news-and-blog-content-app-for-windows-devices-a-notification-must-arrive-on-a-users-device-when-there-is-a-new-article-available-for-them-to-view-you-need-to-implement-push-notifications-how-should-you-complete-the-code-segment)
| 123   | [You are developing an Azure messaging solution. You need to ensure that the solution meets the following requirements: Provide transactional support. Provide duplicate detection. Store the messages for an unlimited period of time. Which two technologies will meet the requirements?](#you-are-developing-an-azure-messaging-solution-you-need-to-ensure-that-the-solution-meets-the-following-requirements-provide-transactional-support-provide-duplicate-detection-store-the-messages-for-an-unlimited-period-of-time-which-two-technologies-will-meet-the-requirements)
| 124   | [You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and hosted in an Azure App Service instance. You need to configure back-end authentication for the API Management service instance. Which target and gateway credential type should you use?](#you-develop-a-gateway-solution-for-a-public-facing-news-api-the-news-api-back-end-is-implemented-as-a-restful-service-and-hosted-in-an-azure-app-service-instance-you-need-to-configure-back-end-authentication-for-the-api-management-service-instance-which-target-and-gateway-credential-type-should-you-use)
| 125   | [You are creating an app that uses Event Grid to connect with other services. Your app's event data will be sent to a serverless function that checks compliance. This function is maintained by your company. You write a new event subscription at the scope of your resource. The event must be invalidated after a specific period of time. You need to configure Event Grid. What should you do?](#you-are-creating-an-app-that-uses-event-grid-to-connect-with-other-services-your-apps-event-data-will-be-sent-to-a-serverless-function-that-checks-compliance-this-function-is-maintained-by-your-company-you-write-a-new-event-subscription-at-the-scope-of-your-resource-the-event-must-be-invalidated-after-a-specific-period-of-time-you-need-to-configure-event-grid-what-should-you-do)
| 126   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 1: The XML segment belongs in the `<inbound>` section of the policy.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-1-the-xml-segment-belongs-in-the-inbound-section-of-the-policy)
| 127   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 2: If the body size is >256k, an error will occur.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-2-if-the-body-size-is-256k-an-error-will-occur)
| 128   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 3: If the request is `<http://contoso.com/api/9.2/>`, the policy will retain the higher version.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-3-if-the-request-is-httpcontosocomapi92-the-policy-will-retain-the-higher-version)
| 129   | [You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and uses an OpenAPI specification. You need to ensure that you can access the news API by using an Azure API Management service instance. Which Azure PowerShell command should you run?](#you-develop-a-gateway-solution-for-a-public-facing-news-api-the-news-api-back-end-is-implemented-as-a-restful-service-and-uses-an-openapi-specification-you-need-to-ensure-that-you-can-access-the-news-api-by-using-an-azure-api-management-service-instance-which-azure-powershell-command-should-you-run)
| 130   | [You are developing an Azure function that connects to an Azure SQL Database instance. The function is triggered by an Azure Storage queue. You receive reports of numerous System.InvalidOperationExceptions with the following message: 'Timeout expired. The timeout period elapsed prior to obtaining a connection from the pool. This may have occurred because all pooled connections were in use and max pool size was reached.' You need to prevent the exception. What should you do?](#you-are-developing-an-azure-function-that-connects-to-an-azure-sql-database-instance-the-function-is-triggered-by-an-azure-storage-queue-you-receive-reports-of-numerous-systeminvalidoperationexceptions-with-the-following-message-timeout-expired-the-timeout-period-elapsed-prior-to-obtaining-a-connection-from-the-pool-this-may-have-occurred-because-all-pooled-connections-were-in-use-and-max-pool-size-was-reached-you-need-to-prevent-the-exception-what-should-you-do)
| 131   | [You are developing a REST web service. Customers will access the service by using an Azure API Management instance. The web service does not correctly handle conflicts. Instead of returning an HTTP status code of 409, the service returns a status code of 500. The body of the status message contains only the word conflict. You need to ensure that conflicts produce the correct response. How should you complete the policy?](#you-are-developing-a-rest-web-service-customers-will-access-the-service-by-using-an-azure-api-management-instance-the-web-service-does-not-correctly-handle-conflicts-instead-of-returning-an-http-status-code-of-409-the-service-returns-a-status-code-of-500-the-body-of-the-status-message-contains-only-the-word-conflict-you-need-to-ensure-that-conflicts-produce-the-correct-response-how-should-you-complete-the-policy)
| 132   | [You are a developer for a Software as a Service (SaaS) company. You develop solutions that provide the ability to send notifications by using Azure Notification Hubs. You need to create sample code that customers can use as a reference for how to send raw notifications to Windows Push Notification Services (WNS) devices. The sample code must not use external packages. How should you complete the code segment?](#you-are-a-developer-for-a-software-as-a-service-saas-company-you-develop-solutions-that-provide-the-ability-to-send-notifications-by-using-azure-notification-hubs-you-need-to-create-sample-code-that-customers-can-use-as-a-reference-for-how-to-send-raw-notifications-to-windows-push-notification-services-wns-devices-the-sample-code-must-not-use-external-packages-how-should-you-complete-the-code-segment)
| 133   | [You develop and deploy an ASP.NET web app to Azure App Service. You use Application Insights telemetry to monitor the app. You must test the app to ensure that the app is available and responsive from various points around the world and at regular intervals. If the app is not responding, you must send an alert to support staff. You need to configure a test for the web app. Which two test types can you use?](#you-develop-and-deploy-an-aspnet-web-app-to-azure-app-service-you-use-application-insights-telemetry-to-monitor-the-app-you-must-test-the-app-to-ensure-that-the-app-is-available-and-responsive-from-various-points-around-the-world-and-at-regular-intervals-if-the-app-is-not-responding-you-must-send-an-alert-to-support-staff-you-need-to-configure-a-test-for-the-web-app-which-two-test-types-can-you-use)
| 134   | [You are developing an Azure solution to collect inventory data from thousands of stores located around the world. Each store location will send the inventory data hourly to an Azure Blob storage account for processing. The solution must meet the following requirements: Begin processing when data is saved to Azure Blob storage. Filter data based on store location information. Trigger an Azure Logic App to process the data for output to Azure Cosmos DB. Enable high availability and geographic distribution. Allow 24-hours for retries. Implement an exponential back off data processing. You need to configure the solution. What should you implement?](#you-are-developing-an-azure-solution-to-collect-inventory-data-from-thousands-of-stores-located-around-the-world-each-store-location-will-send-the-inventory-data-hourly-to-an-azure-blob-storage-account-for-processing-the-solution-must-meet-the-following-requirements-begin-processing-when-data-is-saved-to-azure-blob-storage-filter-data-based-on-store-location-information-trigger-an-azure-logic-app-to-process-the-data-for-output-to-azure-cosmos-db-enable-high-availability-and-geographic-distribution-allow-24-hours-for-retries-implement-an-exponential-back-off-data-processing-you-need-to-configure-the-solution-what-should-you-implement)
| 135   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Enable Application Request Routing (ARR). Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-enable-application-request-routing-arr-does-the-solution-meet-the-goal)
| 136   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure an Azure Database for PostgreSQL. Update the web applications. Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-deploy-and-configure-an-azure-database-for-postgresql-update-the-web-applications-does-the-solution-meet-the-goal)
| 137   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure Azure Cache for Redis. Update the web applications. Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-deploy-and-configure-azure-cache-for-redis-update-the-web-applications-does-the-solution-meet-the-goal)
| 138   | [A company is developing a gaming platform. Users can join teams to play online and see leaderboards that include player statistics. The solution includes an entity named `Team`. You plan to implement an Azure Redis Cache instance to improve the efficiency of data operations for entities that rarely change. You need to invalidate the cache when team data is changed. How should you complete the code?](#a-company-is-developing-a-gaming-platform-users-can-join-teams-to-play-online-and-see-leaderboards-that-include-player-statistics-the-solution-includes-an-entity-named-team-you-plan-to-implement-an-azure-redis-cache-instance-to-improve-the-efficiency-of-data-operations-for-entities-that-rarely-change-you-need-to-invalidate-the-cache-when-team-data-is-changed-how-should-you-complete-the-code)
| 139   | [A company has multiple warehouses. Each warehouse contains IoT temperature devices which deliver temperature data to an Azure Service Bus queue. You need to send email alerts to facility supervisors immediately if the temperature at a warehouse goes above or below specified threshold temperatures. Which five actions should you perform in sequence?](#a-company-has-multiple-warehouses-each-warehouse-contains-iot-temperature-devices-which-deliver-temperature-data-to-an-azure-service-bus-queue-you-need-to-send-email-alerts-to-facility-supervisors-immediately-if-the-temperature-at-a-warehouse-goes-above-or-below-specified-threshold-temperatures-which-five-actions-should-you-perform-in-sequence)
| 140   | [You are creating a hazard notification system that has a single signaling server which triggers audio and visual alarms to start and stop. You implement Azure Service Bus to publish alarms. Each alarm controller uses Azure Service Bus to receive alarm signals as part of a transaction. Alarm events must be recorded for audit purposes. Each transaction record must include information about the alarm type that was activated. You need to implement a reply trail auditing solution. Which two actions should you perform?](#you-are-creating-a-hazard-notification-system-that-has-a-single-signaling-server-which-triggers-audio-and-visual-alarms-to-start-and-stop-you-implement-azure-service-bus-to-publish-alarms-each-alarm-controller-uses-azure-service-bus-to-receive-alarm-signals-as-part-of-a-transaction-alarm-events-must-be-recorded-for-audit-purposes-each-transaction-record-must-include-information-about-the-alarm-type-that-was-activated-you-need-to-implement-a-reply-trail-auditing-solution-which-two-actions-should-you-perform)
| 141   | [You are developing applications for a company. You plan to host the applications on Azure App Services. The company has the following requirements: Every five minutes verify that the websites are responsive. Verify that the websites respond within a specified time threshold. Dependent requests such as images and JavaScript files must load properly. Generate alerts if a website is experiencing issues. If a website fails to load, the system must attempt to reload the site three more times. You need to implement this process with the least amount of effort. What should you do?](#you-are-developing-applications-for-a-company-you-plan-to-host-the-applications-on-azure-app-services-the-company-has-the-following-requirements-every-five-minutes-verify-that-the-websites-are-responsive-verify-that-the-websites-respond-within-a-specified-time-threshold-dependent-requests-such-as-images-and-javascript-files-must-load-properly-generate-alerts-if-a-website-is-experiencing-issues-if-a-website-fails-to-load-the-system-must-attempt-to-reload-the-site-three-more-times-you-need-to-implement-this-process-with-the-least-amount-of-effort-what-should-you-do)
| 142   | [You develop and add several functions to an Azure Function app that uses the latest runtime host. The functions contain several REST API endpoints secured by using SSL. The Azure Function app runs in a Consumption plan. You must send an alert when any of the function endpoints are unavailable or responding too slowly. You need to monitor the availability and responsiveness of the functions. What should you do?](#you-develop-and-add-several-functions-to-an-azure-function-app-that-uses-the-latest-runtime-host-the-functions-contain-several-rest-api-endpoints-secured-by-using-ssl-the-azure-function-app-runs-in-a-consumption-plan-you-must-send-an-alert-when-any-of-the-function-endpoints-are-unavailable-or-responding-too-slowly-you-need-to-monitor-the-availability-and-responsiveness-of-the-functions-what-should-you-do)
| 143   | [You are developing an e-commerce solution that uses a microservice architecture. You need to design a communication backplane for communicating transactional messages between various parts of the solution. Messages must be communicated in first-in-first-out (FIFO) order. What should you use?](#you-are-developing-an-e-commerce-solution-that-uses-a-microservice-architecture-you-need-to-design-a-communication-backplane-for-communicating-transactional-messages-between-various-parts-of-the-solution-messages-must-be-communicated-in-first-in-first-out-fifo-order-what-should-you-use)
| 144   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Service Bus Queue from the mobile application. Create an Azure Function App that uses an Azure Service Bus Queue trigger. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-service-bus-queue-from-the-mobile-application-create-an-azure-function-app-that-uses-an-azure-service-bus-queue-trigger-does-the-solution-meet-the-goal)
| 145   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Notification Hub. Register all devices with the hub. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-notification-hub-register-all-devices-with-the-hub-does-the-solution-meet-the-goal)
| 146   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Service Bus. Configure a topic to receive the device data by using a correlation filter. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-service-bus-configure-a-topic-to-receive-the-device-data-by-using-a-correlation-filter-does-the-solution-meet-the-goal)
| 147   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure event filtering to evaluate the device identifier. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-grid-configure-event-filtering-to-evaluate-the-device-identifier-does-the-solution-meet-the-goal)
| 148   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure Function App that uses an Azure Storage Queue trigger. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-storage-queue-from-the-mobile-application-create-an-azure-function-app-that-uses-an-azure-storage-queue-trigger-does-the-solution-meet-the-goal)
| 149   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure VM that is triggered from Azure Storage Queue events. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-storage-queue-from-the-mobile-application-create-an-azure-vm-that-is-triggered-from-azure-storage-queue-events-does-the-solution-meet-the-goal)
| 150   | [You are developing a solution that will use Azure messaging services. You need to ensure that the solution uses a publish-subscribe model and eliminates the need for constant polling. What are two possible ways to achieve the goal?](#you-are-developing-a-solution-that-will-use-azure-messaging-services-you-need-to-ensure-that-the-solution-uses-a-publish-subscribe-model-and-eliminates-the-need-for-constant-polling-what-are-two-possible-ways-to-achieve-the-goal)
| 151   | [A company is implementing a publish-subscribe (Pub/Sub) messaging component by using Azure Service Bus. You are developing the first subscription application. In the Azure portal you see that messages are being sent to the subscription for each topic. You create and initialize a subscription client object by supplying the correct details, but the subscription application is still not consuming the messages. You need to ensure that the subscription client processes all messages. Which code segment should you use?](#a-company-is-implementing-a-publish-subscribe-pubsub-messaging-component-by-using-azure-service-bus-you-are-developing-the-first-subscription-application-in-the-azure-portal-you-see-that-messages-are-being-sent-to-the-subscription-for-each-topic-you-create-and-initialize-a-subscription-client-object-by-supplying-the-correct-details-but-the-subscription-application-is-still-not-consuming-the-messages-you-need-to-ensure-that-the-subscription-client-processes-all-messages-which-code-segment-should-you-use)
| 152   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Hub. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-hub-configure-the-machine-identifier-as-the-partition-key-and-enable-capture-does-the-solution-meet-the-goal)
| 153   | [A company is developing a solution that allows smart refrigerators to send temperature information to a central location. The solution must receive and store messages until they can be processed. You create an Azure Service Bus instance by providing a name, pricing tier, subscription, resource group, and location. You need to complete the configuration. Which Azure CLI or PowerShell command should you run?](#a-company-is-developing-a-solution-that-allows-smart-refrigerators-to-send-temperature-information-to-a-central-location-the-solution-must-receive-and-store-messages-until-they-can-be-processed-you-create-an-azure-service-bus-instance-by-providing-a-name-pricing-tier-subscription-resource-group-and-location-you-need-to-complete-the-configuration-which-azure-cli-or-powershell-command-should-you-run)
| 154   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Container` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-container-blade-does-the-solution-meet-the-goal)
| 155   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Virtual Machine` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-virtual-machine-blade-does-the-solution-meet-the-goal)
| 156   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Resource Group` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-resource-group-blade-does-the-solution-meet-the-goal)
| 157   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then enable the Use for App service option. Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-open-the-azure-application-gateways-http-setting-and-set-the-override-backend-path-option-to-mywebapp1azurewebsitesnet-you-then-enable-the-use-for-app-service-option-does-this-meet-the-goal)
| 158   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You configure `mywebapp1` to run in an Azure App service environment (ASE). Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-configure-mywebapp1-to-run-in-an-azure-app-service-environment-ase-does-this-meet-the-goal)
| 159   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then add an authentication certificate for `mywebapp1.azurewebsites.net`. Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-open-the-azure-application-gateways-http-setting-and-set-the-override-backend-path-option-to-mywebapp1azurewebsitesnet-you-then-add-an-authentication-certificate-for-mywebapp1azurewebsitesnet-does-this-meet-the-goal)
| 160   | [Your company has a web app named `WebApp1`. You use the WebJobs SDK to design a triggered App Service background task that automatically invokes a function in the code every time new data is received in a queue. You are preparing to configure the service processes a queue data item. Which of the following is the service you should use?](#your-company-has-a-web-app-named-webapp1-you-use-the-webjobs-sdk-to-design-a-triggered-app-service-background-task-that-automatically-invokes-a-function-in-the-code-every-time-new-data-is-received-in-a-queue-you-are-preparing-to-configure-the-service-processes-a-queue-data-item-which-of-the-following-is-the-service-you-should-use)
| 161   | [Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformFaultDomainCount` property?](#your-company-has-an-azure-subscription-you-need-to-deploy-a-number-of-azure-virtual-machines-to-the-subscription-by-using-azure-resource-manager-arm-templates-the-virtual-machines-will-be-included-in-a-single-availability-set-you-need-to-ensure-that-the-arm-template-allows-for-as-many-virtual-machines-as-possible-to-remain-accessible-in-the-event-of-fabric-failure-or-maintenance-which-of-the-following-is-the-value-that-you-should-configure-for-the-platformfaultdomaincount-property)
| 162   | [You have two Hyper-V hosts named `Host1` and `Host2`. Host1 has an Azure virtual machine named `VM1` that was deployed by using a custom Azure Resource Manager template. You need to move `VM1` to `Host2`. What should you do?](#you-have-two-hyper-v-hosts-named-host1-and-host2-host1-has-an-azure-virtual-machine-named-vm1-that-was-deployed-by-using-a-custom-azure-resource-manager-template-you-need-to-move-vm1-to-host2-what-should-you-do)
| 163   | [Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the Azure CLI on the device and run the `kubectl apply -f myapp.yaml` command. Does this meet the goal?](#your-company-has-an-azure-kubernetes-service-aks-cluster-that-you-manage-from-an-microsoft-entra-id-joined-device-the-cluster-is-located-in-a-resource-group-developers-have-created-an-application-named-myapp-myapp-was-packaged-into-a-container-image-you-need-to-deploy-the-yaml-manifest-file-for-the-application-solution-you-install-the-azure-cli-on-the-device-and-run-the-kubectl-apply--f-myappyaml-command-does-this-meet-the-goal)
| 164   | [Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the docker client on the device and run the `docker run -it microsoft/azure-cli:0.10.17` command. Does this meet the goal?](#your-company-has-an-azure-kubernetes-service-aks-cluster-that-you-manage-from-an-microsoft-entra-id-joined-device-the-cluster-is-located-in-a-resource-group-developers-have-created-an-application-named-myapp-myapp-was-packaged-into-a-container-image-you-need-to-deploy-the-yaml-manifest-file-for-the-application-solution-you-install-the-docker-client-on-the-device-and-run-the-docker-run--it-microsoftazure-cli01017-command-does-this-meet-the-goal)
| 165   | [Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformUpdateDomainCount` property?](#your-company-has-an-azure-subscription-you-need-to-deploy-a-number-of-azure-virtual-machines-to-the-subscription-by-using-azure-resource-manager-arm-templates-the-virtual-machines-will-be-included-in-a-single-availability-set-you-need-to-ensure-that-the-arm-template-allows-for-as-many-virtual-machines-as-possible-to-remain-accessible-in-the-event-of-fabric-failure-or-maintenance-which-of-the-following-is-the-value-that-you-should-configure-for-the-platformupdatedomaincount-property)
| 166   | [You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Triggered WebJob type. Does the solution meet the goal?](#you-are-designing-an-azure-webjob-that-will-run-on-the-same-instances-as-a-web-app-you-want-to-make-use-of-a-suitable-webjob-type-the-webjob-type-should-also-allow-for-the-option-to-restrict-the-webjob-to-a-single-instance-solution-you-configure-the-use-of-the-triggered-webjob-type-does-the-solution-meet-the-goal)
| 167   | [You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Continuous WebJob type. Does the solution meet the goal?](#you-are-designing-an-azure-webjob-that-will-run-on-the-same-instances-as-a-web-app-you-want-to-make-use-of-a-suitable-webjob-type-the-webjob-type-should-also-allow-for-the-option-to-restrict-the-webjob-to-a-single-instance-solution-you-configure-the-use-of-the-continuous-webjob-type-does-the-solution-meet-the-goal)
| 168   | [You company has an on-premises deployment of MongoDB, and an Azure Cosmos DB account that makes use of the MongoDB API. You need to devise a strategy to migrate MongoDB to the Azure Cosmos DB account. You include the [Data Management Gateway] tool in your migration strategy.](#you-company-has-an-on-premises-deployment-of-mongodb-and-an-azure-cosmos-db-account-that-makes-use-of-the-mongodb-api-you-need-to-devise-a-strategy-to-migrate-mongodb-to-the-azure-cosmos-db-account-you-include-the-data-management-gateway-tool-in-your-migration-strategy)
| 169   | [You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Event Grid with a subscriber Azure Function app. Does the solution meet the goal?](#you-are-developing-an-application-that-processes-azure-blob-storage-events-your-application-has-the-following-requirements-process-transaction-logs-asynchronously-for-changes-that-occur-to-the-blobs-and-the-blob-metadata-process-changes-in-the-order-in-which-they-occurred-retain-changes-for-compliance-reasons-solution-you-use-azure-event-grid-with-a-subscriber-azure-function-app-does-the-solution-meet-the-goal)
| 170   | [You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Monitor HTTP Data Collector API. Does the solution meet the goal?](#you-are-developing-an-application-that-processes-azure-blob-storage-events-your-application-has-the-following-requirements-process-transaction-logs-asynchronously-for-changes-that-occur-to-the-blobs-and-the-blob-metadata-process-changes-in-the-order-in-which-they-occurred-retain-changes-for-compliance-reasons-solution-you-use-azure-monitor-http-data-collector-api-does-the-solution-meet-the-goal)
| 171   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the follows transact-SQL statement: `ALTER TABLE [dbo].[Weyland].[Customers] ALTER COLUMN [email_address] ADD MASKED WITH (FUNCTION = 'email()')`. Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-follows-transact-sql-statement-alter-table-dboweylandcustomers-alter-column-email_address-add-masked-with-function--email-does-the-solution-meet-the-goal)
| 172   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'` Powershell cmdlet Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-set-azsqldatabasedatamaskingpolicy--databasename-weyland-powershell-cmdlet-does-the-solution-meet-the-goal)
| 173   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingRule -DatabaseName 'Weyland' -SchemaName 'dbo' -TableName 'Customers' -ColumnName 'email_address' -MaskingFunction 'email'` Powershell cmdlet Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-set-azsqldatabasedatamaskingrule--databasename-weyland--schemaname-dbo--tablename-customers--columnname-email_address--maskingfunction-email-powershell-cmdlet-does-the-solution-meet-the-goal)
| 174   | [You are developing an e-Commerce Web App. You want to use Azure Key Vault to ensure that sign-ins to the e-Commerce Web App are secured by using Azure App Service authentication and Microsoft Entra ID. What should you do on the e-Commerce Web App?](#you-are-developing-an-e-commerce-web-app-you-want-to-use-azure-key-vault-to-ensure-that-sign-ins-to-the-e-commerce-web-app-are-secured-by-using-azure-app-service-authentication-and-microsoft-entra-id-what-should-you-do-on-the-e-commerce-web-app)
| 175   | [You are developing a web app that uses Microsoft Entra ID for authentication. You want to configure the web app to use multifactor authentication. What should you do?](#you-are-developing-a-web-app-that-uses-microsoft-entra-id-for-authentication-you-want-to-configure-the-web-app-to-use-multifactor-authentication-what-should-you-do)
| 176   | [You are creating an Azure key vault using PowerShell. Objects deleted from the key vault must be kept for a set period of 90 days. Which two of the following parameters must be used in conjunction to meet the requirement? (Choose two.)](#you-are-creating-an-azure-key-vault-using-powershell-objects-deleted-from-the-key-vault-must-be-kept-for-a-set-period-of-90-days-which-two-of-the-following-parameters-must-be-used-in-conjunction-to-meet-the-requirement-choose-two)
| 177   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Azure Key Vault. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-azure-key-vault-does-the-solution-meet-the-goal)
| 178   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Identity Protection. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-microsoft-entra-id-identity-protection-does-the-solution-meet-the-goal)
| 179   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Privileged Identity Management. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-microsoft-entra-id-privileged-identity-management-does-the-solution-meet-the-goal)
| 180   | [You manage an Azure SQL database that allows for Microsoft Entra ID authentication. You need to make sure that database developers can connect to the SQL database via Microsoft SQL Server Management Studio (SSMS). You also need to make sure the developers use their on-premises Active Directory account for authentication. Your strategy should allow for authentication prompts to be kept to a minimum. Which of the following should you implement?](#you-manage-an-azure-sql-database-that-allows-for-microsoft-entra-id-authentication-you-need-to-make-sure-that-database-developers-can-connect-to-the-sql-database-via-microsoft-sql-server-management-studio-ssms-you-also-need-to-make-sure-the-developers-use-their-on-premises-active-directory-account-for-authentication-your-strategy-should-allow-for-authentication-prompts-to-be-kept-to-a-minimum-which-of-the-following-should-you-implement)
| 181   | [You are developing an application to transfer data between on-premises file servers and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault and makes use of the Azure Key Vault APIs. You want to configure the application to allow recovery of an accidental deletion of the key vault or key vault objects for 90 days after deletion. What should you do?](#you-are-developing-an-application-to-transfer-data-between-on-premises-file-servers-and-azure-blob-storage-the-application-stores-keys-secrets-and-certificates-in-azure-key-vault-and-makes-use-of-the-azure-key-vault-apis-you-want-to-configure-the-application-to-allow-recovery-of-an-accidental-deletion-of-the-key-vault-or-key-vault-objects-for-90-days-after-deletion-what-should-you-do)
| 182   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of Azure Redis Cache in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-azure-redis-cache-in-your-design-does-the-solution-meet-the-goal)
| 183   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of an Azure Content Delivery Network (CDN) in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-an-azure-content-delivery-network-cdn-in-your-design-does-the-solution-meet-the-goal)
| 184   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of a Storage Area Network (SAN) in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-a-storage-area-network-san-in-your-design-does-the-solution-meet-the-goal)
| 185   | [You develop a Web App on a tier D1 app service plan. You notice that page load times increase during periods of peak traffic. You want to implement automatic scaling when CPU load is above 80 percent. Your solution must minimize costs. What should you do first?](#you-develop-a-web-app-on-a-tier-d1-app-service-plan-you-notice-that-page-load-times-increase-during-periods-of-peak-traffic-you-want-to-implement-automatic-scaling-when-cpu-load-is-above-80-percent-your-solution-must-minimize-costs-what-should-you-do-first)
| 186   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the Azure resource. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-basic-gateway-credentials-for-the-azure-resource-does-the-solution-meet-the-goal)
| 187   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-client-cert-gateway-credentials-for-the-https-endpoint-does-the-solution-meet-the-goal)
| 188   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-basic-gateway-credentials-for-the-https-endpoint-does-the-solution-meet-the-goal)
| 189   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the Azure resource. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-client-cert-gateway-credentials-for-the-azure-resource-does-the-solution-meet-the-goal)
| 190   | [You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation venues. You want the application to list holiday accommodation venues that fall within a specific price range and are within a specified distance to an airport. What should you do?](#you-are-developing-a-net-core-mvc-application-that-allows-customers-to-research-independent-holiday-accommodation-providers-you-want-to-implement-azure-search-to-allow-the-application-to-search-the-index-by-using-various-criteria-to-locate-documents-related-to-accommodation-venues-you-want-the-application-to-list-holiday-accommodation-venues-that-fall-within-a-specific-price-range-and-are-within-a-specified-distance-to-an-airport-what-should-you-do)
| 191   | [You are a developer at your company. You need to edit the workflows for an existing Logic App. What should you use?](#you-are-a-developer-at-your-company-you-need-to-edit-the-workflows-for-an-existing-logic-app-what-should-you-use)
| 192   | [You are developing an application that applies a set of governance policies for internal and external services, as well as for applications. You develop a stateful ASP.NET Core 2.1 web application named `PolicyApp` and deploy it to an Azure App Service Web App. The `PolicyApp` reacts to events from Azure Event Grid and performs policy actions based on those events. You have the following requirements: Authentication events must be used to monitor users when they sign in and sign out. All authentication events must be processed by `PolicyApp`. Sign outs must be processed as fast as possible. What should you do?](#you-are-developing-an-application-that-applies-a-set-of-governance-policies-for-internal-and-external-services-as-well-as-for-applications-you-develop-a-stateful-aspnet-core-21-web-application-named-policyapp-and-deploy-it-to-an-azure-app-service-web-app-the-policyapp-reacts-to-events-from-azure-event-grid-and-performs-policy-actions-based-on-those-events-you-have-the-following-requirements-authentication-events-must-be-used-to-monitor-users-when-they-sign-in-and-sign-out-all-authentication-events-must-be-processed-by-policyapp-sign-outs-must-be-processed-as-fast-as-possible-what-should-you-do)
| 193   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM09 to ensure that users can review content using ContentAnalysisService. How should you complete the code?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-code-at-line-am09-to-ensure-that-users-can-review-content-using-contentanalysisservice-how-should-you-complete-the-code)
| 194   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM10 of the application manifest to ensure that the requirement for manually reviewing content can be met. How should you complete the code?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-code-at-line-am10-of-the-application-manifest-to-ensure-that-the-requirement-for-manually-reviewing-content-can-be-met-how-should-you-complete-the-code)
| 195   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that network security policies are met. How should you configure network security?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-ensure-that-network-security-policies-are-met-how-should-you-configure-network-security)
| 196   | [You are building a website to access project data related to teams within your organization. The website does not allow anonymous access. Authentication is performed using an Microsoft Entra ID app named internal. The website has the following authentication requirements: Microsoft Entra ID users must be able to login to the website. Personalization of the website must be based on membership in Active Directory groups. You need to configure the application's manifest to meet the authentication requirements. How should you configure the manifest?](#you-are-building-a-website-to-access-project-data-related-to-teams-within-your-organization-the-website-does-not-allow-anonymous-access-authentication-is-performed-using-an-microsoft-entra-id-app-named-internal-the-website-has-the-following-authentication-requirements-microsoft-entra-id-users-must-be-able-to-login-to-the-website-personalization-of-the-website-must-be-based-on-membership-in-active-directory-groups-you-need-to-configure-the-applications-manifest-to-meet-the-authentication-requirements-how-should-you-configure-the-manifest)
| 197   | [You are developing an Azure solution. You need to develop code to access a secret stored in Azure Key Vault. How should you complete the code segment?](#you-are-developing-an-azure-solution-you-need-to-develop-code-to-access-a-secret-stored-in-azure-key-vault-how-should-you-complete-the-code-segment)
| 198   | [You are developing a web application that makes calls to the Microsoft Graph API. You register the application in the Azure portal and upload a valid `X509` certificate. You create an appsettings.json file containing the certificate name, client identifier for the application, and the tenant identifier of the Microsoft Entra ID. You create a method named `ReadCertificate` to return the `X509` certificate by name. You need to implement code that acquires a token by using the certificate. How should you complete the code segment?](#you-are-developing-a-web-application-that-makes-calls-to-the-microsoft-graph-api-you-register-the-application-in-the-azure-portal-and-upload-a-valid-x509-certificate-you-create-an-appsettingsjson-file-containing-the-certificate-name-client-identifier-for-the-application-and-the-tenant-identifier-of-the-microsoft-entra-id-you-create-a-method-named-readcertificate-to-return-the-x509-certificate-by-name-you-need-to-implement-code-that-acquires-a-token-by-using-the-certificate-how-should-you-complete-the-code-segment)
| 199   | [You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server. You need to ensure that dependency tracking works for calls to the third-party database. Which two dependency telemetry properties should you use?](#you-are-developing-an-aspnet-core-web-api-web-service-the-web-service-uses-azure-application-insights-for-all-telemetry-and-dependency-tracking-the-web-service-reads-and-writes-data-to-a-database-other-than-microsoft-sql-server-you-need-to-ensure-that-dependency-tracking-works-for-calls-to-the-third-party-database-which-two-dependency-telemetry-properties-should-you-use)
| 200   | [You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`. All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node. You need to configure Azure CDN caching rules. Which options should you use?](#you-are-developing-an-azure-app-service-hosted-aspnet-core-web-app-to-deliver-video-on-demand-streaming-media-you-enable-an-azure-content-delivery-network-cdn-standard-for-the-web-endpoint-customer-videos-are-downloaded-from-the-web-app-by-using-the-following-example-url-httpwwwcontosocomcontentmp4quality1-all-media-content-must-expire-from-the-cache-after-one-hour-customer-videos-with-varying-quality-must-be-delivered-to-the-closest-regional-point-of-presence-pop-node-you-need-to-configure-azure-cdn-caching-rules-which-options-should-you-use)
| 201   | [You develop a web app that uses tier D1 app service plan by using the Web Apps feature of Microsoft Azure App Service. Spikes in traffic have caused increases in page load times. You need to ensure that the web app automatically scales when CPU load is about 85 percent and minimize costs. Which four actions should you perform in sequence?](#you-develop-a-web-app-that-uses-tier-d1-app-service-plan-by-using-the-web-apps-feature-of-microsoft-azure-app-service-spikes-in-traffic-have-caused-increases-in-page-load-times-you-need-to-ensure-that-the-web-app-automatically-scales-when-cpu-load-is-about-85-percent-and-minimize-costs-which-four-actions-should-you-perform-in-sequence)
| 202   | [A company backs up all manufacturing data to Azure Blob Storage. Admins move blobs from hot storage to archive tier storage every month. You must automatically move blobs to Archive tier after they have not been modified within 180 days. The path for any item that is not archived must be placed in an existing queue. This operation must be performed automatically once a month. You set the value of TierAgeInDays to -180. How should you configure the Logic App?](#a-company-backs-up-all-manufacturing-data-to-azure-blob-storage-admins-move-blobs-from-hot-storage-to-archive-tier-storage-every-month-you-must-automatically-move-blobs-to-archive-tier-after-they-have-not-been-modified-within-180-days-the-path-for-any-item-that-is-not-archived-must-be-placed-in-an-existing-queue-this-operation-must-be-performed-automatically-once-a-month-you-set-the-value-of-tierageindays-to--180-how-should-you-configure-the-logic-app)
| 203   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 1: The minimum throughput for the container is 400 R/Us.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-1-the-minimum-throughput-for-the-container-is-400-rus)
| 204   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 2: The first query statement is an in-partition query.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-2-the-first-query-statement-is-an-in-partition-query)
| 205   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 3: The second query statement is a cross-partition query.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-3-the-second-query-statement-is-a-cross-partition-query)
| 206   | [Your Microsoft Entra ID tenant has an Azure subscription linked to it. Your developer has created a mobile application that obtains Microsoft Entra ID access tokens using the OAuth 2 implicit grant type. The mobile application must be registered in Microsoft Entra ID. You require [a redirect URI] from the developer for registration purposes.](#your-microsoft-entra-id-tenant-has-an-azure-subscription-linked-to-it-your-developer-has-created-a-mobile-application-that-obtains-microsoft-entra-id-access-tokens-using-the-oauth-2-implicit-grant-type-the-mobile-application-must-be-registered-in-microsoft-entra-id-you-require-a-redirect-uri-from-the-developer-for-registration-purposes)
| 207   | [You develop an ASP.NET Core MVC application. You configure the application to track webpages and custom events. You need to identify trends in application usage. Which Azure Application Insights Usage Analysis features should you use?](#you-develop-an-aspnet-core-mvc-application-you-configure-the-application-to-track-webpages-and-custom-events-you-need-to-identify-trends-in-application-usage-which-azure-application-insights-usage-analysis-features-should-you-use)
| 208   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 1: Block blobs prefixed with container1/salesorders or container2/inventory which have not been modified in over 60 days are moved to cool storage. Blobs that have not been modified in 120 days are moved to the archive tier.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-1-block-blobs-prefixed-with-container1salesorders-or-container2inventory-which-have-not-been-modified-in-over-60-days-are-moved-to-cool-storage-blobs-that-have-not-been-modified-in-120-days-are-moved-to-the-archive-tier)
| 209   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 2: Blobs are moved to cool storage if they have not been accessed for 30 days.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-2-blobs-are-moved-to-cool-storage-if-they-have-not-been-accessed-for-30-days)
| 210   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 3: Blobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-3-blobs-will-automatically-be-tiered-from-cool-back-to-hot-if-accessed-again-after-being-tiered-to-cool)
| 211   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 4: All block blobs older than 730 days will be deleted.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-4-all-block-blobs-older-than-730-days-will-be-deleted)
| 212   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to store the user agreements. Where should you store the agreement after it is completed?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-store-the-user-agreements-where-should-you-store-the-agreement-after-it-is-completed)
| 213   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to monitor `ContentUploadService` according to the requirements. Which command should you use?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-monitor-contentuploadservice-according-to-the-requirements-which-command-should-you-use)
| 214   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to investigate the http server log output to resolve the issue with the `ContentUploadService`. Which command should you use first?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-investigate-the-http-server-log-output-to-resolve-the-issue-with-the-contentuploadservice-which-command-should-you-use-first)
| 215   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to implement the bindings for the CheckUserContent function. How should you complete the code segment?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-implement-the-bindings-for-the-checkusercontent-function-how-should-you-complete-the-code-segment)
| 216   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add markup at line AM04 to implement the ContentReview role. How should you complete the markup?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-markup-at-line-am04-to-implement-the-contentreview-role-how-should-you-complete-the-markup)
| 217   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add YAML markup at line CS17 to ensure that the `ContentUploadService` can access Azure Storage access keys. How should you complete the YAML markup?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-yaml-markup-at-line-cs17-to-ensure-that-the-contentuploadservice-can-access-azure-storage-access-keys-how-should-you-complete-the-yaml-markup)
| 218   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to deploy the CheckUserContent Azure Function. The solution must meet the security and cost requirements. Which hosting model should you use?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-deploy-the-checkusercontent-azure-function-the-solution-must-meet-the-security-and-cost-requirements-which-hosting-model-should-you-use)
| 219   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that validation testing is triggered per the requirements. How should you complete the code segment?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-ensure-that-validation-testing-is-triggered-per-the-requirements-how-should-you-complete-the-code-segment)
| 220   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to configure the `ContentUploadService` deployment. Which two actions should you perform?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-configure-the-contentuploadservice-deployment-which-two-actions-should-you-perform)

### You are implementing a software as a service (SaaS) ASP.NET Core web service that will run as an Azure Web App. The web service will use an on-premises SQL Server database for storage. The web service also includes a WebJob that processes data updates. Four customers will use the web service. Each instance of the WebJob processes data for a single customer and must run as a singleton instance. Each deployment must be tested by using deployment slots prior to serving production data. Azure costs must be minimized. Azure resources must be located in an isolated network. You need to configure the App Service plan for the Web App. How should you configure the App Service plan?

![Question 1](images/question1.jpeg)

- [ ] Number of VM instances: 2. Pricing tier: Isolated.
- [ ] Number of VM instances: 8. Pricing tier: Standard.
- [ ] Number of VM instances: 16. Pricing tier: Premium.
- [x] Number of VM instances: 4. Pricing tier: Isolated.
- [ ] Number of VM instances: 4. Pricing tier: Consumption.

> App Service tier plan
>
> | 层级                       | 自动扩展能力（含实例上限）        | 部署槽支持         | 备份   | VNet 集成支持                   | 关键特性补充说明                         |
> | -------------------------- | --------------------------------- | ------------------ | ------ | ------------------------------- | ---------------------------------------- |
> | **Free (F1)**              | ❌ 不支持（每天 60 分钟 CPU 限制） | ❌ 不支持           | ❌ 无   | ❌ 无                            | 无法绑定自定义域名，仅用于学习测试       |
> | **Shared (D1)**            | ❌ 不支持（固定资源，低优先）      | ❌ 不支持           | ❌ 无   | ❌ 无                            | 与他人共享资源，功能受限                 |
> | **Basic (B1~B3)**          | ✅ 支持（最多 3 实例）             | ❌ 不支持           | ✅ 支持 | ❌ 无                            | 支持自定义域名与 SSL                     |
> | **Standard (S1~S3)**       | ✅ 支持（最多 10 实例）            | ✅ 支持最多 5 个槽  | ✅ 支持 | ✅ 支持基础集成                  | 适合中等流量应用，性价比高               |
> | **Premium v2 (P1v2~P3v2)** | ✅ 支持（最多 20 实例）            | ✅ 支持最多 20 个槽 | ✅ 支持 | ✅ 强化集成                      | 更高性能、更大内存、SSD 存储             |
> | **Premium v3 (P1v3~P3v3)** | ✅ 支持（最多 30+ 实例）           | ✅ 支持最多 30 个槽 | ✅ 支持 | ✅ 支持 Zone 冗余                | 高性能与企业级功能，推荐生产使用         |
> | **Isolated (I1~I3)**       | ✅ 支持（最多 100 实例）           | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ App Service Environment (ASE) | 网络完全隔离，适合高合规需求             |
> | **Isolated v2**            | ✅ 支持（最多 100 实例，按需扩展） | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ ASEv3，支持私有 IP            | 最强隔离性与性能，适合大型企业或政府项目 |

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for a software as a service (SaaS) company that uses an Azure Function to process orders. The Azure Function currently runs on an Azure Function app that is triggered by an Azure Storage queue. You are preparing to migrate the Azure Function to Kubernetes using Kubernetes-based Event Driven Autoscaling (KEDA). You need to configure Kubernetes Custom Resource Definitions (CRD) for the Azure Function. Which CRDs should you configure?

![Question 2](images/question2.jpeg)

- [x] Box 1, CRD type: Deployment. Box 2, CRD type: ScaledObject. Box 3, CRD type: Secret.
- [ ] Box 1, CRD type: Secret. Box 2, CRD type: ScaledObject. Box 3, CRD type: Secret.
- [ ] Box 1, CRD type: TriggerAuthentication. Box 2, CRD type: Deployment. Box 3, CRD type: Secret.
- [ ] Box 1, CRD type: Deployment. Box 2, CRD type: ScaledObject. Box 3, CRD type: TriggerAuthentication.

> ## 1️⃣ 什么是 CRD
>
> - **CRD** 是 **Kubernetes** 的一种扩展机制，全称 **Custom Resource Definition**（自定义资源定义）。
> - 作用：
>   - 允许你在 Kubernetes 里定义一种**新的 API 对象类型**，像内置的 `Pod`、`Service` 一样被管理。
>   - 定义完后，就可以用 `kubectl get/describe/apply` 来操作这种资源。
> - 本质上：
>   - 它是在 Kubernetes API Server 中注册一个新的 **资源类型**。
>   - 然后你就能用 YAML 来创建这种资源实例（Custom Resource, CR）。
>
> 正确答案是：
>
> **✅ Box 1 → Deployment**（Azure Function code）
>
> - Azure Function 在 Kubernetes 上会作为容器运行，通常通过 **Deployment** 来定义它的 Pod 及副本数，所以 Function 代码会在 Deployment 的镜像里。
>
> **✅ Box 2 → ScaledObject**（Polling interval）
>
> - Polling interval（轮询间隔）是 **KEDA ScaledObject** 中的一个配置字段，用来定义多长时间检查一次事件源。
>
> - `spec.pollingInterval` 用在 **ScaledObject**对伸缩行为的影响：
>
>   **0 → 1 扩容**：当应用副本数是 0 时，KEDA 会按 `pollingInterval` 频率去轮询事件源，一旦检测到条件满足，就启动第 1 个 Pod。
>
>   **1 → N 扩容**：副本数大于等于 1 时，扩容主要由 Kubernetes 的 HPA（Horizontal Pod Autoscaler）机制触发，但数据仍来自 KEDA 的 metrics server。
>
>   因此 `pollingInterval` 主要影响 **冷启动（0→1）** 和事件检测频率。
>
> **✅ Box 3 → Secret**（Azure Storage connection string）
>
> - Azure Storage 连接字符串是敏感信息，应该存放在 Kubernetes **Secret** 中，然后供 ScaledObject 或 TriggerAuthentication 引用。

**[⬆ Back to Top](#table-of-contents)**

### You are creating a CLI script that creates an Azure web app and related services in Azure App Service. The web app uses the following variables. You need to automatically deploy code from GitHub to the newly created web app. How should you complete the script?

![Question 3 part 1](images/question3_1.png)
![Question 3 part 2](images/question3_2.jpeg)

- [ ] Box 1: `az webapp`. Box 2: `az webapp create`. Box 3: `git clone $gitrepo`. Box 4: `az webapp`. Box 5: `--plan $webappname`.
- [x] Box 1: `az appservice plan create`. Box 2: `az webapp create`. Box 3: `--plan $webappname`. Box 4: `az webapp deployment`. Box 5: `--repo-url $gitrepo --branch master --manual-integration.`
- [ ] Box 1: `az appservice plan create`. Box 2: `az webapp deployment`. Box 3: `--plan $webappname`. Box 4: `az webapp deployment`. Box 5: `--repo-url $gitrepo --branch master --manual-integration.`
- [ ] Box 1: `az group delete`. Box 2: `az webapp create`. Box 3: `git clone $gitrepo`. Box 4: `az appservice plan create`. Box 5: `git clone $gitrepo`.

> 1. 创建资源组（如果需要）
>
>    ```
>    az group create --name myResourceGroup --location japaneast
>    ```
>
> 2. 创建 App Service Plan
>
>    ```
>    az appservice plan create --name myAppServicePlan --resource-group myResourceGroup --sku B1 --is-linux
>    ```
>
> 3. 创建 Web App（附带部署源）
>
>    ```
>    az webapp create --resource-group myResourceGroup --plan myAppServicePlan \
>      --name my-webapp-name --runtime "NODE|18-lts" \
>      --deployment-source-url https://github.com/your-username/your-repo.git
>    ```
>
> 4. （可选）设置 GitHub Actions 自动部署
>
>    ```
>    az webapp deployment source config \
>      --name my-webapp-name \
>      --resource-group myResourceGroup \
>      --repo-url https://github.com/your-username/your-repo.git \
>      --branch main \
>      --manual-integration
>    ```
>
>    =>也可设置`--manual-integration` 参数，**不启用自动同步 / CI（Continuous Integration）**。
>
>    =>`az webapp deployment slot` 是 Azure CLI 里用于管理 **Azure App Service 部署槽（Deployment Slots）** 的命令组。如
>
>    ```
>    az webapp deployment slot create \
>      --name mywebapp \
>      --resource-group myResourceGroup \
>      --slot staging
>    ```

**[⬆ Back to Top](#table-of-contents)**

### You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Trigger the photo processing from Blob storage events. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **需求重点**
>
> - 必须在照片上传完成 **1 分钟内** 启动图片处理流程。
> - 关键是 **触发机制**（如何知道文件已上传），而不是存储账户类型。
>
> **方案：Blob Storage 事件触发**
>
> - **Azure Blob Storage** 支持通过 **Event Grid** 或 **Azure Functions Blob Trigger** 在对象创建/更新时发送事件。
> - 事件触发是实时的，延迟通常在秒级（远小于 1 分钟）。
> - 可以直接触发处理逻辑（如 Azure Function、Logic App、Azure Container Instance）。
>
> **满足需求**
>
> - **延迟**：Blob Storage → Event Grid → Function 触发，通常 < 1 秒~几秒。
> - **简单实现**：不需要轮询或定时器，节省资源和成本。
>
> =>Yes

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the web.config file to include the applicationInitialization configuration element. Specify custom initialization actions to run the scripts. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 为确保在 **Azure App Service 的部署槽（deployment slots）自动交换（auto swap）之前**执行脚本并确保资源准备就绪，你需要使用 **deployment slot settings** 中的 **预热（warm-up）机制**，特别是：
>
> 要确保 auto swap 之前脚本执行、资源可用，应通过设置 **`applicationInitialization`** 在**web.config**中配置 warm-up endpoint，Azure 会在正式交换前调用它，确保 app 已准备好。
>
> Auto Swap 的工作机制：将代码部署到一个Testing Slot, 部署成功后，去确保 `Production` 槽上启用了 Auto Swap，然后进行自动从 Testing 接收代码 =>也就是说 auto swap 不应该部署到Testing Slot

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Enable auto swap for the Testing slot. Deploy the app to the Testing slot. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **auto swap 不是给源槽启用，而是给目标槽启用的。**
>
> 如果你给 Testing 启用 auto swap，表示的是“部署到其他槽时，自动交换到 Testing”，这不是你想要的场景。
>
> 你的目标是部署到 Testing，然后自动交换到 Production，所以 **auto swap 应该启用在 Production 上**。
>
> 你题目里说已经给 Production 启用 auto swap，这才是正确的做法。

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Disable auto swap. Update the app with a method named `statuscheck` to run the scripts. Re-enable auto swap and deploy the app to the Production slot. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **auto swap 的机制是：**
>
> - 你把新版本部署到非生产槽（比如 Testing），app 会先在该槽启动、预热。
> - 预热完成后，系统自动将非生产槽与生产槽交换。
> - 这样确保生产槽始终是已经预热好的版本。
>
> **但是方案中直接部署到 Production 槽，并且重新启用 auto swap，没有使用其他槽来做预热**。
>
> 这样：
>
> - 关闭 auto swap 后，部署到 Production，应用会直接运行生产环境。
> - 即使有 `statuscheck`，你也需要手动调用确认是否预热完成。
> - 重新启用 auto swap 并不会对当前部署起作用（auto swap 只有当部署到非生产槽时才触发）。
> - 因此**脚本的运行时机与交换时机没有关联**，并不能保证“交换前脚本执行完成”。

**[⬆ Back to Top](#table-of-contents)**

### You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Convert the Azure Storage account to a BlockBlobStorage storage account. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ## 具体 Storage Account 类型（在 CLI 中用 `--sku` 指定）
>
> | 类型名                         | 说明                               | 支持的服务               | 用途                         |
> | ------------------------------ | ---------------------------------- | ------------------------ | ---------------------------- |
> | **Storage (GPv1)**             | 旧版通用账户，已不推荐使用         | Blob, File, Queue, Table | 向后兼容场景                 |
> | **StorageV2 (GPv2)**           | 推荐的通用账户类型                 | Blob, File, Queue, Table | Web应用、备份、归档等        |
> | **BlobStorage**                | 专用于 Blob 服务                   | Blob                     | 适合冷数据访问分层管理       |
> | **BlockBlobStorage**           | 高性能 Blob                        | Blob                     | 数据湖、媒体处理、高性能场景 |
> | **FileStorage**                | 高性能文件共享                     | File                     | 替代 NAS 的场景              |
> | **Premium_ZRS**                | Zone-redundant 高可用 Premium 存储 | Blob, File（部分支持）   | 高可用与性能并存场景         |
> | **BlockBlobStorage + Premium** | SSD 支持的高性能 Blob 存储         | Blob                     | 延迟敏感的大文件上传等       |

> StorageV2 是通用型存储账户，基于 HDD，支持 Block Blob、Append Blob、Page Blob、Queue、Table 和 File 等多种服务及冷热归档层，而 **BlockBlobStorage** 是基于 SSD 的高级账户，仅支持块 Blob，专为高吞吐低延迟场景设计。

> ❌ **No — 这个方案不满足要求**。
>
> ------
>
> ### 原因分析
>
> 1. **需求重点**
>    - 必须在照片上传完成 **1 分钟内** 启动图片处理流程。
>    - 关键是 **触发机制**（如何知道文件已上传），而不是存储账户类型。
> 2. **方案问题**
>    - 将 General-purpose v2 转成 **BlockBlobStorage** 只是更改了存储账户性能类型（优化了低延迟、高吞吐量的块 blob 存储）。
>    - 它不会自动带来文件上传后的**事件触发功能**。
>    - 没有配置 **Blob Storage events**（Event Grid / Blob Trigger），处理流程不会自动启动。
> 3. **正确方向**
>    - 保持 GPv2 或 BlockBlobStorage 都可以，但必须结合 **Blob Storage Events** 或 **Azure Function Blob Trigger** 来实现实时触发。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Web App. You configure TLS mutual authentication for the web app. You need to validate the client certificate in the web app.

![Question 9](images/question9.jpeg)

- [ ] Client certificate location: Client cookie. Encoding type: URL.
- [ ] Client certificate location: HTTP message body. Encoding type: Base64.
- [ ] Client certificate location: HTTP request header. Encoding type: Unicode.
- [x] Client certificate location: HTTP request header. Encoding type: Base64.

> 在 **Azure Web App** 中启用并验证客户端证书（TLS Mutual Authentication），你需要进行以下配置，
>
> 1️⃣ **Client certificate location（客户端证书位置）**
>
> 客户端证书被解码后作为一个 **请求头（HTTP header）`X-ARR-ClientCert`** 传递。
>
> ```
> GET /api/photo HTTP/1.1
> Host: myapp.azurewebsites.net
> User-Agent: Mozilla/5.0
> Accept: application/json
> X-ARR-ClientCert: MIIDXTCCAkWgAwIBAgIJANzY82+H5CeqMA0GCSqGSIb3DQEBCwUAMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDAq3YJkYbXB0MRcwFQYDVQQKDA5NeSBDb21wYW55IEx0ZDAeFw0xOTA3MjcxMzQyMjRaFw0yOTA3MjQxMzQyMjRaMEUxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDAq3YJkYbXB0MRcwFQYDVQQKDA5NeSBDb21wYW55IEx0ZDCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAsU9lg==
> ```
>
> ### 2️⃣ **Encoding type（编码类型）**
>
> > 客户端证书是以 **Base64 编码的 X.509 格式字符串** 传递的。
>
> 因为Azure Web App **不会自动拒绝未通过验证的客户端证书**，你必须**在代码中处理验证逻辑**。这个代码指的是你Azure Web Application的代码！Azure向客户端请求CA证书，然后把它标为X-ARR-ClientCert转给Web App代码去处理

**[⬆ Back to Top](#table-of-contents)**

### You are developing a Docker/Go using Azure App Service Web App for Containers. You plan to run the container in an App Service on Linux. You identify a Docker container image to use. None of your current resource groups reside in a location that supports Linux. You must minimize the number of resource groups required. You need to create the application and perform an initial deployment. Which three Azure CLI commands should you use to develop the solution?

![Question 10](images/question10.png)

- [ ] Box 1: `az webapp create`. Box 2: `az appservice plan create`. Box 3: `az group create`.
- [ ] Box 1: `az appservice plan create`. Box 2: `az group create`. Box 3: `az group update`.
- [x] Box 1: `az group create`. Box 2: `az appservice plan create`. Box 3: `az webapp create`.
- [ ] Box 1: `az appservice plan create`. Box 2: `az webapp create`. Box 3: `az webapp update`.

**[⬆ Back to Top](#table-of-contents)**

### Fourth Coffee has an ASP.NET Core web app that runs in Docker. The app is mapped to the `www.fourthcoffee.com` domain. Fourth Coffee is migrating this application to Azure. You need to provision an App Service Web App to host this docker image and map the custom domain to the App Service web app. A resource group named `FourthCoffeePublicWebResourceGroup` has been created in the WestUS region that contains an App Service Plan named `AppServiceLinuxDockerPlan`. Which order should the CLI commands be used to develop the solution?

![Question 11](images/question11.jpeg)

- [x] Box 1: `#/bin/bash appName='FourthCoffeePublicWeb$random' location='WestUS' dockerHubContainerPath='FourthCoffee/publicweb:v1' fqdn='http://www.fourthcoffee.com'>www.fourthcoffee.com`. Box 2: `az webapp create --name $appName --plan AppServiceLinuxDockerPlan --resource-group fourthCoffeePublicWebResourceGroup`. Box 3: `az webapp config container set --docker-custom-image-name $dockerHubContainerPath --name $appName --resource-group fourthCoffeePublicWebResourceGroup`. Box 4: `az webapp config hostname add --webapp-name $appName --resource-group fourthCoffeePublicWebResourceGroup --hostname $fqdn`.
- [ ] Box 1: `#/bin/bash appName='FourthCoffeePublicWeb$random' location='WestUS' dockerHubContainerPath='FourthCoffee/publicweb:v1' fqdn='http://www.fourthcoffee.com'>www.fourthcoffee.com`. Box 2: `az webapp create --name $appName --plan AppServiceLinuxDockerPlan --resource-group fourthCoffeePublicWebResourceGroup`. Box 3: `az webapp config hostname add --webapp-name $appName --resource-group fourthCoffeePublicWebResourceGroup --hostname $fqdn`. Box 4: `az webapp config container set --docker-custom-image-name $dockerHubContainerPath --name $appName --resource-group fourthCoffeePublicWebResourceGroup`.
- [ ] Box 1: `az webapp config container set --docker-custom-image-name $dockerHubContainerPath --name $appName --resource-group fourthCoffeePublicWebResourceGroup`. Box 2: `az webapp create --name $appName --plan AppServiceLinuxDockerPlan --resource-group fourthCoffeePublicWebResourceGroup`. Box 3: `az webapp config hostname add --webapp-name $appName --resource-group fourthCoffeePublicWebResourceGroup --hostname $fqdn`. Box 4: `#/bin/bash appName='FourthCoffeePublicWeb$random' location='WestUS' dockerHubContainerPath='FourthCoffee/publicweb:v1' fqdn='http://www.fourthcoffee.com'>www.fourthcoffee.com`.
- [ ] Box 1: `az webapp config hostname add --webapp-name $appName --resource-group fourthCoffeePublicWebResourceGroup --hostname $fqdn`. Box 2: `az webapp create --name $appName --plan AppServiceLinuxDockerPlan --resource-group fourthCoffeePublicWebResourceGroup`. Box 3: `#/bin/bash appName='FourthCoffeePublicWeb$random' location='WestUS' dockerHubContainerPath='FourthCoffee/publicweb:v1' fqdn='http://www.fourthcoffee.com'>www.fourthcoffee.com`. Box 4: `az webapp config container set --docker-custom-image-name $dockerHubContainerPath --name $appName --resource-group fourthCoffeePublicWebResourceGroup`.

> 将一个ASP.NET Core Web 应用（基于 Docker）迁移到 Azure，并通过自定义域名（如 `www.fourthcoffee.com`）访问，你可以写一个shell脚本
>
> ```
> #!/bin/bash
> 
> # 1. 创建 Web App（已存在可以略过）
> az webapp create \
> --resource-group FourthCoffeePublicWebResourceGroup \
> --plan AppServiceLinuxDockerPlan \
> --name fourthcoffee-webapp \
> --deployment-container-image-name fourthcoffee/webapp:latest
> 
> # 2. 配置 Docker Hub 镜像（等价于 dockerHubContainerPath）
> az webapp config container set \
> --name fourthcoffee-webapp \
> --resource-group FourthCoffeePublicWebResourceGroup \
> --docker-custom-image-name fourthcoffee/webapp:latest \
> --docker-registry-server-url https://index.docker.io
> 
> # 3. 添加自定义域名
> az webapp config hostname add \
> --webapp-name fourthcoffee-webapp \
> --resource-group FourthCoffeePublicWebResourceGroup \
> --hostname www.fourthcoffee.com
> ```
>
> ### 使用建议
>
> - 通常先确保应用本身部署正常（即容器配置完成，应用可访问）。
> - 再做域名绑定和 SSL 等配置，这样域名访问才不会出现404或异常。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a serverless Java application on Azure. You create a new Azure Key Vault to work with secrets from a new Azure Functions application. The application must meet the following requirements: Reference the Azure Key Vault without requiring any changes to the Java code. Dynamically add and remove instances of the Azure Functions host based on the number of incoming application events. Ensure that instances are perpetually warm to avoid any cold starts. Connect to a VNet. Authentication to the Azure Key Vault instance must be removed if the Azure Function application is deleted. You need to grant the Azure Functions application access to the Azure Key Vault. Which three actions should you perform in sequence?

![Question 12](images/question12.png)

- [ ] Box 1: Create the Azure Functions app with a Consumption plan type. Box 2: Create an access policy in Azure Key Vault for the application identity. Box 3: Create a user-assigned managed identity for the application.
- [x] Box 1: Create the Azure Functions app with a Premium plan type. Box 2: Create a system-assigned managed identity for the application. Box 3: Create an access policy in Azure Key Vault for the application identity.
- [ ] Box 1: Create the Azure Functions app with a Consumption plan type. Box 2: Create a user-assigned managed identity for the application. Box 3: Create an access policy in Azure Key Vault for the application identity.
- [ ] Box 1: Create the Azure Functions app with a Premium plan type. Box 2: Create a user-assigned managed identity for the application. Box 3: Create an access policy in Azure Key Vault for the application identity.

> Azure Functions 各种托管计划:
>
> | 托管计划         | 计费方式                     | 弹性伸缩     | 冷启动 | VNET 支持 | 适用场景                                                    |
> | ---------------- | ---------------------------- | ------------ | ------ | --------- | ----------------------------------------------------------- |
> | Consumption Plan | 按执行量付费                 | 自动按需扩缩 | 有     | 不支持    | 事件驱动、低频调用、无服务器                                |
> | Premium Plan     | 按预留实例计费               | 自动按需扩缩 | 无     | 支持      | 低延迟、高性能、**VNET 集成**                               |
> | App Service Plan | 固定资源规格计费             | 手动扩缩     | 无     | 支持      | 复用现有资源、负载稳定，**仅部分 SKU 支持VNET，且性能很差** |
> | Dedicated Plan   | App Service Environment 计费 | 手动扩缩     | 无     | 支持      | 高安全隔离、企业级环境                                      |
>
> =>Premium Plan 是 **专门为 Azure Function 优化** 的运行环境，有自动 scale-out、高性能、**冷启动优化**。App Service Plan 虽然能跑 Function，但并**不建议**用它做高负载函数运行平台，**缺乏自动扩展能力**（不是真正 Serverless，因为资源是预先分配的，不按调用量计费。）。除非你已经有 App Service Plan，想复用资源。Plan 可以保持几乎热启动，需设置**Always On**，确保无冷启动
>
> =>Consumption Plan 没有冷启动优化，搞不好得10min才能启动起来
>
> =>Azure Functions 在 App Service Plan 上运行时，本质上就是在 **标准的 Azure App Service 环境** 里启动函数应用（Function App），跟普通的 Web App、API App 共享同一组计算资源（VM 或实例）。

> **用户分配的托管身份（User-assigned managed identities）** 是一种可以在多个应用之间复用权限的方式。
> 用户分配的托管身份将托管身份与新应用关联起来，不需要使用密钥或密码。
>
> **系统分配的托管身份（System-assigned managed identities）** 是为每个应用创建一个新的身份，
> 这不符合常见的配置需求（因为不能复用）。
>
> | 特性 / 维度        | 用户分配的托管身份（UAMI）                                   | 系统分配的托管身份（SAMI）                             |
> | ------------------ | ------------------------------------------------------------ | ------------------------------------------------------ |
> | **创建和生命周期** | 独立于任何具体资源创建，可以被多个资源共享。                 | 随资源创建，同时创建；资源删除时身份自动删除。         |
> | **作用域**         | 可以在多个 Azure 资源（VM、App Service、Function 等）间复用。 | 绑定到单个资源，不可跨资源共享。                       |
> | **管理复杂度**     | 需要单独管理身份资源，权限授予在身份级别管理。               | 身份随资源自动管理，无需额外维护。                     |
> | **权限复用**       | ✅ 支持，多个应用可使用同一个托管身份访问相同资源。           | ❌ 不支持，每个应用有独立身份。                         |
> | **资源删除影响**   | 身份独立，删除某个应用不影响身份存在。                       | **资源删除即删除身份，身份随资源生命周期结束。**       |
> | **典型使用场景**   | - 多个服务需要用同一身份访问同一资源- 需要集中管理权限       | - 简单应用或场景- 身份只绑定一个资源- 不需要跨应用复用 |
> | **身份更改影响**   | 独立更改身份配置，不影响已绑定的资源（需要重新绑定）         | 身份随资源变更，自动同步。                             |
> | **角色分配管理**   | 针对身份进行角色分配。                                       | 针对身份进行角色分配，但身份只能用于单一资源。         |

**[⬆ Back to Top](#table-of-contents)**

### You develop a website. You plan to host the website in Azure. You expect the website to experience high traffic volumes after it is published. You must ensure that the website remains available and responsive while minimizing cost. You need to deploy the website. What should you do?

- [ ] Deploy the website to a virtual machine. Configure the virtual machine to automatically scale when the CPU load is high.
- [ ] Deploy the website to an App Service that uses the Shared service tier. Configure the App Service plan to automatically scale when the CPU load is high.
- [ ] Deploy the website to a virtual machine. Configure a Scale Set to increase the virtual machine instance count when the CPU load is high.
- [x] Deploy the website to an App Service that uses the Standard service tier. Configure the App Service plan to automatically scale when the CPU load is high.

> App Service tier plan
>
> | 层级                       | 自动扩展能力（含实例上限）        | 部署槽支持         | 备份   | VNet 集成支持                   | 关键特性补充说明                         |
> | -------------------------- | --------------------------------- | ------------------ | ------ | ------------------------------- | ---------------------------------------- |
> | **Free (F1)**              | ❌ 不支持（每天 60 分钟 CPU 限制） | ❌ 不支持           | ❌ 无   | ❌ 无                            | 无法绑定自定义域名，仅用于学习测试       |
> | **Shared (D1)**            | ❌ 不支持（固定资源，低优先）      | ❌ 不支持           | ❌ 无   | ❌ 无                            | 与他人共享资源，功能受限                 |
> | **Basic (B1~B3)**          | ✅ 支持（最多 3 实例）             | ❌ 不支持           | ✅ 支持 | ❌ 无                            | 支持自定义域名与 SSL                     |
> | **Standard (S1~S3)**       | ✅ 支持（最多 10 实例）            | ✅ 支持最多 5 个槽  | ✅ 支持 | ✅ 支持基础集成                  | 适合中等流量应用，性价比高               |
> | **Premium v2 (P1v2~P3v2)** | ✅ 支持（最多 20 实例）            | ✅ 支持最多 20 个槽 | ✅ 支持 | ✅ 强化集成                      | 更高性能、更大内存、SSD 存储             |
> | **Premium v3 (P1v3~P3v3)** | ✅ 支持（最多 30+ 实例）           | ✅ 支持最多 30 个槽 | ✅ 支持 | ✅ 支持 Zone 冗余                | 高性能与企业级功能，推荐生产使用         |
> | **Isolated (I1~I3)**       | ✅ 支持（最多 100 实例）           | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ App Service Environment (ASE) | 网络完全隔离，适合高合规需求             |
> | **Isolated v2**            | ✅ 支持（最多 100 实例，按需扩展） | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ ASEv3，支持私有 IP            | 最强隔离性与性能，适合大型企业或政府项目 |

**[⬆ Back to Top](#table-of-contents)**

### A company is developing a Java web app. The web app code is hosted in a GitHub repository located at `https://github.com/Contoso/webapp`. The web app must be evaluated before it is moved to production. You must deploy the initial code release to a deployment slot named `staging`. You need to create the web app and deploy the code. How should you complete the commands?

![Question 14](images/question14.png)

- [x] Box 1: `group`. Box 2: `appservice plan`. Box 3: `webapp`. Box 4: `webapp deployment slot`. Box 5: `webapp deployment source`.
- [ ] Box 1: `appservice plan`. Box 2: `group`. Box 3: `webapp`. Box 4: `webapp deployment slot`. Box 5: `webapp deployment source`.
- [ ] Box 1: `webapp`. Box 2: `group`. Box 3: `webapp deployment source`. Box 4: `webapp deployment slot`. Box 5: `appservice plan`.
- [ ] Box 1: `webapp`. Box 2: `group`. Box 3: `webapp deployment source`. Box 4: `webapp deployment slot`. Box 5: `appservice plan`.

**[⬆ Back to Top](#table-of-contents)**

### You have a web service that is used to pay for food deliveries. The web service uses Azure Cosmos DB as the data store. You plan to add a new feature that allows users to set a tip amount. The new feature requires that a property named tip on the document in Cosmos DB must be present and contain a numeric value. There are many existing websites and mobile apps that use the web service that will not be updated to set the tip property for some time. How should you complete the trigger?

![Question 15](images/question15.jpeg)

- [ ] Box 1: `__value();`. Box 2: `if (request.getValue('tip') === null) {`. Box 3: `__.upsertDocument(i);`.
- [ ] Box 1: `__readDocument()('item');`. Box 2: `if (!('tip' in i)) {`. Box 3: `__.replaceDocument(i);`.
- [x] Box 1: `getContext().getRequest();`. Box 2: `if (!('tip' in i)) {`. Box 3: `r.setBody(i);`.
- [ ] Box 1: `getContext().getRequest();`. Box 2: `if (isNaN(i)['tip'] || i['tip'] === null) {`. Box 3: `r.setValue(i);`.

> 你有一个支付外卖的 **Web Service**，数据存在 **Azure Cosmos DB**。
>
> 新功能要求：每个 Cosmos DB 文档必须有一个名为 `tip` 的属性，且值是数字。
>
> 但是：现有的客户端（网站、移动端）暂时不会更新来设置这个 `tip` 属性，意味着旧文档可能没有 `tip` 字段。
>
> =>使用 Pre-trigger比较好，伪代码
>
> ```c#
> function preTrigger() {
> var context = getContext();
> var request = context.getRequest();
> var documentToCreate = request.getBody();
> 
> if (!documentToCreate.hasOwnProperty('tip') || typeof documentToCreate.tip !== 'number') {
>  documentToCreate.tip = 0;  // 默认值
> }
> 
> request.setBody(documentToCreate);
> }
> ```

**[⬆ Back to Top](#table-of-contents)**

### You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Use the Durable Function async pattern to process the blob data. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> **Durable Function 异步模式会先立即返回 HTTP 响应，告诉客户端“请求已接收”，后台再异步处理 Blob 数据。**
>
> 这样就**避免了 HTTP 超时，保证长时间处理能完成。**

**[⬆ Back to Top](#table-of-contents)**

### You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Pass the HTTP trigger payload into an Azure Service Bus queue to be processed by a queue trigger function and return an immediate HTTP success response. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Configure the app to use an App Service hosting plan and enable the Always On setting. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **只能保证函数本身不被 Azure 平台超时终止。**
>
> **不能保证调用端 HTTP 请求不超时。**

**[⬆ Back to Top](#table-of-contents)**

### You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Move photo processing to an Azure Function triggered from the blob upload. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> Azure Function Blob 触发器可以在照片上传后及时启动处理。
>
> 能确保处理流程在上传后不到 1 分钟内开始。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses Azure Blob storage. The application must read the transaction logs of all the changes that occur to the blobs and the blob metadata in the storage account for auditing purposes. The changes must be in the order in which they occurred, include only create, update, delete, and copy operations and be retained for compliance reasons. You need to process the transaction logs asynchronously. What should you do?

- [ ] Process all Azure Blob storage events by using Azure Event Grid with a subscriber Azure Function app.
- [x] Enable the change feed on the storage account and process all changes for available events.
- [ ] Process all Azure Storage Analytics logs for successful blob events.
- [ ] Use the Azure Monitor HTTP Data Collector API and scan the request body for successful blob events.

> 什么是 Azure Blob Storage 的 Change Feed？
>
> **Change Feed** 是一种 **事件日志记录机制**，用于记录对 Blob（包括 block blob 和 append blob）进行的 **创建、修改和删除等操作**。它为开发者提供了类似数据库事务日志的功能，可以 **有序追踪和读取变更历史**。
>
> Change Feed 的数据存储在特殊容器 `$blobchangefeed` 中
>
> =>非常适合 审计合规
>
> =>另外， **Azure Cosmos DB** 也提供了 **Change Feed** 功能，而且非常强大，广泛用于**实时数据处理、事件驱动架构、审计日志、增量ETL等场景**。

**[⬆ Back to Top](#table-of-contents)**

### You plan to create a Docker image that runs an ASP.NET Core application named `ContosoApp`. You have a setup script named `setupScript.ps1` and a series of application files including `ContosoApp.dll`. You need to create a Dockerfile document that meets the following requirements: Call setupScripts.ps1 when the container is built. Run `ContosoApp.dll` when the container starts. The Dockerfile document must be created in the same folder where `ContosoApp.dll` and `setupScript.ps1` are stored. Which five commands should you use to develop the solution?

![Question 21](images/question21.png)

- [ ] Box 1: `CMD ['dotnet', 'ContosoApp.dll']`. Box 2: `FROM microsoft/aspnetcore:latest`. Box 3: `RUN powershell ./setupScript.ps1`. Box 4: `WORKDIR /apps/ContosoApp`. Box 5:` COPY ./ .`.
- [ ] Box 1:` COPY ./ .`.. Box 2: `RUN powershell ./setupScript.ps1`. Box 3: `FROM microsoft/aspnetcore:latest`. Box 4: `CMD ['dotnet', 'ContosoApp.dll']`. Box 5: `WORKDIR /apps/ContosoApp`.
- [ ] Box 1: `RUN powershell ./setupScript.ps1`. Box 2: `CMD ['dotnet', 'ContosoApp.dll']`. Box 3: `FROM microsoft/aspnetcore:latest`. Box 4: `WORKDIR /apps/ContosoApp`. Box 5:` COPY ./ .`.
- [x] Box 1: `FROM microsoft/aspnetcore:latest`. Box 2: `WORKDIR /apps/ContosoApp`. Box 3:` COPY ./ .`. Box 4: `RUN powershell ./setupScript.ps1`. Box 5: `CMD ['dotnet', 'ContosoApp.dll']`.

> 以下是一个简单的 Dockerfile 示例，用于构建一个运行 Python 应用的镜像：
>
> ```dockerfile
> # 使用官方 Python 镜像作为基础镜像
> FROM python:3.8-slim
> 
> # 设置工作目录，终端默认进入的落脚点
> WORKDIR /app
> 
> # 复制当前目录内容到容器的 /app 目录
> COPY . /app
> 
> # 安装依赖
> # RUN 等同于，在终端操作的shell命令
> RUN pip install --no-cache-dir -r requirements.txt
> 
> # 暴露端口
> EXPOSE 80
> 
> # 设置环境变量
> ENV NAME World
> 
> # 运行应用
> CMD ["python", "app.py"]
> ```
>

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function App that processes images that are uploaded to an Azure Blob container. Images must be processed as quickly as possible after they are uploaded, and the solution must minimize latency. You create code to process images when the Function App is triggered. You need to configure the Function App. What should you do?

- [ ] Use an App Service plan. Configure the Function App to use an Azure Blob Storage input trigger.
- [ ] Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger.
- [ ] Use a Consumption plan. Configure the Function App to use a Timer trigger.
- [x] Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.
- [ ] Use a Consumption plan. Configure the Function App to use an Azure Blob Storage input trigger.

> Azure Blob Storage input trigger不存在

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a new development environment for a Java application. The environment requires a Virtual Machine Scale Set (VMSS), several storage accounts, and networking components. The VMSS must not be created until the storage accounts have been successfully created and an associated load balancer and virtual network is configured. How should you complete the Azure Resource Manager template?

![Question 23](images/question23.png)

- [x] Box 1: `copyIndex`. Box 2: `copy`. Box 3: `dependsOn`.
- [ ] Box 1: `copy`. Box 2: `copyIndex`. Box 3: `dependsOn`.
- [ ] Box 1: `priority`. Box 2: `dependsOn`. Box 3: `copyIndex`.
- [ ] Box 1: `priority`. Box 2: `copyIndex`. Box 3: `dependsOn`.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 1: The code will log the time that the order was processed from the queue.

![Question 24](images/question24_25_26_27.png)

- [ ] Yes.
- [x] No.

> ```C#
> public static class OrderProcessor
> {
>     // 这个函数监听名为 "incoming-orders" 的 Azure Storage Queue 队列，
>     // 当有新消息入队时触发执行。
>     [FunctionName("ProcessOrders")]
>     public static void ProcessOrders(
>         [QueueTrigger("incoming-orders")] CloudQueueMessage myQueueItem, // 绑定触发消息
>         [Table("Orders")] ICollector<Order> tableBindings,                // 绑定到 Azure Table Storage 的 Orders 表，用于插入数据
>         TraceWriter log)                                                  // 日志记录器
>     {
>         // 记录日志，打印消息的 Id
>         log.Info($"Processing Order: {myQueueItem.Id}");
>         // 这行代码是 记录了队列消息的插入时间（即消息被放入队列的时间），而不是订单被“处理”的时间。
>         log.Info($"Queue Insertion Time: {myQueueItem.InsertionTime}");
>         // 记录消息过期时间
>         log.Info($"Queue Expiration Time: {myQueueItem.ExpirationTime}");
>         
>         // 将队列消息体反序列化为 Order 对象，并添加到 Orders 表中
>         tableBindings.Add(JsonConvert.DeserializeObject<Order>(myQueueItem.AsString));
>     }
>     
>     // 这个函数监听名为 "incoming-orders-poison" 的队列，用于处理处理失败的死信消息。
>     [FunctionName("ProcessOrders-Poison")]
>     public static void ProcessFailedOrders(
>         [QueueTrigger("incoming-orders-poison")] CloudQueueMessage myQueueItem, // 监听死信队列消息
>         TraceWriter log)                                                        // 日志记录器
>     {
>         // 记录错误日志，打印处理失败的订单消息体内容
>         log.Error($"Failed to process order: {myQueueItem.AsString}");
>         
>         // 这里省略的代码通常是：
>         // - 告警通知
>         // - 记录到专门的错误表或日志存储
>         // - 进一步的补偿处理等
>         . . .
>     }
> }
> ```
>
> ### 总结
>
> - **`ProcessOrders` 函数**负责正常订单的处理：从队列读取消息，写入表存储。
> - **`ProcessOrders-Poison` 函数**负责处理死信队列中的消息（处理失败多次后进入该队列），用于错误告警和后续处理。
> - 这种设计帮助将正常流程和失败流程解耦，提高系统稳定性和可维护性。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 2: When the ProcessOrders function fails, the function will retry up to five times for a given order, including the first try.

![Question 25](images/question24_25_26_27.png)

- [x] Yes.
- [ ] No.

> ### Azure Functions 队列触发器默认重试机制：
>
> - **Azure Storage Queue 触发的 Azure Functions，有内置的重试机制。**
> - **默认行为是，如果函数执行失败，消息不会立即从队列中删除，会在可见性超时（Visibility Timeout）后再次变为可见，函数会重新处理该消息。**
> - 这个重试次数是由 Azure Storage Queue 的“最大传递计数”（Dequeue Count）控制，默认情况下为 **5 次**。
> - 超过最大重试次数的消息会被自动转移到“死信队列”（Dead-letter queue），即通常是另一个队列（需要开发者配置），或者消息被丢弃。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 3: When there are multiple orders in the queue, a batch of orders will be received from the queue and the ProcessOrders function will run multiple instances concurrently to process the orders.

![Question 26](images/question24_25_26_27.png)

- [x] Yes.
- [ ] No.

> ### Azure Functions 对 Azure Storage Queue 的并发处理机制：
>
> - Azure Functions 的队列触发器默认是可以并发处理多个消息的。
> - Azure Functions 运行时会根据配置和资源情况，**一次批量从队列中读取多条消息（batch）**，然后并发调用多个函数实例处理这些消息。
> - 这个批量大小和并发程度可以通过 `host.json` 中的 `batchSize` 和 `maxConcurrentCalls` 参数进行配置。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 4: The ProcessOrders function will output the order to an Orders table in Azure Table Storage.

![Question 27](images/question24_25_26_27.png)

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a hospital to support the following use cases: The most recent patient status details must be retrieved even if multiple users in different locations have updated the patient record. Patient health monitoring data retrieved must be the current version or the prior version. After a patient is discharged and all charges have been assessed, the patient billing record contains the final charges. You provision a Cosmos DB NoSQL database and set the default consistency level for the database account to Strong. You set the value for Indexing Mode to Consistent. You need to minimize latency and any impact to the availability of the solution. You must override the default consistency level at the query level to meet the required consistency guarantees for the scenarios. Which consistency levels should you implement?

![Question 28](images/question28.png)

- [ ] Box 1: Strong. Box 2: Consistent Prefix. Box 3: Eventual.
- [ ] Box 1: Eventual. Box 2: Strong. Box 3: Bounded Staleness.
- [ ] Box 1: Consistent Prefix. Box 2: Bounded Staleness. Box 3: Eventual.
- [x] Box 1: Strong. Box 2: Bounded Staleness. Box 3: Eventual.

> **Consistency Level 是你读取数据时对一致性、延迟、吞吐之间的权衡策略**，Cosmos DB 提供 5 个级别可选，按强到弱排序。
>
> ## 5 种一致性级别对比表
>
> | 一致性级别（从强到弱）              | 延迟 | 吞吐 | 可用性 | 保证（Guarantee）说明                            |
> | ----------------------------------- | ---- | ---- | ------ | ------------------------------------------------ |
> | **Strong**（强一致性）              | 高   | 低   | 低     | 所有副本读到的都是最新写入的数据（线性化一致性） |
> | **Bounded Staleness**（有界过时）   | 中   | 中   | 中     | 数据最多落后 N 秒 或 N 次写入操作（可控旧数据）  |
> | **Session**（会话一致性）           | 低   | 高   | 高     | 当前客户端读写强一致，跨客户端可能看到旧数据     |
> | **Consistent Prefix**（前缀一致性） | 低   | 高   | 高     | 保证读到的数据是按写入顺序排列的前缀             |
> | **Eventual**（最终一致性）          | 最低 | 最高 | 最高   | 不保证顺序，最终你**可能**读到一致的数据         |

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a development environment for your team. You deploy the latest Visual Studio image from the Azure Marketplace to your Azure subscription. The development environment requires several software development kits (SDKs) and third-party components to support application development across the organization. You install and customize the deployed virtual machine (VM) for your development team. The customized VM must be saved to allow provisioning of a new team member development environment. You need to save the customized VM for future provisioning. Which tools or services should you use?

![Question 29](images/question29.png)

- [ ] Generalize the VM: Visual Studio command prompt. Store images: Azure Data Lake Storage.
- [x] Generalize the VM: Azure PowerShell. Store images: Azure Blob Storage.
- [ ] Generalize the VM: Visual Studio command prompt. Store images: Azure File Storage.
- [ ] Generalize the VM: Azure PowerShell. Store images: Azure File Storage.

**[⬆ Back to Top](#table-of-contents)**

### You are preparing to deploy a website to an Azure Web App from a GitHub repository. The website includes static content generated by a script. You plan to use the Azure Web App continuous deployment feature. You need to run the static generation script before the website starts serving traffic. What are two possible ways to achieve this goal?

- [ ] Add the path to the static content generation tool to `WEBSITE_RUN_FROM_PACKAGE` setting in the `host.json` file.
- [x] Add a PreBuild target in the websites `csproj` project file that runs the static content generation script.
- [ ] Create a file named `run.cmd` in the folder `/run` that calls a script which generates the static content and deploys the website.
- [x] Create a file named `.deployment` in the root of the repository that calls a script which generates the static content and deploys the website.

> ### 选项分析
>
> 1. **`Add the path to the static content generation tool to WEBSITE_RUN_FROM_PACKAGE setting in host.json`**
>    - `WEBSITE_RUN_FROM_PACKAGE` 是 Azure Web App 的配置，用于直接从 zip 包运行网站，跟 `host.json` 无关，且不能指定运行脚本。
>    - 该选项错误。
> 2. **`Add a PreBuild target in the websites csproj project file that runs the static content generation script.`**
>    - 在项目文件中配置 PreBuild 事件，在构建前运行脚本，可以生成静态内容。
>    - 适用于使用 MSBuild 构建的项目，是很好的构建时自动生成方案。
>    - 该选项正确。
> 3. **`Create a file named run.cmd in the folder /run that calls a script which generates the static content and deploys the website.`**
>    - Azure Web App 并不默认识别 `/run/run.cmd` 文件，也不是标准部署或启动钩子。
>    - 该选项错误。
> 4. **`Create a file named .deployment in the root of the repository that calls a script which generates the static content and deploys the website.`**
>    - `.deployment` 文件可以自定义 Kudu 部署过程，指定自定义部署脚本（如调用生成脚本然后继续部署）。
>    - 这是 Azure Web App 持续部署中常用且官方支持的方式。
>    - 该选项正确。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application to use Azure Blob storage. You have configured Azure Blob storage to include change feeds. A copy of your storage account must be created in another region. Data must be copied from the current storage account to the new storage account directly between the storage servers. You need to create a copy of the storage account in another region and copy the data. In which order should you perform the actions?

![Question 31](images/question31.jpeg)

- [ ] Box 1: Create a new template deployment. Box 2: Export a Resource Manager template. Box 3: Modify the template by changing the storage account name and region. Box 4: Deploy the template to create a new storage account in the target region. Box 5: Use `AZCopy` to copy the data to the new storage account.
- [ ] Box 1: Use `AZCopy` to copy the data to the new storage account. Box 2: Create a new template deployment. Box 3: Modify the template by changing the storage account name and region. Box 4: Deploy the template to create a new storage account in the target region. Box 5: Export a Resource Manager template.
- [x] Box 1: Export a Resource Manager template. Box 2: Create a new template deployment. Box 3: Modify the template by changing the storage account name and region. Box 4: Deploy the template to create a new storage account in the target region. Box 5: Use `AZCopy` to copy the data to the new storage account.
- [ ] Box 1: Use `AZCopy` to copy the data to the new storage account. Box 2: Create a new template deployment. Box 3: Modify the template by changing the storage account name and region. Box 4: Deploy the template to create a new storage account in the target region. Box 5: Export a Resource Manager template.

**[⬆ Back to Top](#table-of-contents)**

### You are preparing to deploy an Azure virtual machine (VM)-based application. The VMs that run the application have the following requirements: When a VM is provisioned the firewall must be automatically configured before it can access Azure resources. Supporting services must be installed by using an Azure PowerShell script that is stored in Azure Storage. You need to ensure that the requirements are met. Which features should you use?

![Question 32](images/question32.jpeg)

- [ ] Firewall configuration: Run Command. Supporting services script: Hybrid Runbook Worker.
- [ ] Firewall configuration: Custom Script Extension. Supporting services script: Serial console.
- [x] Firewall configuration: Run Command. Supporting services script: Custom Script Extension.
- [ ] Firewall configuration: Hybrid Runbook Worker. Supporting services script: Custom Script Extension.

> ### 需求分析
>
> | 需求                                         | 要求说明                                                     |
> | -------------------------------------------- | ------------------------------------------------------------ |
> | **防火墙配置**                               | VM 在配置时，需要**自动配置防火墙**，确保能访问 Azure 资源。 |
> | **安装支持服务，使用 Azure PowerShell 脚本** | 需要执行存储在 Azure Storage 中的 PowerShell 脚本，安装必需的支持服务。 |
>
> ### 理由：
>
> - **Run Command** 适合临时执行命令，配置防火墙这种网络配置通常需要快速、直接执行命令，Run Command 可以直接远程执行 PowerShell 命令完成防火墙设置，且不需要提前部署脚本，比较灵活快速。
> - **Custom Script Extension** 适合自动化部署期间执行复杂的脚本，比如从 Azure Storage 下载 PowerShell 脚本并执行，用于安装支持服务等自动化操作。
>
> ------
>
> ### 其他选项分析：
>
> - **Hybrid Runbook Worker** 是用于 Azure Automation 的扩展，适合长期管理和复杂自动化，不太适合这两种具体即时配置任务。
> - **Serial console** 是用于故障排查和交互式管理，不适合自动脚本执行。

**[⬆ Back to Top](#table-of-contents)**

### A company is developing a Node.js web app. The web app code is hosted in a GitHub repository located at `https://github.com/TailSpinToys/webapp`. The web app must be reviewed before it is moved to production. You must deploy the initial code release to a deployment slot named `review`. You need to create the web app and deploy the code. How should you complete the commands?

![Question 33](images/question33.jpeg)

- [ ] Box 1: `New-AzWebAppSlot`. Box 2: `New-AzWebApp`. Box 3: `New-AzAppServicePlan`. Box 4: `New-AzResourceGroup`.
- [x] Box 1: `New-AzResourceGroup`. Box 2: `New-AzAppServicePlan`. Box 3: `New-AzWebApp`. Box 4: `New-AzWebAppSlot`.
- [ ] Box 1: `New-AzWebAppSlot`. Box 2: `New-AzAppServicePlan`. Box 3: `New-AzWebApp`. Box 4: `New-AzResourceGroup`.
- [ ] Box 1: `New-AzResourceGroup`. Box 2: `New-AzAppServicePlan`. Box 3: `New-AzWebAppSlot`. Box 4: `New-AzWebApp`.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that needs access to an Azure virtual machine (VM). The access lifecycle for the application must be associated with the VM service instance. You need to enable managed identity for the VM. How should you complete the PowerShell segment?

![Question 34](images/question34.jpeg)

- [ ] Box 1: `-AssignIdentity:`. Box 2: `$SystemAssigned`.
- [ ] Box 1: `-AssignIdentity:`. Box 2: `$UserAssigned`.
- [x] Box 1: `-IdentityId:` (note: screenshot has mistake, it should be `-IdentityType:` in the dropdown). Box 2: `$SystemAssigned`.
- [ ] Box 1: `-IdentityId:` (note: screenshot has mistake, it should be `-IdentityType:` in the dropdown). Box 2: `$UserAssigned`.

**[⬆ Back to Top](#table-of-contents)**

### You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Create an Azure Function app that uses the Consumption hosting model and that is triggered from the blob upload. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 官方没给出“冷启动可能长达X分钟”的明确数据。
>
> 冷启动一般在**秒级到十几秒**，超过 1 分钟极少见且不正常。
>
> 如果对启动时间有严格要求，建议考虑 Premium Plan 或 App Service Plan。

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the app with a method named `statuscheck` to run the scripts. Update the app settings for the app. Set the `WEBSITE_SWAP_WARMUP_PING_PATH` and `WEBSITE_SWAP_WARMUP_PING_STATUSES` with a path to the new method and appropriate response codes. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 你想要确保在开启了自动交换（Auto Swap）功能的情况下，**在交换操作发生之前先运行一些脚本，并确保资源就绪**。
>
> Azure App Service 提供了一个机制，允许在实际完成交换前，先对目标槽位进行**预热（warm-up）**，即：
>
> > **自动交换过程中，Azure 会先对目标槽位进行 Ping（探测），只有当返回指定的状态码时，才会继续完成交换。**
>
> **配置两个重要的应用设置（App Settings）**：
>
> - `WEBSITE_SWAP_WARMUP_PING_PATH`：设置要在交换前 Ping 的路径，比如 `/statuscheck`。
> - `WEBSITE_SWAP_WARMUP_PING_STATUSES`：设置哪些 HTTP 状态码表示“准备就绪”，比如 `200`。

**[⬆ Back to Top](#table-of-contents)**

### You create the following PowerShell script. Question 1: A log alert is created that sends an email when the CPU percentage is above 60 percent for five minutes.

![Question 37](images/question37_38_39.png)

- [ ] Yes.
- [x] No.

> ```shell
> # 创建一个数据源，定义查询内容为过去1小时内Heartbeat事件，数据源ID为 "contoso"
> $source = New-AzScheduledQueryRuleSource -Query 'Heartbeat | where TimeGenerated > ago(1h)' -DataSourceId "contoso"
> 
> # 定义调度规则，查询频率为每60分钟执行一次，查询窗口为最近60分钟
> $schedule = New-AzScheduledQueryRuleSchedule -FrequencyInMinutes 60 -TimeWindowInMinutes 60
> 
> # 设置告警触发条件，当查询结果数量少于5时触发告警
> $triggerCondition = New-AzScheduledQueryRuleTriggerCondition -ThresholdOperator "LessThan" -Threshold 5
> 
> # 创建一个Azure通知服务（Azns）操作组，指定动作组名称为 "contoso"，邮件主题为 "Custom email subject"，
> # 并定义自定义的Webhook负载，包含告警规则名称和是否包含查询结果
> $aznsActionGroup = New-AzScheduledQueryRuleAznsActionGroup -ActionGroup "contoso" -EmailSubject "Custom email subject" -CustomWebhookPayload "{"alert":"#alertrulename","IncludeSearchResults":true}"
> 
> # 创建告警动作，包含上述的Azns动作组，设置告警严重性为3，应用上述触发条件
> $alertingAction = New-AzScheduledQueryRuleAlertingAction -AznsAction $aznsActionGroup -Severity "3" -Trigger $triggerCondition
> 
> # 创建一个新的定时查询告警规则，位于资源组 "contoso"，区域为 "eastus"，
> # 使用前面定义的动作、调度计划、数据源，启用该规则，描述为 "Alert description"，规则名称为 "Alert Name"
> New-AzScheduledQueryRule -ResourceGroupName "contoso" -Location "eastus" -Action $alertingAction -Enabled $true -Description "Alert description" -Schedule $schedule -Source $sourc
> ```

**[⬆ Back to Top](#table-of-contents)**

### You create the following PowerShell script. Question 2: A log alert is created that sends an email when the number of machine heartbeats in the past hour is less than five.

![Question 38](images/question37_38_39.png)

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You create the following PowerShell script. Question 3: The log alert is scheduled to run every two hours.

![Question 39](images/question37_38_39.png)

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Function app. The app must meet the following requirements: Enable developers to write the functions by using the Rust language. Declaratively connect to an Azure Blob Storage account. You need to implement the app. Which Azure Function app features should you use?

![Question 40](images/question40.png)

- [ ] Enable developers to write the functions by using the Rust language: Hosting plan. Declaratively connect to an Azure Blog Storage account: Custom handler.
- [ ] Enable developers to write the functions by using the Rust language: Runtime. Declaratively connect to an Azure Blog Storage account: Policy.
- [ ] Enable developers to write the functions by using the Rust language: Custom handler. Declaratively connect to an Azure Blog Storage account: Trigger.
- [x] Enable developers to write the functions by using the Rust language: Custom handler. Declaratively connect to an Azure Blog Storage account: Extension bundle.

> **Extension Bundle** 是 Azure Functions 的一种机制，用来统一管理和加载各种触发器和绑定扩展包，比如 Blob Trigger、Queue Trigger、Cosmos DB Trigger 等。
>
> 通过启用 Extension Bundle，开发者不必手动安装每个触发器绑定的 NuGet 包或者扩展，Azure 会自动帮你处理依赖，简化配置和部署流程。
>
> 这对于非 .NET 项目（JavaScript、Python、PowerShell，甚至通过 Custom Handler 实现的其他语言）尤其方便。
>
> 这样你就可以**声明式地**通过 `function.json` 中配置绑定类型，Azure Functions 会自动加载对应的扩展支持。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core web application. You plan to deploy the application to Azure Web App for Containers. The application needs to store runtime diagnostic data that must be persisted across application restarts. You have the following code. You need to configure the application settings so that diagnostic data is stored as required. How should you configure the web app's settings?

![Question 41 part 1](images/question41_1.jpeg)
![Question 41 part 2](images/question41_2.jpeg)

- [x] App setting: `WEBSITES_ENABLE_APP_SERVICE_STORAGE`. Value: `/home`.
- [ ] App setting: `WEBSITES_ENABLE_APP_SERVICE_STORAGE`. Value: `/local`.
- [ ] App setting: `LOCALAPPDATA`. Value: `D:\home`.
- [ ] App setting: `DOTNET_HOSTING_OPTIMIZATION_CACHE`. Value: `D:\home`.

> ### `WEBSITES_ENABLE_APP_SERVICE_STORAGE`
>
> - **类型：** Azure App Service 的内置 App Setting
> - **可能的值：**
>   - `/home`（或 `true`）：**启用共享存储**
>   - `/local`（或 `false`）：**使用本地磁盘（不持久）**
>
> #### 🔹作用：
>
> 控制 App Service 是否使用 **持久性存储（shared storage）**（通常是 `/home` 目录）。适用于 Linux App Service。
>
> - 如果设为 `/home`（或 `true`）：
>   - 应用可以读写 `/home` 目录，数据在重启后保留
>   - 适合日志、缓存、临时文件、持久化内容
> - 如果设为 `/local`（或 `false`）：
>   - 使用临时的本地磁盘存储，**重启后内容会丢失**
>   - 但性能可能更好（例如 cold start 更快）
>
> #### 🔹适用场景：
>
> - 使用 `/home`：需要写日志、文件持久化
> - 使用 `/local`：追求性能，不在本地存储文件

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app that is protected by Azure Web Application Firewall (WAF). All traffic to the web app is routed through an Azure Application Gateway instance that is used by multiple web apps. The web app address is `contoso.azurewebsites.net`. All traffic must be secured with SSL. The Azure Application Gateway instance is used by multiple web apps. You need to configure the Azure Application Gateway for the web app. Which two actions should you perform?

- [x] In the Azure Application Gateway's HTTP setting, enable the Use for App service setting.
- [ ] Convert the web app to run in an Azure App service environment (ASE).
- [ ] Add an authentication certificate for `contoso.azurewebsites.net` to the Azure Application Gateway.
- [x] In the Azure Application Gateway's HTTP setting, set the value of the Override backend path option to `contoso22.azurewebsites.net`.

> **HTTP 设置**是 Azure Application Gateway 中的一项配置，用于定义网关如何将客户端请求 **转发到后端目标（Backend Pool）**。
>
> 每一个 **Listener（监听器）** 接收到的请求，都会通过一个 **Routing Rule（路由规则）** 路由到某个 **Backend Pool**，而 HTTP 设置则控制：
>
> - 使用什么协议（HTTP/HTTPS）
> - 是否启用 cookie 粘性
> - 是否使用自定义探针（Probe）
> - 请求的 Host Header 和路径是否需要改写
> - 与 Azure App Service 的兼容选项
>
> **Use for App Service** ：**专门用于 Azure App Service 的选项**。 启用后，Application Gateway 会自动设置 Host Header、使用 SNI、并处理 App Service 所需的通信细节。 **建议在使用 App Service 时务必启用。**
>
> `contoso.azurewebsites.net` 是 Azure 提供的标准 App Service，使用的是 **微软托管的受信任证书**，**不需要额外添加身份验证证书**。

**[⬆ Back to Top](#table-of-contents)**

### You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Use the Azure Blob Storage change feed to trigger photo processing. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 1: SaveScore will work with Cosmos DB.

![Question 44 part 1](images/question44_45_46_47_1.png)
![Question 44 part 2](images/question44_45_46_47_2.png)
![Question 44 part 3](images/question44_45_46_47_3.jpeg)

- [x] Yes.

- [ ] No.

  > ```c#
  > // 保存玩家得分记录到 Azure Table Storage
  > public void SaveScore(string gameId, string playerId, int score, long timeplayed)
  > {
  >     // 解析存储账户连接字符串，获取 CloudStorageAccount 实例
  >     // 注意：connectionString 必须在类中定义或作为参数传入
  >     CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);
  > 
  >     // 创建用于访问 Table Storage 的客户端对象
  >     CloudTableClient tableClient = storageAccount.CreateCloudTableClient();
  > 
  >     // 获取名为 "scoreTable" 的表引用（如果表不存在，不会抛错）
  >     CloudTable table = tableClient.GetTableReference("scoreTable");
  > 
  >     // 如果表不存在，则创建它（会发起一次网络请求，性能较低）
  >     // ⚠️ 建议：此操作在应用初始化阶段做一次即可，不必每次写入都检查
  >     table.CreateIfNotExists();
  > 
  >     // 创建一个新的得分记录实体，传入游戏 ID、玩家 ID、得分和时间
  >     // ⚠️ 要确保 PlayerScore 类继承自 TableEntity，并正确设置 PartitionKey 和 RowKey
  >     var scoreRecord = new PlayerScore(gameId, playerId, score, timeplayed);
  > 
  >     // 构造一个插入操作（Insert），用于插入新实体
  >     // ⚠️ 如果该主键（PartitionKey + RowKey）已存在，会抛出异常
  >     // 可考虑使用 InsertOrReplace 或 Merge 替代 Insert
  >     TableOperation insertOperation = TableOperation.Insert(scoreRecord);
  > 
  >     // 执行插入操作，将实体写入表中
  >     // ⚠️ 无异常处理，建议加上 try-catch 以避免因单条失败影响整体应用
  >     table.Execute(insertOperation);
  > }
  > ```
  >
  > - 你的 `SaveScore` 代码是针对 Azure Table Storage 写的。
  > - 理论上可以连接到 Cosmos DB 的 Table API，但需要使用 Cosmos DB 的连接字符串，并确保使用兼容的 SDK。
  > - 最稳妥的是，使用 Cosmos DB 专用的 Table API SDK，调整连接字符串和配置后再调用相似的方法。
  > - 直接用经典 Storage SDK 操作 Cosmos DB Table API，有时会有兼容性或性能问题。
  >
  > ```c#
  > // 1. 使用已有的 CloudStorageAccount 对象 account，创建一个 CloudTableClient，用于操作表存储服务。
  > CloudTableClient tableClient = account.CreateCloudTableClient();
  > 
  > // 2. 获取名为 "people" 的 CloudTable 引用，注意此操作不会自动创建该表，只是获取引用。
  > CloudTable table = tableClient.GetTableReference("people");
  > 
  > // 3~7. 构造一个 TableQuery<CustomerEntity> 查询对象，用于查询满足条件的实体。
  > // 其中条件是多个筛选条件的组合。
  > TableQuery<CustomerEntity> query = new TableQuery<CustomerEntity>()
  >     .Where(
  >         // 使用 TableQuery.CombineFilters 组合两个过滤条件（AND关系）
  >         TableQuery.CombineFilters(
  >             // 第一个条件：PartitionKey 属性值等于 "Smith"
  >             TableQuery.GenerateFilterCondition("PartitionKey", QueryComparisons.Equal, "Smith"),
  >             TableOperators.And,
  >             // 第二个条件：Email 属性值等于 "smith@contoso.com"
  >             TableQuery.GenerateFilterCondition("Email", QueryComparisons.Equal, "smith@contoso.com")
  >         )
  >     );
  > 
  > // 8. 异步执行查询，使用 ExecuteQuerySegmentedAsync 方法。
  > // 传入查询条件 query，和 continuationToken 为 null，表示从查询的起点开始。
  > // 该方法返回查询结果的一个“分段”（分页）数据，适合处理大数据量查询，避免内存压力。
  > // 返回结果包含符合条件的 CustomerEntity 实体集合和下一段的 continuationToken（可用于后续分页查询）。
  > var queryResult = await table.ExecuteQuerySegmentedAsync<CustomerEntity>(query, null);
  > 
  > ```
  >
  > 

**[⬆ Back to Top](#table-of-contents)**

### A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 2: SaveScore will update and replace a record if one already exists with the same playerId and gameId.

![Question 45 part 1](images/question44_45_46_47_1.png)
![Question 45 part 2](images/question44_45_46_47_2.png)
![Question 45 part 3](images/question44_45_46_47_3.jpeg)

- [ ] Yes.
- [x] No.

> ### 如果想「更新或替换」已存在的记录，应改用：
>
> - `InsertOrReplace` —— 如果存在，则替换整个实体；不存在则插入新实体。

**[⬆ Back to Top](#table-of-contents)**

### A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 3: Leader board data for the game will be automatically partitioned using gameId.

![Question 46 part 1](images/question44_45_46_47_1.png)
![Question 46 part 2](images/question44_45_46_47_2.png)
![Question 46 part 3](images/question44_45_46_47_3.jpeg)

- [ ] Yes.
- [x] No.

> **代码体现“以 gameId 分区”完全靠 `PlayerScore` 类中 PartitionKey 的设置。**
>
> 需要 `PartitionKey = gameId`，才会自动分区，Azure Table Storage 会根据 PartitionKey 做数据分区和分布。

**[⬆ Back to Top](#table-of-contents)**

### A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 4: SaveScore will store the values for the gameId and playerId parameters in the database.

![Question 47 part 1](images/question44_45_46_47_1.png)
![Question 47 part 2](images/question44_45_46_47_2.png)
![Question 47 part 3](images/question44_45_46_47_3.jpeg)

- [x] Yes.
- [ ] No.

=>2025.7.30

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 1: The code creates an infinite lease.

![Question 48](images/question48_49_50.jpeg)

- [x] Yes.
- [ ] No.

> **无限期的租约（infinite lease）** 指的是：
>
> - 一旦 lease 被创建，它**不会自动过期**，除非被显式释放或中止。
> - 持有该租约的客户端在释放之前，其他客户端不能修改该资源。
>
> 以 Blob 为例：
>
> ```C#
> #传 null 在旧 SDK 中等价于无限期（infinite）租约，或用 用 TimeSpan.MaxValue 表示
> blob.AcquireLeaseAsync(null)
> ```

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 2: The code at line 06 always creates a new blob.

![Question 49](images/question48_49_50.jpeg)

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 3: The finally block releases the lease.

![Question 50](images/question48_49_50.jpeg)

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You are building a website that uses Azure Blob storage for data storage. You configure Azure Blob storage lifecycle to move all blobs to the archive tier after 30 days. Customers have requested a service-level agreement (SLA) for viewing data older than 30 days. You need to document the minimum SLA for data recovery. Which SLA should you use?

- [ ] At least two days.
- [x] Between one and 15 hours.
- [ ] At least one day.
- [ ] Between zero and 60 minutes.

> 当你将 Azure Blob 存储配置为在 30 天后自动将所有 Blob 移动到 **归档层（archive tier）**，这些文件会变成**离线存储**，无法立即读取。若用户请求访问超过 30 天的数据，系统需要先将其**“解冻”（rehydration）**，这会花费一定时间
>
> 从归档层恢复数据可能需要最长 15 小时。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a ticket reservation system for an airline. The storage solution for the application must meet the following requirements: Ensure at least 99.99% availability and provide low latency. Accept reservations even when localized network outages or other unforeseen failures occur. Process reservations in the exact sequence as reservations are submitted to minimize overbooking or selling the same seat to multiple travelers. Allow simultaneous and out-of-order reservations with a maximum five-second tolerance window. You provision a resource group named `airlineResourceGroup` in the Azure South-Central US region. You need to provision a SQL API Cosmos DB account to support the app. How should you complete the Azure CLI commands?

![Question 52](images/question52.jpeg)

- [x] Box 1: `BoundedStaleness`. Box 2: `--enable-automatic-failover true \`. Box 3: `--locations 'southcentralplus=0 eastus=1 westus=2'`.
- [ ] Box 1: `Strong`. Box 2: `--enable-automatic-failover true \`. Box 3: `--locations 'southcentralplus=0 eastus=1 westus=2'`.
- [ ] Box 1: `BoundedStaleness`. Box 2: `--enable-automatic-failover true \`. Box 3: `--locations 'southcentralus'`.
- [ ] Box 1: `Strong`. Box 2: `--kind 'MongoDB' \`. Box 3: `--locations 'southcentralus'`.

> | 一致性级别                          | 保证                                   | 读取延迟 | 可用性 | 场景示例             |
> | ----------------------------------- | -------------------------------------- | -------- | ------ | -------------------- |
> | **Strong**（强一致性）              | 始终读取到最新写入的数据               | ⬆ 高     | ⬇ 低   | 金融系统、库存管理   |
> | **Bounded Staleness**（有限过时）   | 读取的数据最多滞后 K 个操作或 T 秒时间 | ⬆ 较高   | ⬆ 中等 | 订单系统、社交动态流 |
> | **Session**（会话一致性）           | 单个会话内读取始终能看到自己的写入     | ⬇ 低     | ⬆ 高   | 用户购物车、预订系统 |
> | **Consistent Prefix**（前缀一致性） | 保证读取顺序正确，但数据可能是旧的     | ⬇ 低     | ⬆ 高   | 日志记录、IoT数据    |
> | **Eventual**（最终一致性）          | 不保证顺序，只保证最终一致             | ⬇ 最低   | ⬆ 最好 | 缓存、推荐系统       |
>
> `southcentralplus=0` 表示主写入区域是 `South Central Plus US`，其他是读取副本并作为故障转移备份。



**[⬆ Back to Top](#table-of-contents)**

### You are preparing to deploy a Python website to an Azure Web App using a container. The solution will use multiple containers in the same container group. The Dockerfile that builds the container is as follows. You build a container by using the following command. The Azure Container Registry instance named `images` is a private registry. The user name and password for the registry is admin. The Web App must always run the same version of the website regardless of future builds. You need to create an Azure Web App to run the website. How should you complete the commands?

![Question 53 part 1](images/question53_1.png)
![Question 53 part 2](images/question53_2.png)
![Question 53 part 3](images/question53_3.jpeg)

- [ ] Box 1: `--sku B1 --hyper-v`. Box 2: `--deployment-source-url images.azurecr.io/website:1.0.0`. Box 3: `container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin`.
- [x] Box 1: `--sku B1 --is-linux`. Box 2: `--deployment-container-image-name images.azurecr.io/website:v1.0.0`. Box 3: `container set --docker-registry-server-url https://images.azurecr.io -u admin -p admin`.
- [ ] Box 1: `--tags container`. Box 2: `--deployment-source-url images.azurecr.io/website:latest`. Box 3: `set --python-version 2.7 --generic-configurations user=admin password=admin`.
- [ ] Box 1: `--sku SHARED`. Box 2: `--deployment-container-image-name images.azurecr.io/website:latest`. Box 3: `set --python-version 3.6 --generic-configurations user=admin password=admin`.

> Azure Web App for Containers（容器服务）仅支持 Linux 容器部署
>
> 要求每次部署使用的是 **指定版本** 的镜像（如 `v1.0`），**而不是 latest**
>
> 因为你的 ACR 是**私有仓库**，Web App 默认没有权限访问，必须显式配置认证信息。
>
> ```
>   --docker-registry-server-url https://images.azurecr.io \
>   --docker-registry-server-user admin \
>   --docker-registry-server-password <你的密码>
> ```



**[⬆ Back to Top](#table-of-contents)**

### You are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue. A rule already exists to scale up the App Service when the average queue length of unprocessed and valid queue messages is greater than 1000. You need to add a new rule that will continuously scale down the App Service as long as the scale up condition is not met. How should you configure the Scale rule?

![Question 54](images/question54.jpeg)

- [x] Metric source: Service Bus queue. Metric name: Active Message Count. Time train statistic: Average. Operator: Less than or equal to. Operation: Decrease count by.
- [ ] Metric source: Service Bus queue. Metric name: Active Message Count. Time train statistic: Count. Operator: Less than or equal to. Operation: Decrease count by.
- [ ] Metric source: Storage queue. Metric name: Active Message Count. Time train statistic: Count. Operator: Less than. Operation: Decrease count to.
- [ ] Metric source: Service Bus queue. Metric name: Message Count. Time train statistic: Average. Operator: Greater than. Operation: Decrease count to.

> | 属性                            | 配置示例                                        |
> | ------------------------------- | ----------------------------------------------- |
> | **指标源（Metric Source）**     | `Service Bus Queue`                             |
> | **指标名称（Metric Name）**     | `Active Messages` （或 `Active Message Count`） |
> | **统计方法**                    | `Average` 或 `Total`                            |
> | **时间粒度**                    | `1分钟`（粒度越小，响应越快，但可能更敏感）     |
> | **评估期（Evaluation period）** | `5分钟`（例如最近5个周期内符合条件）            |
> | **条件运算符**                  | `Less Than`                                     |
> | **阈值（Threshold）**           | `1000`                                          |
> | **操作（Operation）**           | `Decrease instance count by 1`                  |
> | **冷却时间（Cooldown）**        | `5分钟`（防止缩容过快，避免来回抖动）           |
>
> **Active Messages** 表示：当前还没有被处理的消息；即这些是**真正占用系统处理资源的“待处理消息”**。
>
> 使用 `Average` 能避免个别峰值引起误判，更平滑反应趋势。
>
> **自动缩放（Autoscale）是渐进过程**，而不是一步到底。设置 `Decrease by 1` 意味着每次缩容触发，只减一个实例，可以过度缩容

**[⬆ Back to Top](#table-of-contents)**

### You have an application that uses Azure Blob storage. You need to update the metadata of the blobs. Which three methods should you use to develop the solution?

![Question 55](images/question55.jpeg)

- [ ] Box 1: `Metadata.Add`. Box 2: `SetMetadataAsync`. Box 3: `SetPropertiesAsync`.
- [ ] Box 1: `Metadata.Add`. Box 2: `SetMetadataAsync`. Box 3: `UploadFileStream`.
- [ ] Box 1: `Metadata.Add`. Box 2: `FetchAttributesAsync`. Box 3: `SetPropertiesAsync`.
- [x] Box 1: `FetchAttributesAsync`. Box 2: `Metadata.Add`. Box 3: `SetMetadataAsync`.

> 必须先调用 `FetchAttributesAsync()` 才能访问 `Metadata` 和 `Properties` 字段的值。在新 SDK（`Azure.Storage.Blobs`）中已经 **不再使用这个方法**，而是改用：`GetPropertiesAsync()`
>
> 在设置 Blob 元数据前，你可以通过`metadata.Add()` 方法添加键值对。
>
> `SetMetadataAsync()`更新或设置 Blob 的元数据。
>
> 注意`SetPropertiesAsync()`只能用来设置 Blob 的 HTTP 属性（HTTP Headers），而不是设置元数据（Metadata）！=>Azure Blob 的 **HTTP 属性**，也称为 **Blob HTTP Headers**，指的是与 Web 请求响应相关联的标准 HTTP 头部信息，这些属性控制的是**客户端如何处理或缓存 Blob 的内容**，而不是自定义的业务信息。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

> ## 正确方案建议（示意）
>
> - **使用 Azure Event Hubs** 作为数据接收管道，支持高吞吐量数据。
> - 在 Event Hubs 中配置 **Capture** 功能，将数据自动存入 Blob Storage。
> - 通过 Partition Key 绑定设备 ID，保证同设备数据顺序和归类。
> - 下游数据处理或分析服务根据 Blob 文件名或 Partition Key 实现数据关联。
>
> => Azure Event Grid 不支持 Capture，也不能直接存 Blob，不能完成设备数据的收集与存储。

### You develop Azure solutions. A .NET application needs to receive a message each time an Azure virtual machine finishes processing data. The messages must NOT persist after being processed by the receiving application. You need to implement the .NET object that will receive the messages. Which object should you use?

- [x] `QueueClient`.
- [ ] `SubscriptionClient`.
- [ ] `TopicClient`.
- [ ] `CloudQueueClient`.

> 消息需要**即时接收和消费**，并且处理后不保留消息（不持久化）。这符合 **“队列消息”** 的消费模型，常见的实现是使用 **Azure Service Bus Queue** 或 **Azure Storage Queue**。如果你用的是 Service Bus，则通常用 `QueueClient`。

**[⬆ Back to Top](#table-of-contents)**

### You are maintaining an existing application that uses an Azure Blob GPv1 Premium storage account. Data older than three months is rarely used. Data newer than three months must be available immediately. Data older than a year must be saved but does not need to be available immediately. You need to configure the account to support a lifecycle management rule that moves blob data to archive storage for data not modified in the last year. Which three actions should you perform in sequence?

![Question 58](images/question58.jpeg)

- [ ] Box 1: Upgrade the storage account to GPv2. Box 2: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account. Box 3: Change the storage account access tier from hot to cool.
- [x] Box 1: Upgrade the storage account to GPv2. Box 2: Create a new GPv2 Standard account and set its default access tier level to cool. Box 3: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account.
- [ ] Box 1: Upgrade the storage account to GPv2. Box 2: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account. Box 3: Create a new GPv2 Standard account and set its default access tier level to cool.
- [ ] Box 1: Create a new GPv2 Standard account and set its default access tier level to cool. Box 2: Copy the data to be archived to a Standard GPv2 storage account and then delete the data from the original storage account. Box 3: Upgrade the storage account to GPv2.

> | 存储账户类型                      | 性能层                   | 支持的服务               | 特点与适用场景                                               | 生命周期管理支持 | 备注                         |
> | --------------------------------- | ------------------------ | ------------------------ | ------------------------------------------------------------ | ---------------- | ---------------------------- |
> | **GPv1 (General Purpose v1)**     | 标准 & 高性能(含Premium) | Blob, File, Queue, Table | 早期版本，功能有限，Premium 只支持 Blob；成本相对较高        | ❌ 不支持         | 推荐迁移到 GPv2              |
> | **GPv2 (General Purpose v2)**     | 标准 & Premium           | Blob, File, Queue, Table | 最新通用型账户，支持所有最新功能，支持生命周期管理和分层存储 | ✅ 支持           | Azure 推荐的默认存储账户类型 |
> | **Blob Storage (专用 Blob 账户)** | 标准                     | 仅 Blob                  | 专注 Blob，支持冷热层分层，成本相对低                        | ✅ 支持           | 适合只使用 Blob 的场景       |
> | **Premium Block Blob Storage**    | Premium                  | 仅 Blob (块 Blob)        | 高性能低延迟，适合 IO 密集型应用                             | ❌ 不支持         | 用于高性能需求，如视频处理等 |
> | **Premium File Storage**          | Premium                  | 仅 Azure 文件共享        | 高性能文件共享，支持 SMB 协议                                | ❌ 不支持         | 适合文件共享和高性能文件访问 |
> | **Azure Data Lake Storage Gen2**  | 基于 GPv2 标准           | Blob + 大数据分析优化    | 结合 Blob 存储和 Hadoop 分布式文件系统特性                   | ✅ 支持           | 适合大数据和分析场景         |
>
> Azure 存储账户 **不支持直接“升级”从 GPv1 到 GPv2**，所以你必须：**新建一个 GPv2 存储账户**（标准性能层）,然后 **将数据从 GPv1 存储账户迁移到新 GPv2 存储账户**。
>
> 第二个选项“升级”步骤表述有误，但逻辑至少是合理；而第四个选项 最后Upgrade升级操作不存在。

**[⬆ Back to Top](#table-of-contents)**

### You develop Azure solutions. You must connect to a No-SQL globally-distributed database by using the .NET API. You need to create an object to configure and execute requests in the database. Which code segment should you use?

- [ ] `new Container(EndpointUri, PrimaryKey);`.
- [ ] `new Database(EndpointUri, PrimaryKey);`.
- [x] `new CosmosClient(EndpointUri, PrimaryKey);`.

> 使用 .NET API 访问 Cosmos DB，推荐使用 **`CosmosClient`** 类。

**[⬆ Back to Top](#table-of-contents)**

### You have an existing Azure storage account that stores large volumes of data across multiple containers. You need to copy all data from the existing storage account to a new storage account. The copy process must meet the following requirements: Automate data movement. Minimize user input required to perform the operation. Ensure that the data movement process is recoverable. What should you use?

- [x] `AzCopy`.
- [ ] Azure Storage Explorer.
- [ ] Azure portal.
- [ ] .NET Storage Client Library.

> ## 推荐方案
>
> **使用 AzCopy 工具**
>
> - AzCopy 是微软官方的高性能命令行数据迁移工具。
> - 支持多线程复制，支持断点续传（自动恢复失败的复制）。
> - 只需写一个脚本，执行自动化任务即可，几乎不需要用户交互。
> - 可轻松集成到 CI/CD 或定时任务中。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web service that will run on Azure virtual machines that use Azure Storage. You configure all virtual machines to use managed identities. You have the following requirements: Secret-based authentication mechanisms are not permitted for accessing an Azure Storage account. Must use only Azure Instance Metadata Service endpoints. You need to write code to retrieve an access token to access Azure Storage.

![Question 61](images/question61.jpg)

- [ ] Code segment 1: `<http://localhost::50342/oauth2/token>`. Code segment 2: `new MultipartContent(payload);`.
- [ ] Code segment 1: `<http://localhost/metadata/identity/oauth2/token>`. Code segment 2: `JsonConvert.DeserializeObject<Dictionary<string, string>>(payload);`.
- [ ] Code segment 1: `<http://169.254.169.254:50432/metadata/identity/oauth2/token>`. Code segment 2: `new NetworkCredential('Azure', payload);`.
- [x] Code segment 1: `<http://169.254.169.254:50432/metadata/identity/oauth2/token>`. Code segment 2: `JsonConvert.DeserializeObject<Dictionary<string, string>>(payload);`.

> ```C#
> public static async Task<string> GetAzureStorageAccessTokenAsync()
> {
>     var client = new HttpClient();
>     client.DefaultRequestHeaders.Add("Metadata", "true");
> 
>     //169.254.169.254 是 Azure 预留的 IMDS 服务端点
>     var requestUri = "http://169.254.169.254/metadata/identity/oauth2/token" +
>                      "?api-version=2018-02-01" +
>                      "&resource=https://storage.azure.com/";
> 
>     var response = await client.GetAsync(requestUri);
>     var content = await response.Content.ReadAsStringAsync();
> 
>     // 解析 JSON，获取 access_token 字段
>     dynamic result = Newtonsoft.Json.JsonConvert.DeserializeObject(content);
>     return result.access_token;
> }
> ```

**[⬆ Back to Top](#table-of-contents)**

### You are developing a new page for a website that uses Azure Cosmos DB for data storage. The feature uses documents that have the following format. You must display data for the new page in a specific order. You create the following query for the page. You need to configure a Cosmos DB policy to support the query. How should you configure the policy?

![Question 62 part 1](images/question62_1.png)
![Question 62 part 2](images/question62_2.png)
![Question 62 part 2](images/question62_3.png)

- [ ] Box 1: `orderBy`. Box 2: `compositeIndexes`.
- [x] Box 1: `compositeIndexes`. Box 2: `descending`.
- [ ] Box 1: `compositeIndexes`. Box 2: `ascending`.
- [ ] Box 1: `ascending`. Box 2: `descending`.

> **Indexing Policy（索引策略）** 是 Cosmos DB 中定义文档如何被索引的配置。
>
> 你可以控制：
>
> - 是否自动索引所有文档（自动/手动）
> - 哪些字段包含在索引中
> - 哪些字段排除在索引之外
> - 索引类型（Range / Hash / Spatial）
> - 排序需求（通过 composite indexes）
>
> | 索引类型            | 支持数据类型                                                | 支持的操作                                       | 是否默认启用 | 优点                     | 适用场景                          |
> | ------------------- | ----------------------------------------------------------- | ------------------------------------------------ | ------------ | ------------------------ | --------------------------------- |
> | **Range Index**     | `String`, `Number`, `Boolean`, `DateTime`                   | `=`, `<`, `>`, `<=`, `>=`, `BETWEEN`, `ORDER BY` | ✅ 默认启用   | 支持范围查询和排序       | 按字段排序、筛选、分页            |
> | **Hash Index**      | `String`, `Number`, `Boolean`                               | `=`（等值匹配）                                  | ❌ 默认不是   | 写入性能更优，占用空间少 | 只做等值匹配的主键或标识查询      |
> | **Spatial Index**   | `Point`, `LineString`, `Polygon`, `MultiPolygon`（GeoJSON） | `ST_DISTANCE`, `ST_WITHIN`, `ST_INTERSECTS` 等   | ❌ 默认不启用 | 支持地理空间查询         | 地图、定位、地理围栏等            |
> | **Composite Index** | 多个字段（组合）                                            | 多字段联合 `WHERE + ORDER BY`                    | ❌ 需手动配置 | 提高联合过滤+排序性能    | 例如：`WHERE a=1 ORDER BY b DESC` |
> | **No Index**        | -                                                           | -                                                | ❌ 需手动设置 | 写入极快，节省存储       | 写多查少、日志类、冷数据容器      |

**[⬆ Back to Top](#table-of-contents)**

### You are building a traffic monitoring system that monitors traffic along six highways. The system produces time series analysis-based reports for each highway. Data from traffic sensors are stored in Azure Event Hub. Traffic data is consumed by four departments. Each department has an Azure Web App that displays the time series-based reports and contains a WebJob that processes the incoming data from Event Hub. All Web Apps run on App Service Plans with three instances. Data throughput must be maximized. Latency must be minimized. You need to implement the Azure Event Hub. Which settings should you use?

![Question 63](images/question63.png)

- [x] Number of partitions: 6. Partition Key: Highway.
- [ ] Number of partitions: 12. Partition Key: VM name.
- [ ] Number of partitions: 12. Partition Key: Highway.
- [ ] Number of partitions: 6 Partition Key: Department.

> **Partition Key** 应该与**事件数据本身相关联**，例如：高速公路（Highway）  => 分区键应来源于数据内容，而非消费方（VM）
>
> **分区数** 应 ≥ 实际业务维度数量，确保并发处理能力
>
> **消费者（WebJob）数量再多也不影响分区键选择**，但可用并发度受分区数限制

**[⬆ Back to Top](#table-of-contents)**

### You are developing a microservices solution. You plan to deploy the solution to a multinode Azure Kubernetes Service (AKS) cluster. You need to deploy a solution that includes the following features: reverse proxy capabilities configurable traffic routing TLS termination with a custom certificate. Which components should you use?

![Question 64](images/question64.jpg)

- [ ] Deploy solution: `Draft`. View cluster and external addressing: `CoreDNS`. Implement a single, public IP endpoint that is routed to multiple microservices: `Vrtual Kubelet`.
- [ ] Deploy solution: `Helm`. View cluster and external addressing: `Brigade`. Implement a single, public IP endpoint that is routed to multiple microservices: `KubeCtl`.
- [x] Deploy solution: `Helm`. View cluster and external addressing: `KubeCtl`. Implement a single, public IP endpoint that is routed to multiple microservices: `Ingress Controller`.
- [ ] Deploy solution: `Ingress Controller`. View cluster and external addressing: `Helm`. Implement a single, public IP endpoint that is routed to multiple microservices: `Brigade`.

> 1. **Deploy solution**
>
>    推荐组件：**Helm**
>
>    - Helm 是 Kubernetes 的“包管理器”，能帮你定义、打包、部署完整的微服务架构（多个 Pod、Service、Ingress 等）
>    - 可以轻松重复部署和管理复杂系统
>
> 2. View cluster and external IP addressing
>
>    推荐组件：**kubectl**
>
>    `kubectl get svc` 可以查看服务的 external IP
>
>    `kubectl get nodes`、`kubectl get ingress`、`kubectl describe` 等也能查看集群内部状态
>
> 3. Implement a single public IP endpoint that is routed to multiple microservices
>
>    推荐组件：**Ingress Controller**,通过 Ingress Controller，多个服务可共享**一个 Public IP**

**[⬆ Back to Top](#table-of-contents)**

### You are implementing an order processing system. A point of sale application publishes orders to topics in an Azure Service Bus queue. The Label property for the topic includes the following data. The system has the following requirements for subscriptions. You need to implement filtering and maximize throughput while evaluating filters. Which filter types should you implement?

![Question 65 part 1](images/question65_1.png)
![Question 65 part 2](images/question65_2.png)
![Question 65 part 3](images/question65_3.png)

- [x] Box 1: `SQLFilter`. Box 2: `CorrelationFilter`. Box 3: `SQLFilter`. Box 4: `SQLFilter`. Box 5: No Filter.
- [ ] Box 1: `CorrelationFilter`. Box 2: `SQLFilter`. Box 3: No Filter. Box 4: `CorrelationFilter`. Box 5: `SQLFilter`.
- [ ] Box 1: No Filter. Box 2: `CorrelationFilter`. Box 3: `SQLFilter`. Box 4: `SQLFilter`. Box 5: No Filter.
- [ ] Box 1: No Filter. Box 2: `SQLFilter`. Box 3: `SQLFilter`. Box 4: `CorrelationFilter`. Box 5: `CorrelationFilter`.

> | Subscription Type       | 要求                                                       |
> | ----------------------- | ---------------------------------------------------------- |
> | **FutureOrders**        | ❌ 不得接收任何消息（将来可能用，现在禁用）                 |
> | **HighPriorityOrders**  | ✅ 接收高优先级订单和国际订单                               |
> | **InternationalOrders** | ✅ 接收来自美国以外的订单                                   |
> | **HighQuantityOrders**  | ✅ 接收数量超过100的订单                                    |
> | **AllOrders**           | ✅ 接收所有订单（用于审计），还要定义 Action 来记录审计时间 |
>
> Azure Service Bus Topic 支持的订阅过滤器类型主要有以下三种：
>
> | Filter 类型            | 描述                                                         | 性能                      |
> | ---------------------- | ------------------------------------------------------------ | ------------------------- |
> | **SQL Filter**         | 类似 SQL 语句，对消息属性进行条件过滤，例如 `Label = 'HighPriority'` | ✅ 功能强大，但相对较慢    |
> | **Correlation Filter** | 根据消息的 **系统属性**（如 Label, MessageId, CorrelationId）进行简单匹配 | ✅✅ **性能最好**（高吞吐） |
> | **Boolean Filter**     | 特例，如 `TrueFilter`、`FalseFilter`（全接收或全不接收）     | 用于特殊情况，功能有限    |

**[⬆ Back to Top](#table-of-contents)**

### Your company has several websites that use a company logo image. You use Azure Content Delivery Network (CDN) to store the static image. You need to determine the correct process of how the CDN and the Point of Presence (POP) server will distribute the image and list the items in the correct order. In which order do the actions occur?

![Question 66](images/question66.jpg)

- [ ] Box 1: If no edge servers in the POP have the image in cache, the POP requests the file from the origin server. Box 2: Subsequent requests for the file may be directed to the same POP using the CDN logo image URL. The POP edge server returns the file from cache if the TTL has not expired. Box 3: The origin server returns the logo image to an edge server in the POP. An edge server in the POP caches the logo image and returns the image to the client. Box 4: A user requests the image from the CDN URL. The DNS routes the request to the best performing POP location.
- [x] Box 1: A user requests the image from the CDN URL. The DNS routes the request to the best performing POP location. Box 2: If no edge servers in the POP have the image in cache, the POP requests the file from the origin server. Box 3: The origin server returns the logo image to an edge server in the POP. An edge server in the POP caches the logo image and returns the image to the client. Box 4: Subsequent requests for the file may be directed to the same POP using the CDN logo image URL. The POP edge server returns the file from cache if the TTL has not expired.
- [ ] Box 1: Subsequent requests for the file may be directed to the same POP using the CDN logo image URL. The POP edge server returns the file from cache if the TTL has not expired. Box 2: A user requests the image from the CDN URL. The DNS routes the request to the best performing POP location. Box 3: If no edge servers in the POP have the image in cache, the POP requests the file from the origin server. Box 4: The origin server returns the logo image to an edge server in the POP. An edge server in the POP caches the logo image and returns the image to the client.
- [ ] Box 1: The origin server returns the logo image to an edge server in the POP. An edge server in the POP caches the logo image and returns the image to the client. Box 2: A user requests the image from the CDN URL. The DNS routes the request to the best performing POP location. Box 3: Subsequent requests for the file may be directed to the same POP using the CDN logo image URL. The POP edge server returns the file from cache if the TTL has not expired. Box 4: If no edge servers in the POP have the image in cache, the POP requests the file from the origin server.

> ### CDN + POP 内容分发流程分析（按正确顺序）
>
> 1. **User requests the logo image via the website.**
>
>    > 用户通过浏览器访问页面，页面上包含 logo 图片的链接（URL 指向 CDN）。
>
> 2. **Request goes to the closest CDN Point of Presence (POP).**
>
>    > 请求被自动路由到离用户最近的 CDN 节点（POP）以减少延迟。
>
> 3. **POP server checks its cache for the image.**
>
>    > POP 节点先检查自己本地有没有缓存这张图片。
>
> 4. **If the image is not cached, the POP server forwards the request to the origin server (e.g., Azure Blob Storage).**
>
>    > 如果缓存中没有，POP 会将请求转发到源服务器（也就是原始存储位置，如 Azure Blob Storage）。
>
> 5. **Origin server returns the image to the POP server.**
>
>    > 源服务器将图片返回给 POP 节点。
>
> 6. **POP server caches the image locally.**
>
>    > POP 节点将获取的图片缓存在本地，以便下次用户请求时直接返回。
>
> 7. **POP server returns the image to the user.**
>
>    > 最终，POP 节点将图片响应给用户的浏览器。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Cosmos DB solution by using the Azure Cosmos DB SQL API. The data includes millions of documents. Each document may contain hundreds of properties. The properties of the documents do not contain distinct values for partitioning. Azure Cosmos DB must scale individual containers in the database to meet the performance needs of the application by spreading the workload evenly across all partitions over time. You need to select a partition key. Which two partition keys can you use?

- [ ] A single property value that does not appear frequently in the documents.
- [ ] A value containing the collection name.
- [ ] A single property value that appears frequently in the documents.
- [x] A concatenation of multiple property values with a random suffix appended.
- [x] A hash suffix appended to a property value.

> ## Cosmos DB 选择 partition key 的基本原则：
>
> 1. **高基数（High cardinality）**：partition key 值应该具有足够的变化（例如 userId、deviceId、orderId）。
> 2. **分布均匀（Uniform distribution）**：partition key 的值应当尽可能地让数据分布在所有分区上，避免热点。
> 3. **访问模式友好（Access pattern-friendly）**：选的 key 应该与查询语句的 filter 条件有关，以减少跨分区查询（跨分区会影响性能）。
> 4. **可预见增长（Scalability over time）**：避免数据过度集中在单个 partition key 上。
>
> 使用人工构造的复合 key，如：
>
> ```
> "partitionKey": userId + "_" + date
> "partitionKey": hash(id) % 1000
> ```
>
> 可以人为地增加 key 的基数、提高分布性。这种方法尤其在没有天然合适字段时非常有效。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 1: A database named `SalesOrders` is created. The database will include two containers.

![Question 68](images/question68_69_70.png)

- [x] Yes.
- [ ] No.

> ```C#
> using System;
> using System.Threading.Tasks;
> using Microsoft.Azure.Cosmos;                      // 引入 Azure Cosmos DB 的 SDK
> using Microsoft.Extensions.Configuration;         // 引入配置读取相关类（读取 appSettings.json）
> using Newtonsoft.Json;                            // 用于序列化和反序列化 JSON 对象
> 
> namespace SalesOrders
> {
>     // 表示 Cosmos DB 中的一条订单记录（文档）
>     public class SalesOrder
>     {
>         // 假设有很多属性，这里只用了 AccountNumber 作为示例
>         public string AccountNumber { get; set; }
>     }
> 
>     internal class ManageSalesOrders
>     {
>         // 主方法，生成订单数据并写入 Cosmos DB
>         private static async Task GenerateSalesOrders()
>         {
>             // 从 appSettings.json 中读取配置信息
>             IConfigurationRoot configuration = new ConfigurationBuilder()
>                 .AddJsonFile("appSettings.json")
>                 .Build();
> 
>             // 获取 Cosmos DB 的连接终端地址和授权密钥
>             string endpoint = configuration["EndPointUrl"];
>             string authKey = configuration["AuthorizationKey"];
> 
>             // 创建 CosmosClient 实例，进行 Cosmos DB 的操作
>             using CosmosClient client = new CosmosClient(endpoint, authKey);
> 
>             Database database = null;
> 
>             // 如果数据库 "SalesOrders" 存在，则先删除（用于测试目的）
>             using (await client.GetDatabase("SalesOrders").DeleteStreamAsync()) { }
> 
>             // 创建数据库 "SalesOrders"（如果不存在则新建）
>             database = await client.CreateDatabaseIfNotExistsAsync("SalesOrders");
> 
>             // 创建两个容器（类似于两张表），指定 partition key 为 "/AccountNumber"
>             Container container1 = await database.CreateContainerAsync(
>                 id: "Container1", 
>                 partitionKeyPath: "/AccountNumber");
> 
>             Container container2 = await database.CreateContainerAsync(
>                 id: "Container2", 
>                 partitionKeyPath: "/AccountNumber");
> 
>             // 创建订单对象，AccountNumber 是分区键（Partition Key）
>             SalesOrder salesOrder1 = new SalesOrder() { AccountNumber = "123456" };
> 
>             // 将订单插入 container1 中，使用 AccountNumber 作为分区键
>             await container1.CreateItemAsync(salesOrder1, new PartitionKey(salesOrder1.AccountNumber));
> 
>             SalesOrder salesOrder2 = new SalesOrder() { AccountNumber = "654321" };
>             await container1.CreateItemAsync(salesOrder2, new PartitionKey(salesOrder2.AccountNumber));
> 
>             SalesOrder salesOrder3 = new SalesOrder() { AccountNumber = "109876" };
>             await container2.CreateItemAsync(salesOrder3, new PartitionKey(salesOrder3.AccountNumber));
> 
>             // 创建一个 Cosmos DB 数据库级别的用户（用于 RBAC 或权限管理）
>             _ = await database.CreateUserAsync("User1");
> 
>             // 获取用户对象并读取其信息
>             User user1 = database.GetUser("User1");
>             _ = await user1.ReadAsync();
>         }
>     }
> }
> 
> ```

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 2: Container1 will contain two items.

![Question 69](images/question68_69_70.png)

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 3: Container2 will contain one item.

![Question 70](images/question68_69_70.png)

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You develop an Azure solution that uses Cosmos DB. The current Cosmos DB container must be replicated and must use a partition key that is optimized for queries. You need to implement a change feed processor solution. Which change feed processor components should you use?

![Question 71](images/question71.png)

- [ ] Store the data from which the change feed is generated: Host. Coordinate processing of the change feed across multiple workers: Delegate. Use the change feed processor to listen for changes: Lease container. Handle each batch of changes: Monitored container.
- [ ] Store the data from which the change feed is generated: Lease container. Coordinate processing of the change feed across multiple workers: Host. Use the change feed processor to listen for changes: Delegate. Handle each batch of changes: Monitored container.
- [ ] Store the data from which the change feed is generated: Delegate. Coordinate processing of the change feed across multiple workers: Monitored container. Use the change feed processor to listen for changes: Lease container. Handle each batch of changes: Host.
- [x] Store the data from which the change feed is generated: Monitored container. Coordinate processing of the change feed across multiple workers: Lease container. Use the change feed processor to listen for changes: Host. Handle each batch of changes: Delegate.

> ```
> 数据写入 → Monitored Container → Change Feed → Host → Delegate（处理逻辑）
>                            ↑
>                Lease Container 控制并发和状态
> ```
>
> Monitored Container是你希望“监听变更”的主容器，也就是数据源。
>
> Host 是运行 Change Feed Processor 的应用实例。它负责监听数据变化并触发委托（delegate）来处理变更。可以是单个实例，也可以是多个实例（用于高可用或负载均衡）。
>
> Change Feed Processor 只能监视指定的那个容器（Monitored Container）。在 Cosmos DB 中，每个容器的数据被分成多个 物理分区（Partition）。如果有多个 Host 实例（例如为了水平扩展），就必须分配不同的分区给不同的 Host 来处理。为了做到这一点，每个 Host 在启动时都会访问 Lease Container：查看哪些分区已被“租用”（Lease）；哪些是空闲的；决定“我这个 Host 来负责处理哪几个分区的数据变化”。=>**所以是一个Monitored Container会对应多个Host实例**
>
> Change Feed 并不会自动“同步”数据，它只是检测变更，然后调用你定义的 Delegate 来同步数据，推送消息，实时分析，数据审计

**[⬆ Back to Top](#table-of-contents)**

### You develop a web application. You need to register the application with an active Microsoft Entra ID tenant. Which three actions should you perform in sequence?

![Question 72](images/question72.jpg)

- [ ] Box 1: Select Manifest from the middle-tier service registration. Box 2: Add a Cryptographic key. Box 3: In App Registrations, select New registration.
- [ ] Box 1: In App Registrations, select New registration. Box 2: Select the Microsoft Entra ID instance. Box 3: Select Manifest from the middle-tier service registration.
- [x] Box 1: In App Registrations, select New registration. Box 2: Select the Microsoft Entra ID instance. Box 3: Create a new application and provide the name, account type, and redirect URI.
- [ ] Box 1: In Enterprise Applications, select New application. Box 2: In App Registrations, select New registration. Box 3: Select the Microsoft Entra ID instance.

> 注册应用 → 设置基本属性 → 配置密钥
>
> | 动作                                                         | 是否选择 | 说明                                                  |
> | ------------------------------------------------------------ | -------- | ----------------------------------------------------- |
> | **In App Registrations, select New registration.**           | ✅ 是     | 正确第一步：进入 Entra ID（Azure AD）中注册新应用。   |
> | **Create a new application and provide the name, account type, and redirect URI.** | ✅ 是     | 创建应用时需要提供这些关键信息。                      |
> | **Add a Cryptographic key.**                                 | ✅ 是     | 添加客户端密钥（client secret），用于机密客户端认证。 |
> | **Select Manifest from the middle-tier service registration.** | ❌ 否     | 不需要直接编辑 manifest，除非特殊配置。               |
> | **In Enterprise Applications, select New application.**      | ❌ 否     | 这是用于 SSO SaaS 应用，不是自定义 app 注册流程。     |
> | **Select the Azure AD instance.**                            | ❌ 否     | 注册时已绑定当前 tenant，不需手动选。                 |
> | **Use an access token to access the secure resource.**       | ❌ 否     | 这属于运行时逻辑，非注册阶段动作。                    |

**[⬆ Back to Top](#table-of-contents)**

### You have a new Azure subscription. You are developing an internal website for employees to view sensitive data. The website uses Microsoft Entra ID for authentication. You need to implement multifactor authentication for the website. Which two actions should you perform?

- [ ] Configure the website to use Microsoft Entra ID B2C.
- [x] MFA Enabled by conditional access policy.
- [x] In Microsoft Entra ID, create a new conditional access policy.
- [ ] Upgrade to Microsoft Entra ID Premium.
- [ ] In Microsoft Entra ID, enable application proxy.
- [ ] In Microsoft Entra ID conditional access, enable the baseline policy.

> 1. **Configure a conditional access policy.**
> 2. **Enable Entra ID Security Defaults.**（二选一，根据你选择的MFA实现方式）
>
> 但要注意：
>
> - 如果你使用 **Conditional Access Policy**，就不需要启用 Security Defaults。
> - 如果你只是快速启用 MFA，可以使用 **Security Defaults**（简便方式，但自定义不灵活）。
>
> **Conditional Access（条件性访问）** 是 Microsoft Entra ID（原 Azure AD）提供的一项高级安全功能，用于根据特定条件（如用户、设备、应用、位置等）动态控制用户对资源的访问行为。通俗地讲，它就是一套 **“如果……那么……”** 的策略系统：Access = Conditions + Controls; 例如**如果** 某个用户尝试从不可信设备访问某个应用，**那么** 要求多重身份验证（MFA）或阻止访问。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a Java application that uses Cassandra to store key and value data. You plan to use a new Azure Cosmos DB resource and the Cassandra API in the application. You create an Microsoft Entra ID group named Cosmos DB Creators to enable provisioning of Azure Cosmos accounts, databases, and containers. The Microsoft Entra ID group must not be able to access the keys that are required to access the data. You need to restrict access to the Microsoft Entra ID group. Which role-based access control should you use?

- [ ] DocumentDB Accounts Contributor.
- [ ] Cosmos Backup Operator.
- [x] Cosmos DB Operator.
- [ ] Cosmos DB Account Reader.

> | 角色名                 | 权限说明                                                     |
> | ---------------------- | ------------------------------------------------------------ |
> | **Cosmos DB Operator** | 可以创建和管理 Azure Cosmos DB 资源（账户、数据库、容器），但不能访问密钥或数据。 |

**[⬆ Back to Top](#table-of-contents)**

### You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure the Azure Web App for the website to allow only authenticated requests and require Microsoft Entra ID log on. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 提供的 solution只能做到 **身份验证（authentication）**，也就是让用户**登录**网站，但并没有实现 **授权（authorization）**。 也就是根据 Entra ID 的 group membership 来判断权限等级：admin / normal / reader
>
> | 评估项                              | 是否满足     |
> | ----------------------------------- | ------------ |
> | 要求用户登录（Authentication）      | ✅ 满足       |
> | 根据组分配权限等级（Authorization） | ❌ **不满足** |

**[⬆ Back to Top](#table-of-contents)**

### You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, set value of the `groupMembershipClaims` option to All. In the website, use the value of the groups claim from the JWT for the user to determine permissions. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 你创建了一个新的 Microsoft Entra ID（原 Azure AD）应用注册。在该应用的清单（manifest）中，将 `"groupMembershipClaims"` 设置为 `"All"`。 这样，用户登录时颁发的 JWT（令牌）中会包含用户所属的所有组的 ID。你的网站在验证用户身份时，从 JWT 的 `groups` 声明中读取用户所在的组信息。根据用户所属的组来判断并分配权限级别，比如 `admin`、`normal` 和 `reader`。
>
> **认证**使用了 Microsoft Entra ID。**授权**通过组成员关系实现。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, define application roles that match the required permission levels for the application. Assign the appropriate Microsoft Entra ID group to each role. In the website, use the value of the roles claim from the JWT for the user to determine permissions. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 在 Microsoft Entra ID 应用注册的清单（manifest）中定义了**应用角色**（Application Roles），角色名称包括 `admin`、`normal`、`reader`。
>
> 将对应的 Microsoft Entra ID **用户组分配给这些应用角色**，即某个组的成员自动获得该角色权限。
>
> 用户登录后，颁发的 JWT 令牌中会包含一个 `roles` 声明，里面是用户拥有的角色。
>
> 网站根据 JWT 中的 `roles` 值，判断用户的权限级别。
>
> =>感觉可以...

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application to securely transfer data between on-premises file systems and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault. The application uses the Azure Key Vault APIs. The application must allow recovery of an accidental deletion of the key vault or key vault objects. Key vault objects must be retained for 90 days after deletion. You need to protect the key vault and key vault objects. Which Azure Key Vault feature should you use?

![Question 78](images/question78.png)

- [x] Enable retention period and accidental deletion: Soft delete. Enforce retention period and accidental deletion: Purge protection.
- [ ] Enable retention period and accidental deletion: Access policy. Enforce retention period and accidental deletion: Soft delete.
- [ ] Enable retention period and accidental deletion: Shared access signature. Enforce retention period and accidental deletion: Pure protection.
- [ ] Enable retention period and accidental deletion: Soft delete. Enforce retention period and accidental deletion: Shared access signature.

> **软删除（Soft Delete）**：
>  启用后，当 Key Vault 中的密钥、机密或证书被删除时，这些对象不会被立即永久删除，而是进入“已删除”状态，默认保留90天。在此期间，可以恢复这些被删除的对象，防止误删造成数据丢失。
>
> **清除保护（Purge Protection）**：
>  这是软删除的加强版，开启后即使有人尝试执行“清除（永久删除）”操作，也无法在保留期内真正删除 Key Vault 或其对象。这样确保了在90天内，数据不可被彻底销毁，保证恢复的可能性。

**[⬆ Back to Top](#table-of-contents)**

### You provide an Azure API Management managed web service to clients. The back-end web service implements HTTP Strict Transport Security (HSTS). Every request to the backend service must include a valid HTTP authorization header. You need to configure the Azure API Management instance with an authentication policy. Which two policies can you use?

- [x] Basic Authentication.
- [ ] Digest Authentication.
- [x] Certificate Authentication.
- [ ] OAuth Client Credential Grant.

> | 选项                                | 是否正确 | 原因                                                         |
> | ----------------------------------- | -------- | ------------------------------------------------------------ |
> | ✅ **Basic Authentication**          | ✔️ 正确   | Azure API Management 支持使用 `set-header` 或 `basic-authentication` 策略，向后端添加 `Authorization: Basic xxx` 头部，非常常见。 |
> | ❌ **Certificate Authentication**    | ✖️ 错误   | 这是 TLS 层的认证方式，不是通过 HTTP Header 中的 `Authorization` 字段完成的。APIM 的认证策略（Authentication Policy）**并不能配置或插入客户端证书**，只能在 TLS 层配置证书绑定，**不符合“通过 Authorization header 认证”的条件**。 |
> | ❌ **Digest Authentication**         | ✖️ 错误   | Azure API Management 不原生支持 Digest Auth，Digest Auth 需要挑战响应（challenge-response）流程，**APIM 无法直接处理**，因此不符合要求。 |
> | ✅ **OAuth Client Credential Grant** | ✔️ 正确   | APIM 支持通过 OAuth 客户端凭据流程（Client Credentials Grant Flow）获取 token，并设置 `Authorization: Bearer <token>` 头部，**完全满足题目“需要添加有效 Authorization header”的要求。** |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core website that can be used to manage photographs which are stored in Azure Blob Storage containers. Users of the website authenticate by using their Microsoft Entra ID credentials. You implement role-based access control (RBAC) role permissions on the containers that store photographs. You assign users to RBAC roles. You need to configure the website's Microsoft Entra ID Application so that user's permissions can be used with the Azure Blob containers. How should you configure the application?

![Question 80](images/question80.png)

- [ ] Azure Storage Permission: `client_id`. Azure Storage Type: `application`. Microsoft Graph Type: `user_impersonation`.
- [ ] Azure Storage Permission: `client_id`. Azure Storage Type: `profile`. Microsoft Graph Type: `application`.
- [x] Azure Storage Permission: `user_impersonation`. Azure Storage Type: `delegated`. Microsoft Graph Type: `delegated`.
- [ ] Azure Storage Permission: `user_impersonation`. Azure Storage Type: `delegated`. Microsoft Graph Type: `profile`.

> 你开发的是一个 ASP.NET Core 网站：
>
> - 用户通过 **Microsoft Entra ID** 登录；
> - 网站根据 RBAC 控制用户是否可访问 Azure Blob Storage 中的照片；
> - 权限来自于用户身份（比如所属组、角色等）；
> - 所以必须使用 **delegated permission（委托权限）**；=>“**委托权限（Delegated Permissions）**” 是 Azure 中用于表示 **“应用程序代表登录用户访问资源”** 的一种权限类型。而`user_impersonation` 是 **Microsoft Entra ID（以前叫 Azure AD）** 中的一种 **委托权限（Delegated Permission）**，意思是：允许应用程序“代表已登录的用户”访问特定资源或服务。
> - 网站也可能用 Microsoft Graph 来确认用户信息或所属组。
>
> 
>
> >  ✅ `Azure Storage Permission: user_impersonation`
> >  ✅ `Azure Storage Type: delegated`
> >  ✅ `Microsoft Graph Type: delegated`
>
> - Storage 使用 `user_impersonation` 表示“代表用户”访问资源；
> - `delegated` 是典型的 Web 应用场景；
> - Graph 也使用 `delegated` 权限，表示网站代表登录用户来请求 Microsoft Graph。`profile` 可能想表达的是 `User.Read` 等读取 profile 信息，但这属于 `delegated` 权限。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core app that includes feature flags which are managed by Azure App Configuration. You create an Azure App Configuration store named `AppFeatureFlagStore` that contains a feature flag named `Export`. You need to update the app to meet the following requirements: Use the `Export` feature in the app without requiring a restart of the app. Validate users before users are allowed access to secure resources. Permit users to access secure resources. How should you complete the code segment?

![Question 81](images/question81.png)

- [ ] Box 1: `UseSession`. Box 2: `UseCookiePolicy`. Box 3: `UseStaticFiles`.
- [ ] Box 1: `UseAuthentication`. Box 2: `UseAuthorization`. Box 3: `UseStaticFiles`.
- [ ] Box 1: `UseCookiePolicy`. Box 2: `UseHttpsRedirection`. Box 3: `UseCors`.
- [x] Box 1: `UseAuthentication`. Box 2: `UseAuthorization`. Box 3: `UseAzureAppConfiguration`.

> ```C#
> public void Configure(IApplicationBuilder app, IWebHostEnvironment env)
> {
>     // 开发环境错误页面
>     if (env.IsDevelopment())
>     {
>         app.UseDeveloperExceptionPage();
>     }
>     else
>     {
>         app.UseExceptionHandler("/Home/Error");
>         app.UseHsts();
>     }
> 
>     // 使用 HTTPS
>     app.UseHttpsRedirection();
> 
>     // 使用静态文件（如果有）
>     app.UseStaticFiles();
> 
>     app.UseRouting();
> 
>     // 启用身份验证（必须在 UseRouting 和 UseAuthorization 之间）
>     app.UseAuthentication();
> 
>     // 启用授权
>     app.UseAuthorization();
> 
>     // 使用 Azure App Configuration 的中间件以启用 Feature Flags 的动态刷新
>     app.UseAzureAppConfiguration();
> 
>     // 配置终结点（例如 MVC 或 Razor Pages）
>     app.UseEndpoints(endpoints =>
>     {
>         endpoints.MapControllerRoute(
>             name: "default",
>             pattern: "{controller=Home}/{action=Index}/{id?}");
>     });
> }
> ```

**[⬆ Back to Top](#table-of-contents)**

### You have an application that includes an Azure Web app and several Azure Function apps. Application secrets including connection strings and certificates are stored in Azure Key Vault. Secrets must not be stored in the application or application runtime environment. Changes to Microsoft Entra ID must be minimized. You need to design the approach to loading application secrets. What should you do?

- [ ] Create a single user-assigned Managed Identity with permission to access Key Vault and configure each App Service to use that Managed Identity.
- [ ] Create a single Microsoft Entra ID Service Principal with permission to access Key Vault and use a client secret from within the App Services to access Key Vault.
- [x] Create a system assigned Managed Identity in each App Service with permission to access Key Vault.
- [ ] Create an Microsoft Entra ID Service Principal with Permissions to access Key Vault for each App Service and use a certificate from within the App Services to access Key Vault.

> **为所有 Azure 应用启用系统分配托管身份**（Azure Portal 一键开启），之后托管身份由 Azure 自动管理，无需管理凭据或密钥；在 Key Vault 中给对应托管身份分配读取 Secret 权限

**[⬆ Back to Top](#table-of-contents)**

### You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Key Vault key named `skey`. 2. Encrypt the intake forms using the public key portion of skey. 3. Store the encrypted data in Azure Blob storage. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> **加密数据存储**，即使 Blob 被第三方下载，也无法直接读取明文，保护了数据的机密性（confidentiality）。=>基本满足，但是也需要注意使用公钥加密大数据本身不高效，更推荐使用 **Azure Blob Storage 客户端加密（Client-side encryption）**

**[⬆ Back to Top](#table-of-contents)**

### You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Cosmos DB database with Storage Service Encryption enabled. 2. Store the intake forms in the Azure Cosmos DB database. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Cosmos DB 是**多模型、分布式的 NoSQL 数据库服务**，适合存储结构化或半结构化数据（JSON 文档、键值等），不适合直接存储大量二进制大文件（如扫描表单图像、PDF 等）。将大量二进制文件直接存储在 Cosmos DB，成本高且性能不佳。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: Store the intake forms as Azure Key Vault secrets. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Key Vault Secrets 主要用于存储 **短小的机密信息**，比如密码、连接字符串、API 密钥等；Key Vault 的大小限制通常为 **25 KB 左右**，远小于文件大小需求。

**[⬆ Back to Top](#table-of-contents)**

### You plan to deploy a new application to a Linux virtual machine (VM) that is hosted in Azure. The entire VM must be secured at rest by using industry-standard encryption technology to address organizational security and compliance requirements. You need to configure Azure Disk Encryption for the VM. How should you complete the Azure CLI commands?

![Question 86](images/question86.jpg)

- [x] Box 1: `keyvault`. Box 2: `keyvault key`. Box 3: `vm`. Box 4: `vm encryption`. Box 5: `all`.
- [ ] Box 1: `vm`. Box 2: `vm encryption`. Box 3: `keyvault key`. Box 4: `keyvault`. Box 5: `data`.
- [ ] Box 1: `vm encryption`. Box 2: `vm`. Box 3: `keyvault`. Box 4: `keyvault key`. Box 5: `all`.
- [ ] Box 1: `keyvault key`. Box 2: `keyvault`. Box 3: `vm encryption`. Box 4: `vm`. Box 5: `os`.

> 1.创建资源组
>
> 2.创建Azure Key Vault
>
> 3.为 Key Vault 创建密钥（Key Encryption Key，KEK）
>
> 4.创建vm
>
> 5.启用 **Azure Disk Encryption (ADE)**，使整个 VM 磁盘在休息状态下被加密
>
> ```
> az vm encryption enable \
>   --resource-group MyResourceGroup \
>   --name MyLinuxVM \
>   --disk-encryption-keyvault https://myKeyVault.vault.azure.net/ \
>   --key-encryption-key https://myKeyVault.vault.azure.net/keys/myKey/1234567890abcdef \
>   --volume-type ALL
> ```
>
> `--volume-type ALL`：表示加密操作应用于 OS 和数据磁盘（整个 VM 磁盘）

**[⬆ Back to Top](#table-of-contents)**

### Your company is developing an Azure API hosted in Azure. You need to implement authentication for the Azure API to access other Azure resources. You have the following requirements: All API calls must be authenticated. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?

- [ ] Basic.
- [ ] Anonymous.
- [x] Managed identity.
- [ ] Client certificate.

**[⬆ Back to Top](#table-of-contents)**

### You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 1: The file MIME type is supported by the service.

- [ ] Yes.
- [x] No.

> “MIME” 全称是 **Multipurpose Internet Mail Extensions**，是一种标准，用来**标识和描述网络上文件的类型和格式**，让浏览器、服务器、邮件客户端等知道该如何处理文件。
>
> 在 HTTP 通信中，服务器通过响应头的 `Content-Type` 字段告诉客户端（浏览器、API 调用方）这个文件是什么类型，比如：
>
> - `text/html` ：网页
> - `image/png` ：PNG 图片
> - `application/json` ：JSON 数据
> - `application/xml` ：XML 文件
>
> 客户端根据 MIME 类型决定如何显示或处理文件。
>
> =>XML文件肯定是被支持的呀...这个不是root cause（问题问得有些不明确...）

**[⬆ Back to Top](#table-of-contents)**

### You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 2: Edge nodes must be purged of all cache assets.

- [x] Yes.
- [ ] No.

> Azure Front Door 具有边缘缓存（Edge cache）功能，会缓存请求过的静态资源，加速响应速度；
>
> 当文件已经被缓存后，Front Door 会直接返回缓存内容，不会重新压缩或重新处理这个文件，除非缓存被清理（purge）；
>
> 如果之前缓存的文件是未压缩版本，Front Door 会一直返回未压缩的内容；
>
> **清理（purge）边缘节点缓存**可以强制 Azure Front Door 重新拉取最新内容并重新应用压缩策略。

**[⬆ Back to Top](#table-of-contents)**

### You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 3: The compression type is supported.

- [x] Yes.
- [ ] No.

> Brotli 压缩是一种现代的**无损数据压缩算法**，由 Google 开发，广泛用于网络传输中对文本内容进行高效压缩。
>
> Azure Front Door 支持的压缩类型包括 **Brotli** 和 **Gzip**；
>
> Brotli 压缩适用于文本类型文件，如 `application/xml`；
>
> 如果你已经确认启用了 Brotli 压缩，并且客户端请求头中包含 `Accept-Encoding: br`，那么 **压缩类型本身是被支持的**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application. You have an Azure user account that has access to two subscriptions. You need to retrieve a storage account key secret from Azure Key Vault. In which order should you arrange the PowerShell commands to develop the solution?

![Question 91](images/question91.png)

- [ ] Box 1: `Get-AzSubscription`. Box 2: `Set-AzContext -SubscriptionId $subscriptionID`. Box 3: `Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct`. Box 4: `Get-AzKeyVaultSecret -VaultName $vaultName`. Box 5: `$secretvalue = ConvertTo-SecureString $storAcctkey -AsPlainText -Force Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue`.
- [ ] Box 1: `Set-AzContext -SubscriptionId $subscriptionID`. Box 2: `Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct`. Box 3: `Get-AzKeyVaultSecret -VaultName $vaultName`. Box 4: `$secretvalue = ConvertTo-SecureString $storAcctkey -AsPlainText -Force Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue`. Box 5: `Get-AzSubscription`.
- [x] Box 1: `Get-AzSubscription`. Box 2: `Set-AzContext -SubscriptionId $subscriptionID`. Box 3: `Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct`. Box 4: `$secretvalue = ConvertTo-SecureString $storAcctkey -AsPlainText -Force Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue`. Box 5: `Get-AzKeyVaultSecret -VaultName $vaultName`.
- [ ] Box 1: `Get-AzKeyVaultSecret -VaultName $vaultName`. Box 2: `Get-AzSubscription`. Box 3: `Set-AzContext -SubscriptionId $subscriptionID`. Box 4: `Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct`. Box 5: `$secretvalue = ConvertTo-SecureString $storAcctkey -AsPlainText -Force Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue`.

> ## 正确流程建议
>
> 1. 用 `Get-AzSubscription` 查看当前可用订阅，确认要操作的订阅 ID
> 2. 用 `Set-AzContext` 切换到指定订阅
> 3. 用 `Get-AzStorageAccountKey` 获取存储账号访问密钥 =>用来 **获取指定 Azure 存储账户的访问密钥（Access Keys）**
> 4. 把密钥转换为安全字符串 `ConvertTo-SecureString`
> 5. 用 `Set-AzKeyVaultSecret` 将密钥存入 Key Vault
> 6. 用 `Get-AzKeyVaultSecret` 验证是否存储成功

**[⬆ Back to Top](#table-of-contents)**

### You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use an `X.509` certificate to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 1. X.509 证书认证是什么？
>
> - Azure AD 支持多种身份验证方式，包括基于证书的身份验证（通常用于服务主体 Service Principal）；
> - 通过在 Azure AD 中创建使用证书的服务主体，可以用证书来请求令牌；
>
> ### 2. VM 直接用 X.509 证书认证的难点
>
> - 虚拟机本身没有内置自动管理证书身份的能力，需要你自行部署和管理证书；
> - 证书管理比较复杂，不易于维护和自动化；
> - 需要你在 VM 上安全存储证书和私钥，增加安全风险。
>
> ### 3. 更推荐的做法
>
> - **使用系统分配或用户分配的托管身份（Managed Identity）**，Azure 自动管理身份和令牌获取，无需你自己管理证书；
> - 托管身份可以直接向 Azure AD 请求令牌，访问 ARM API 和指定资源权限；
> - 这大大简化了身份认证流程，安全性和可维护性更好。

**[⬆ Back to Top](#table-of-contents)**

### You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use the Reader role-based access control (RBAC) role to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### **认证和授权的区别**
>
> - **认证** 是证明“我是谁”，获取访问令牌的过程；
> - **授权** 是证明“我能做什么”，RBAC 角色决定资源访问权限范围；
> - 给 VM 分配 Reader 角色是授权，不是身份认证的方式；

**[⬆ Back to Top](#table-of-contents)**

### You are building a website that is used to review restaurants. The website will use an Azure CDN to improve performance and add functionality to requests. You build and deploy a mobile app for Apple iPhones. Whenever a user accesses the website from an iPhone, the user must be redirected to the app store. You need to implement an Azure CDN rule that ensures that iPhone users are redirected to the app store. How should you complete the Azure Resource Manager template?

![Question 94](images/question94.png)

- [ ] Box 1: `iOS`. Box 2: `DeliveryRulelsDeviceConditionParameters`. Box 3: `HTTP_USER_AGENT`. Box 4: `DeliveryRuleRequestHeaderConditionParameters`. Box 5: `iOS`.
- [x] Box 1: `Mobile`. Box 2: `DeliveryRulelsDeviceConditionParameters`. Box 3: `HTTP_USER_AGENT`. Box 4: `DeliveryRuleRequestHeaderConditionParameters`. Box 5: `iPhone`.
- [ ] Box 1: `Desktop`. Box 2: `DeliveryRuleCookiesConditionParameters`. Box 3: `PRAGMA`. Box 4: `DeliveryRulelsDeviceConditionParameters`. Box 5: `Desktop`.
- [ ] Box 1: `iOS`. Box 2: `DeliveryRulelsDeviceConditionParameters`. Box 3: `FROM`. Box 4: `DeliveryRulePostArgsConditionParameters`. Box 5: `Mobile`.

> **Box 1:** 这个是匹配设备类别，`Mobile` 是更宽泛的手机设备类别，比 `iOS` 更常用，且能包含 iPhone；
>
> **Box 2:** 设备类型判断需要用 `DeliveryRuleIsDeviceConditionParameters`；
>
> **Box 3:** 请求头选择要检测 User-Agent，`HTTP_USER_AGENT` 是标准头名；
>
> **Box 4:** 请求头条件需要用 `DeliveryRuleRequestHeaderConditionParameters`；
>
> **Box 5:** User-Agent 匹配值为 `iPhone`，能准确识别 iPhone 设备。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure and use Integrated Windows Authentication in the website. In the website, query Microsoft Graph API to load the group to which the user is a member. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### Integrated Windows Authentication (IWA) 适用场景
>
> - IWA 主要用于企业内部网络（域环境）中，利用 Windows 域账户自动登录；
> - 它依赖客户端和服务器都在同一 Active Directory 域或信任环境中；
> - **Azure Web App 运行在云端，且用户可能是全球各种身份，通常不适用 IWA**；

**[⬆ Back to Top](#table-of-contents)**

### You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Run the `Invoke-RestMethod` cmdlet to make a request to the local managed identity for Azure resources endpoint. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> Azure 虚拟机可以启用 **托管身份（Managed Identity）**，这允许 VM 自身安全地从本地环境获取 Azure AD 令牌，而不需要在代码中保存任何凭据。
>
> VM 可以通过调用本地的 **Azure Instance Metadata Service (IMDS) 端点** 来请求访问令牌。
>
> 使用 PowerShell 的 `Invoke-RestMethod` 命令调用这个本地 IMDS 端点，能够获取对应托管身份的 **Azure Resource Manager（ARM）访问令牌**。
>
> 获得的令牌可以用来访问指定资源组内的 ARM 资源（前提是该托管身份拥有相应的权限）。
>
> 
>
> **Azure Instance Metadata Service (IMDS)** 是 Azure 提供的一个本地服务接口，运行在每个 Azure 虚拟机（VM）内部，允许 VM **安全地查询自身的元数据信息和获取访问令牌**，无需人工配置凭据。
>
> ------
>
> 详细介绍
>
> - IMDS 通过固定的 IP 地址 `http://169.254.169.254` 在 VM 内部提供 REST API 接口；
> - 你可以使用它查询 VM 的配置信息（如 VM 大小、区域、资源组、订阅 ID 等）；
> - 也可以通过它获取虚拟机的 **托管身份（Managed Identity）访问令牌**，用来访问 Azure 资源；
> - IMDS 是无状态且高可用的，安全地为运行在 VM 上的应用提供身份验证支持。



**[⬆ Back to Top](#table-of-contents)**

### Your company's Azure subscription includes an Azure Log Analytics workspace. Your company has a hundred on-premises servers that run either Windows Server 2012 R2 or Windows Server 2016, and is linked to the Azure Log Analytics workspace. The Azure Log Analytics workspace is set up to gather performance counters associated with security from these linked servers. You must configure alerts based on the information gathered by the Azure Log Analytics workspace. You have to make sure that alert rules allow for dimensions, and that alert creation time should be kept to a minimum. Furthermore, a single alert notification must be created when the alert is created and when the alert is resolved. You need to make use of the necessary signal type when creating the alert rules. Which of the following is the option you should use?

- [ ] The Activity log signal type.
- [ ] The Application Log signal type.
- [x] The Metric signal type.
- [ ] The Audit Log signal type.

> ## Azure Monitor 告警信号类型简介
>
> Azure Monitor 告警规则基于不同的“信号类型（Signal Type）”：
>
> - **日志信号（Log signal）**
>    基于 Log Analytics 中的 Kusto 查询（KQL）结果创建的告警规则。适合灵活复杂的查询。
> - **指标信号（Metric signal）**
>    基于 Azure 资源的性能指标进行告警，支持维度，告警响应快。
> - **活动日志信号（Activity log signal）**
>    针对 Azure 资源管理操作的事件告警。
>
> **如果必须支持维度且告警响应时间短，应使用“指标信号（Metric signal）”类型的告警规则**，结合从 Log Analytics 导出的自定义指标；

**[⬆ Back to Top](#table-of-contents)**

### You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation. You want the application to allow customers to search the index by using regular expressions. What should you do?

- [ ] Configure the `SearchMode` property of the `SearchParameters` class.
- [x] Configure the `QueryType` property of the `SearchParameters` class.
- [ ] Configure the `Facets` property of the `SearchParameters` class.
- [ ] Configure the `Filter` property of the `SearchParameters` class.

> #### `QueryType`
>
> - 作用：配置 Azure Search 使用的查询语言。
> - 设置为 `QueryType.Full` 可使用 Lucene 查询语法，其中支持一些高级功能（如模糊匹配 `term~`、通配符 `*` 和 `?`）。
> - **虽然仍不是真正的正则表达式，但可以提供更灵活的匹配方式**。
>
> ⚠ 所以，如果你希望尽可能模拟 regex，可以配置 `QueryType = QueryType.Full`

**[⬆ Back to Top](#table-of-contents)**

### You are a developer at your company. You need to update the definitions for an existing Logic App. What should you use?

- [ ] The Enterprise Integration Pack (EIP).
- [x] The Logic App Code View.
- [ ] The API Connections.
- [ ] The Logic Apps Designer.

> ### **Logic App Code View**
>
> - 提供对 Logic App **完整 JSON 工作流定义文件**的直接访问。
> - 适用于直接编辑触发器、条件、动作等结构。
> - **这是修改 Logic App 结构最底层、最精准的方式**。

**[⬆ Back to Top](#table-of-contents)**

### The cluster uses Azure Monitor for containers to monitor the cluster. The application has sticky sessions enabled on the ingress controller. Some customers report a large number of errors in the application over the last 24 hours. You need to determine on which virtual machines (VMs) the errors are occurring. How should you complete the Azure Monitor query?

![Question 100](images/question100.png)

- [x] Box 1: `ago(1d)`. Box 2: `distinct ContainerID`. Box 3: `where ContainerID in (ContainerIDs)`. Box 4: `summarize count() by Computer`.
- [ ] Box 1: `date(now() - 1d)`. Box 2: `sample ContainerID`. Box 3: `where ContainerID in (ContainerIDs)`. Box 4: `partition count() by Computer`.
- [ ] Box 1: `ago(1d)`. Box 2: `distinct ContainerID`. Box 3: `join ContainerID = = ContainerIDs.ContainerID`. Box 4: `summarize by Computer`.
- [ ] Box 1: `totimespan(1d)`. Box 2: `top ContainerID`. Box 3: `fork containerIDs`. Box 4: `project by Computer`.

> 考察如何在 **Azure Monitor (Kusto Query Language - KQL)** 中编写查询以定位集群错误来源虚拟机（VM）的题目
>
> ```
> // ago(1d) 是标准的 KQL 函数，用来获取“当前时间往前推一天”的时间点，适合用作最近 24 小时内的过滤条件
> let startTimestamp = ago(1d);
> 
> // 获取集群名为 "Cluster1" 的所有容器的唯一 ContainerID 列表
> let ContainerIDs = KubePodInventory
> | where ClusterName == "Cluster1"
> | distinct ContainerID;
> 
> // 查询 ContainerLog 表，筛选符合条件的日志记录：
> // 1. 只包含指定容器 ID
> // 2. 只看最近24小时内的数据
> // 3. 只看 stderr 来源的日志（表示错误）
> ContainerLog
> | where ContainerID in (ContainerIDs)
> | where TimeGenerated > startTimestamp
> | where LogEntrySource == "stderr"
> 
> // 这是标准的聚合写法，用于统计每台 VM（通过字段 Computer）上的错误日志数量。
> | summarize count() by Computer
> ```

**[⬆ Back to Top](#table-of-contents)**

### You plan to deploy a web app to App Service on Linux. You create an App Service plan. You create and push a custom Docker image that contains the web app to Azure Container Registry. You need to access the console logs generated from inside the container in real-time. How should you complete the Azure CLI command?

![Question 101](images/question101.png)

- [x] Box 1: `config`. Box 2: `--docker-container-logging`. Box 3: `webapp`. Box 4: `tail`.
- [ ] Box 1: `tail`. Box 2: `--web-server-logging`. Box 3: `aks` Box 4: `show`.
- [ ] Box 1: `show`. Box 2: `--web-server-logging`. Box 3: `acr`. Box 4: `config`.
- [ ] Box 1: `config`. Box 2: `--application-logging`. Box 3: `webapp`. Box 4: `show`.

> ```
> //实时查看日志命令（主命令）
> az webapp log tail --name <应用名称> --resource-group <资源组名称>
> //可选）启用日志记录功能（首次配置时建议运行）
> az webapp log config \
>   --name <应用名称> \
>   --resource-group <资源组名称> \
>   --docker-container-logging filesystem
> ```

**[⬆ Back to Top](#table-of-contents)**

### You develop an app that allows users to upload photos and videos to Azure storage. The app uses a storage REST API call to upload the media to a blob storage account named `Account1`. You have blob storage containers named `Container1` and `Container2`. Uploading of videos occurs on an irregular basis. You need to copy specific blobs from `Container1` to `Container2` when a new video is uploaded. What should you do?

- [ ] Copy blobs to `Container2` by using the Put Blob operation of the Blob Service REST API.
- [x] Create an Event Grid topic that uses the `Start-AzureStorageBlobCopy` cmdlet.
- [ ] Use `AzCopy` with the Snapshot switch to copy blobs to `Container2`.
- [ ] Download the blob to a virtual machine and then upload the blob to `Container2`.

> ###  **使用 Azure Event Grid + Azure Function 实现自动复制**
>
> #### 步骤说明：
>
> 1. **启用 Azure Storage 的事件发布功能**：
>    - 在 `Account1` 上启用 **Event Grid** 集成，以便在 `Container1` 中有新 blob 创建时触发事件。
>    - 你可以筛选事件类型为 `BlobCreated`，并限定路径前缀为视频文件路径（如 `.mp4`）。
> 2. **创建一个 Azure Function（或 Azure Logic App）**：
>    - 使用 **Blob Trigger** 或 **Event Grid Trigger**。
>    - 当检测到视频上传时，Function 读取 blob，并使用 **Blob REST API** 或 SDK 将其复制到 `Container2`。
>    - 可使用 `StartCopyFromUri` 方法实现异步复制。
> 3. **授权和安全**：
>    - 确保 Function 有权限访问两个容器（建议使用托管身份或 SAS Token）
>
> =>四个选项都不太对，只能选最为相似的？

**[⬆ Back to Top](#table-of-contents)**

### A web service provides customer summary information for e-commerce partners. The web service is implemented as an Azure Function app with an HTTP trigger. Access to the API is provided by an Azure API Management instance. The API Management instance is configured in consumption plan mode. All API calls are authenticated by using OAuth. API calls must be cached. Customers must not be able to view cached data for other customers. You need to configure API Management policies for caching. How should you complete the policy statement?

![Question 103](images/question103.jpg)

- [ ] caching-type: `Internal`. downstream-caching-type: `Private`. vary-by-header: `Authorization`.
- [ ] caching-type: `Public`. downstream-caching-type: `Expect`. vary-by-header: `Private`.
- [ ] caching-type: `Internal`. downstream-caching-type: `External`. vary-by-header: `Authorization`.
- [x] caching-type: `External`. downstream-caching-type: `Private`. vary-by-header: `Authorization`.

> ### ✅ **选项 4：✔ caching-type: `External`, downstream-caching-type: `Private`, vary-by-header: `Authorization`**
>
> - `caching-type: External`：指缓存是由下游服务（比如 CDN）控制的。**虽然通常 `Internal` 更常用于 APIM 内部缓存，但 Azure 允许使用 `External` 搭配 `vary-by-header` 进行自定义缓存策略。**  =>题目选择的是 **consumption plan**，而 Internal 缓存会有容量限制（例如 5MB），并且不总是可用。
> - `downstream-caching-type: Private`：告诉浏览器或下游服务缓存只对当前用户有效，✅ 正确。
> - `vary-by-header: Authorization`：使用 Authorization Header 中的 OAuth token 来区分缓存，防止用户看到别人的数据，**这是题目的关键点**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core website that uses Azure FrontDoor. The website is used to build custom weather data sets for researchers. Data sets are downloaded by users as Comma Separated Value (CSV) files. The data is refreshed every 10 hours. Specific files must be purged from the FrontDoor cache based upon Response Header values. You need to purge individual assets from the Front Door cache. Which type of cache purge should you use?

- [x] `single path`.
- [ ] `wildcard`.
- [ ] `root domain`.

> 正确答案：
>
> ### **"Single-path purge"**（也叫 **individual asset purge**）
>
> - **适用于单个文件（如某个 .csv 文件）的清除**。
> - 你可以通过逻辑（例如检查某文件的 Response Header 中的时间戳是否过期）来决定要不要清除缓存。
> - 然后调用 Azure Front Door 的 API 或使用 Azure CLI/PowerShell 进行 **精确路径清除**。

**[⬆ Back to Top](#table-of-contents)**

### Contoso, Ltd. provides an API to customers by using Azure API Management (APIM). The API authorizes users with a JWT token. You must implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID. You need to add the following policies to the policies file: a set-variable policy to store the detected user identity a cache-lookup-value policy a cache-store-value policy a find-and-replace policy to update the response body with the user profile information To which policy section should you add the policies?

![Question 105](images/question105.jpg)

- [x] Set-variable: Inbound. Cache-lookup-value: Inbound. Cache-store-value: Outbound. Find-and-replace: Outbound.
- [ ] Set-variable: Outbound. Cache-lookup-value: Inbound. Cache-store-value: Outbound. Find-and-replace: Inbound.
- [ ] Set-variable: Inbound. Cache-lookup-value: Outbound. Cache-store-value: Inbound. Find-and-replace: Outbound.
- [ ] Set-variable: Outbound. Cache-lookup-value: Outbound. Cache-store-value: Inbound. Find-and-replace: Inbound.

> 使用 **JWT token 授权**；
>
> 对响应启用 **按用户 ID 缓存**；
>
> 实现以下策略行为：
>
> 1. 通过 JWT token 提取 user ID（`set-variable`）；
> 2. 缓存查找（`cache-lookup-value`）；
> 3. 缓存写入（`cache-store-value`）；
> 4. 修改响应体，注入用户信息（`find-and-replace`）；
>
> | 策略                 | 应放置位置   | 原因                                                         |
> | -------------------- | ------------ | ------------------------------------------------------------ |
> | `set-variable`       | `<inbound>`  | 提取用户 ID（如从 JWT 的 `sub` claim）并存为变量，用于缓存 key。 |
> | `cache-lookup-value` | `<inbound>`  | 在实际转发请求到后端之前，尝试从缓存读取内容。               |
> | `cache-store-value`  | `<outbound>` | 在获得后端响应后，将结果存入缓存中。                         |
> | `find-and-replace`   | `<outbound>` | 修改返回体，注入用户 profile 信息或 mask 内容等。            |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application to retrieve user profile information. The application will use the Microsoft Graph SDK. The app must retrieve user profile information by using a Microsoft Graph API call. You need to call the Microsoft Graph API from the application. In which order should you perform the actions?

![Question 106](images/question106.jpg)

- [x] Box 1: Register the application with the Microsoft identity platform. Box 2: Build a client by using the client app ID. Box 3: Create an authentication provider. Box 4: Create a new instance of the GraphServiceClient. Box 5: Invoke the request to the Microsoft Graph API.
- [ ] Box 1: Invoke the request to the Microsoft Graph API. Box 2: Create an authentication provider. Box 3: Register the application with the Microsoft identity platform. Box 4: Build a client by using the client app ID. Box 5: Create a new instance of the GraphServiceClient.
- [ ] Box 1: Build a client by using the client app ID. Box 2: Register the application with the Microsoft identity platform. Box 3: Create an authentication provider. Box 4: Create a new instance of the GraphServiceClient. Box 5: Invoke the request to the Microsoft Graph API.
- [ ] Box 1: Register the application with the Microsoft identity platform. Box 2: Build a client by using the client app ID. Box 3: Invoke the request to the Microsoft Graph API. Box 4: Create a new instance of the GraphServiceClient. Box 5: Create an authentication provider. Graph API.

> ### 调用 Microsoft Graph API 获取用户信息的步骤顺序：
>
> 1. **在 Azure AD 中注册应用程序**
>    - 在 Azure 门户注册你的应用，获取应用程序（客户端）ID、租户ID和客户端密钥（或证书）。
>    - 配置应用所需的权限，比如 `User.Read`。
> 2. **用户身份认证并获取访问令牌（Access Token）**
>    - 使用 MSAL（Microsoft 身份验证库）等库进行用户登录认证，获取包含必要权限的 OAuth 2.0 访问令牌。
> 3. **使用访问令牌初始化 Microsoft Graph SDK 客户端**
>    - 创建 `GraphServiceClient` 实例，并配置其使用刚刚获取的访问令牌进行授权。
> 4. **调用 Microsoft Graph API 获取用户资料**

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure Logic App that calls an Azure Function app. The Azure Function App includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Logic App must use Azure Monitor logs to record and store information about runtime data and events. The logs must be stored in the Azure Blob storage account. You need to set up Azure Monitor logs and collect diagnostics data for the Azure Logic App. Which three actions should you perform in sequence?

![Question 107](images/question107.png)

- [x] Box 1: Create a Log Analytics workspace. Box 2: Install the Logic Apps Management solution. Box 3: Add a diagnostic setting to the Azure Logic App.
- [ ] Box 1: Install the Logic Apps Management solution. Box 2: Add a diagnostic setting to the Azure Function App. Box 3: Create action groups and alert rules.
- [ ] Box 1: Add a diagnostic setting to the Azure Function App. Box 2: Create a Log Analytics workspace. Box 3: Create action groups and alert rules.
- [ ] Box 1: Create a Log Analytics workspace. Box 2: Create action groups and alert rules. Box 3: Add a diagnostic setting to the Azure Function App.

> 这组步骤：
>
> - **Box 1:** Create a Log Analytics workspace.
> - **Box 2:** Install the Logic Apps Management solution.
> - **Box 3:** Add a diagnostic setting to the Azure Logic App.
>
> 是正确的顺序。
>
> 原因总结：
>
> - 先创建 Log Analytics 工作区，作为日志的集中存储和分析平台。
> - 然后安装 Logic Apps Management 解决方案，方便收集和展示 Logic App 相关日志。
> - 最后在 Logic App 上添加诊断设置，将日志发送到 Log Analytics。
>
> 其他选项中：
>
> - 添加诊断设置给 Azure Function App 并不是题目要求的重点。
> - 创建告警组和告警规则属于告警配置，不是日志收集的关键步骤。

**[⬆ Back to Top](#table-of-contents)**

### You develop an application. You plan to host the application on a set of virtual machines (VMs) in Azure. You need to configure Azure Monitor to collect logs from the application. Which four actions should you perform in sequence?

![Question 108](images/question108.png)

- [x] Box 1: Create a Log Analytics workspace. Box 2: Add a VMInsights solution. Box 3: Install agents on the VM and VM scale set to be monitored. Box 4: Create an Application Insights resource.
- [ ] Box 1: Add a VMInsights solution. Box 2: Create a Log Analytics workspace. Box 3: AInstall agents on the VM and VM scale set to be monitored. Box 4: Create an Application Insights resource.
- [ ] Box 1: Create an Application Insights resource. Box 2: Add a VMInsights solution. Box 3: AInstall agents on the VM and VM scale set to be monitored. Box 4: Create a Log Analytics workspace.
- [ ] Box 1: Create a Log Analytics workspace. Box 2: Add a VMInsights solution. Box 3: Create an Application Insights resource. Box 4: Install agents on the VM and VM scale set to be monitored.

> ### 推荐顺序：
>
> **Box 1:** Create a Log Analytics workspace.
>
> > 先创建 Log Analytics 工作区，作为日志的集中存储和分析平台。
>
> **Box 2:** Add a VMInsights solution.
>
> > VMInsights 是针对虚拟机监控的解决方案，提供性能和健康状况监控。
>
> **Box 3:** Install agents on the VM and VM scale set to be monitored.
>
> > 安装 Azure Monitor 代理（MMA）到虚拟机及虚拟机规模集，实现数据采集。
>
> **Box 4:** Create an Application Insights resource.
>
> > Application Insights 用于监控应用程序层面的性能和日志。
>
> ------
>
> ### 解析：
>
> - **Log Analytics workspace** 是核心日志收集和查询平台，必须先创建。
> - **VMInsights** 是监控 VM 状态的扩展解决方案，部署在工作区后才有效。
> - **安装代理** 是让 VM 发送数据到工作区的关键步骤。
> - **Application Insights** 专注于应用级别的遥测，是收集应用日志不可缺的资源。
>
> =>把安装代理放在最后，实际中容易导致**没有数据上传，后续监控和分析没意义**。

**[⬆ Back to Top](#table-of-contents)**

### You have an application that provides weather forecasting data to external partners. You use Azure API Management to publish APIs. You must change the behavior of the API to meet the following requirements: Support alternative input parameters. Remove formatting text from responses. Provide additional context to back-end services. Which types of policies should you implement?

![Question 109](images/question109.png)

- [x] Rewrite the request URL to match to the format expected by the web service: Inbound. Remove formatting text from responses: Outbound. Forward the user ID that is associated with the subscription key for the original request to the back-end service: Inbound.
- [ ] Rewrite the request URL to match to the format expected by the web service: Inbound. Remove formatting text from responses: Outbound. Forward the user ID that is associated with the subscription key for the original request to the back-end service: Backend.
- [ ] Rewrite the request URL to match to the format expected by the web service: Inbound. Remove formatting text from responses: Backend. Forward the user ID that is associated with the subscription key for the original request to the back-end service: Inbound.
- [ ] Rewrite the request URL to match to the format expected by the web service: Backend. Remove formatting text from responses: Backend. Forward the user ID that is associated with the subscription key for the original request to the back-end service: Inbound.

> | 需求                     | 应使用的策略类型  |
> | ------------------------ | ----------------- |
> | 支持替代输入参数         | `Inbound` policy  |
> | 移除响应中的格式化文本   | `Outbound` policy |
> | 提供额外上下文给后端服务 | `Inbound` policy  |

**[⬆ Back to Top](#table-of-contents)**

### Your company is developing an Azure API. You need to implement authentication for the Azure API. You have the following requirements: All API calls must be secure. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?

- [ ] Basic.
- [ ] Anonymous.
- [x] Managed identity.
- [ ] Client certificate.

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for a SaaS company that offers many web services. All web services for the company must meet the following requirements: Use API Management to access the services Use OpenID Connect for authentication Prevent anonymous usage A recent security audit found that several web services can be called without any authentication. Which API Management policy should you implement?

- [ ] `jsonp`.
- [ ] `authentication-certificate`.
- [ ] `check-header`.
- [x] `validate-jwt`.

> | 策略                                        | 说明                                                         |
> | ------------------------------------------- | ------------------------------------------------------------ |
> | **`<validate-jwt>`**                        | ✅ 用于验证传入请求中的 JWT 令牌（通常来自 OpenID Connect 提供者，如 Entra ID、Auth0、Google 等）。这可以有效**防止匿名访问**，并强制用户身份验证。 |
> | 其他策略（如 `check-header`、`set-header`） | 这些仅处理表面信息，不做身份验证。                           |
> | 没有设置 `<validate-jwt>` 的话              | 客户端可以绕过认证，形成“匿名访问”的漏洞                     |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure App Service REST API. The API must be called by an Azure App Service web app. The API must retrieve and update user profile information stored in Microsoft Entra ID. You need to configure the API to make the updates. Which two tools should you use?

- [x] Microsoft Graph API.
- [ ] Microsoft Authentication Library (MSAL).
- [x] Azure API Management.
- [ ] Microsoft Defender for Cloud.
- [ ] Microsoft Azure Key Vault SDK.

> #### ✅ 1. **Microsoft Graph API**
>
> - Microsoft Entra ID（以前叫 Azure AD）中的用户资料信息（如姓名、邮箱、部门等）**只能通过 Microsoft Graph API 访问和更新**
> - Graph 提供统一的 REST 接口，用于对 Entra ID 中的资源（如用户、组、应用）进行操作
>
> #### ✅ 2. **Microsoft Authentication Library (MSAL)**
>
> - 用于从 Web App 获取 **访问令牌（Access Token）**
> - API 使用这些令牌代表用户或客户端，向 Graph API 发出认证请求
> - 支持 OAuth 2.0、OpenID Connect，适用于多种身份验证场景（用户、服务主体、混合）
>
> #### ✖️ **Azure API Management**
>
> - 是一个 API 网关，**用于管理和保护 API**，但本题中**并不涉及 API 网关的发布或管理需求**
> - 它不提供直接调用 Entra ID 或 Graph 的能力

**[⬆ Back to Top](#table-of-contents)**

### You develop a REST API. You implement a user delegation SAS token to communicate with Azure Blob storage. The token is compromised. You need to revoke the token. What are two possible ways to achieve this goal?

- [x] Revoke the delegation key.
- [x] Delete the stored access policy.
- [ ] Regenerate the account key.
- [ ] Remove the role assignment for the security principle.

> | 选项                                                      | 是否有效 | 说明                                                         |
> | --------------------------------------------------------- | -------- | ------------------------------------------------------------ |
> | **Revoke the delegation key**                             | ✅ 有效   | **用户委托 SAS 是基于存储账户的用户委托密钥生成的**，撤销（重新生成）这个密钥，旧密钥失效，关联的 SAS 也失效。 |
> | **Delete the stored access policy**                       | ❌ 无效   | **Stored Access Policy** 只作用于 **基于账户密钥的 Service SAS（服务 SAS）**，不影响用户委托 SAS。 |
> | **Regenerate the account key**                            | ❌ 无效   | 账户密钥主要用于签发基于账户密钥的 SAS，不影响用户委托 SAS。 |
> | **Remove the role assignment for the security principal** | ✅ 有效   | 如果撤销 Azure AD 用户或服务主体对存储账户的权限，则相应生成的委托 SAS 无法正常访问资源。 |
>
> | 类型                                    | 描述                                                         | 签发者                                     | 典型用途                                                  |
> | --------------------------------------- | ------------------------------------------------------------ | ------------------------------------------ | --------------------------------------------------------- |
> | **服务 SAS（Service SAS）**             | 基于存储账户的密钥签发，允许对指定资源（如单个 Blob）授权访问 | 存储账户密钥                               | 允许临时访问特定文件/容器                                 |
> | **账户 SAS（Account SAS）**             | 基于存储账户密钥，授权对账户内多个服务和资源操作             | 存储账户密钥                               | 跨服务授权，较广泛权限                                    |
> | **用户委托 SAS（User Delegation SAS）** | 基于 Azure AD 用户令牌生成，安全性更高，适合现代认证场景     | Azure AD 用户令牌 + 存储账户的用户委托密钥 | 通过 Azure AD 授权访问 Blob Storage，避免存储账户密钥暴露 |



**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure-hosted application that must use an on-premises hardware security module (HSM) key. The key must be transferred to your existing Azure Key Vault by using the Bring Your Own Key (BYOK) process. You need to securely transfer the key to Azure Key Vault. Which four actions should you perform in sequence?

![Question 114](images/question114.jpeg)

- [ ] Box 1: Create a custom policy definition in Azure Policy. Box 2: Generate a Key Exchange Key (KEK). Box 3: Retrieve the Key Exchange Key (KEK) public key. Box 4: Run the `az keyvault key import` command.
- [ ] Box 1: Create a custom policy definition in Azure Policy. Box 2: Retrieve the Key Exchange Key (KEK) public key. Box 3: Generate a key transfer blob file by using the HSM `vendor-provided` tool. Box 4: Run the `az keyvault key import` command.
- [ ] Box 1: Generate a Key Exchange Key (KEK). Box 2: Retrieve the Key Exchange Key (KEK) public key. Box 3: Generate a key transfer blob file by using the HSM `vendor-provided` tool. Box 4: Run the `az keyvault key restore` command.
- [x] Box 1: Generate a Key Exchange Key (KEK). Box 2: Retrieve the Key Exchange Key (KEK) public key. Box 3: Generate a key transfer blob file by using the HSM `vendor-provided` tool. Box 4: Run the `az keyvault key import` command.

> ###  步骤说明：
>
> 1. **Generate a Key Exchange Key (KEK)**
>    - Azure Key Vault 会为每个 Key Vault 生成一个 KEK（Key Exchange Key）用于封装客户的密钥。
>    - 可通过 Azure 下载该 KEK 的证书（public key）。
> 2. **Retrieve the KEK public key**
>    - 这一步通常是使用 `az keyvault key get` 或下载证书公钥，用于 HSM 侧的加密操作。
> 3. **Generate a key transfer blob file by using the HSM vendor-provided tool**
>    - 通过硬件厂商提供的 BYOK 工具（例如 Thales 或 SafeNet）使用 Azure 的 KEK 对你的密钥进行封装并生成 `.byok` 文件。
> 4. **Run the `az keyvault key import` command**
>    - 最后一步是将 `.byok` 文件上传导入 Azure Key Vault。这个文件是加密的，因此 Azure 也无法看到原始密钥内容。
>
> ------
>
> ### ❌ 为什么其他选项不对？
>
> - **包含 "Create a custom policy definition in Azure Policy" 的选项错误**
>    ➤ 与 BYOK 完全无关，Azure Policy 用于资源控制策略，与密钥迁移无关。
> - **使用 `az keyvault key restore` 命令的选项错误**
>    ➤ `key restore` 是恢复备份用的，不是导入封装密钥用的命令。

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an Azure Logic app that calls an Azure Function app. The Azure Function app includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Azure Logic app must securely access the Azure Blob storage account. Microsoft Entra ID resources must remain if the Azure Logic app is deleted. You need to secure the Azure Logic app. What should you do?

- [x] Create a user-assigned managed identity and assign role-based access controls.
- [ ] Create an Microsoft Entra ID custom role and assign the role to the Azure Blob storage account.
- [ ] Create an Azure Key Vault and issue a client certificate.
- [ ] Create a system-assigned managed identity and issue a client certificate.
- [ ] Create an Microsoft Entra ID custom role and assign role-based access controls.

> Logic App 删除后，身份仍需保留 ✅ → 使用 **User-assigned Managed Identity**

**[⬆ Back to Top](#table-of-contents)**

### You manage several existing Logic Apps. You need to change definitions, add new logic, and optimize these apps on a regular basis. What should you use?

![Question 116](images/question116.jpg)

- [x] Edit B2B Workflows: Enterprise Integration Pack. Edit definitions in JSON: Code View Editor. Visually add functionality: Logic Apps Designer.
- [ ] Edit B2B Workflows: Logic Apps Designer. Edit definitions in JSON: Enterprise Integration Pack. Visually add functionality: Code View Editor.
- [ ] Edit B2B Workflows: Code View Editor. Edit definitions in JSON: Logic Apps Designer. Visually add functionality: Enterprise Integration Pack.
- [ ] Edit B2B Workflows: Enterprise Integration Pack. Edit definitions in JSON: Code View Editor. Visually add functionality: Code View Editor.

> #### 1. **Edit B2B Workflows → Enterprise Integration Pack**
>
> - **Enterprise Integration Pack** 是 Logic Apps 的一项扩展功能，专门支持 **B2B 场景**（如使用 **EDIFACT、X12、AS2** 等协议）。
> - 你可以用它来管理 **schemas、maps、partners、agreements** 等 B2B 元素。
>
> #### 2. **Edit definitions in JSON → Code View Editor**
>
> - 每个 Logic App 背后都由一个 **JSON 定义文件（Workflow Definition Language）** 支持。
> - 在 Azure 门户或 VS Code 中使用 **Code View Editor** 可以直接编辑这个 JSON 定义。
>
> #### 3. **Visually add functionality → Logic Apps Designer**
>
> - **Logic Apps Designer** 是一个 **拖放式图形界面**，用于直观地设计工作流。
> - 适合非开发人员或快速构建和调试。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that will use a multi-partitioned Azure Cosmos DB database. You plan to use the latest Azure Cosmos DB SDK for development. The solution must meet the following requirements: Send insert and update operations to an Azure Blob storage account. Process changes to all partitions immediately. Allow parallelization of change processing. You need to process the Azure Cosmos DB operations. What are two possible ways to achieve this goal?

- [ ] Create an Azure App Service API and implement the change feed estimator of the SDK. Scale the API by using multiple Azure App Service instances.
- [ ] Create a background job in an Azure Kubernetes Service and implement the change feed feature of the SDK.
- [x] Create an Azure Function to use a trigger for Azure Cosmos DB. Configure the trigger to connect to the container.
- [x] Create an Azure Function that uses a FeedIterator object that processes the change feed by using the pull model on the container. Use a FeedRange object to parallelize the processing of the change feed across multiple functions.

> ## 可能的两种方案：
>
> ### 1. **使用 Azure Cosmos DB Change Feed + Azure Functions (Cosmos DB trigger)**
>
> - Azure Cosmos DB Change Feed 会跟踪数据的插入和更新操作，支持多分区数据库
> - Azure Functions 通过 Cosmos DB Trigger 自动监听 Change Feed，支持分区和并行处理
> - 你可以在 Function 中实现逻辑，把变更数据写入 Azure Blob Storage
> - 这种方式实现简单，且能即时响应变化
>
> ------
>
> ### 2. **使用 Azure Cosmos DB Change Feed Processor Library（最新 SDK 中）**
>
> - Change Feed Processor Library 能监听所有分区的变更
> - 支持多实例并行消费 Change Feed，提高吞吐和处理效率
> - 你可以自己实现分布式的变更处理逻辑，将数据写入 Blob Storage
> - 适合需要更细粒度控制和自定义处理的场景
>
> ###  推荐选项
>
> - **Create an Azure Function to use a trigger for Azure Cosmos DB. Configure the trigger to connect to the container.**
>   - Azure Functions 提供的 Cosmos DB Trigger 本质上是基于 Change Feed 的实时监听。
>   - 触发器支持多分区数据库的自动并行处理，简化变更事件的实时响应。
>   - 适合快速开发和高扩展性需求。
> - **Create an Azure Function that uses a FeedIterator object that processes the change feed by using the pull model on the container. Use a FeedRange object to parallelize the processing of the change feed across multiple functions.**
>   - 使用 SDK 的 FeedIterator 和 FeedRange 进行“拉取式”消费 Change Feed，可以手动控制分区范围，实现自定义并行度。
>   - 适合更复杂、需要细粒度并行控制的场景

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses Azure Storage Queues. You have the following code. Question 1: The code configures the lock duration for the queue.

![Question 118](images/question118_119_120.jpg)

- [ ] Yes.
- [x] No.

> ```C#
> // 从配置文件中读取存储账户连接字符串，并创建 CloudStorageAccount 对象
> CloudStorageAccount storageAccount = CloudStorageAccount.Parse(
>     CloudConfigurationManager.GetSetting("StorageConnectionString"));
> 
> // 通过存储账户对象创建一个队列客户端，后续操作基于此客户端
> CloudQueueClient queueClient = storageAccount.CreateCloudQueueClient();
> 
> // 获取名为 "appqueue" 的队列引用（如果该队列不存在，后续可创建）
> CloudQueue queue = queueClient.GetQueueReference("appqueue");
> 
> // 异步创建队列，如果队列已存在则不会重复创建
> await queue.CreateIfNotExistsAsync();
> 
> // 异步查看队列中下一条消息，但不将其从队列中移除（即“窥视”操作）
> // 这步操作不会影响消息的可见性或状态
> CloudQueueMessage peekedMessage = await queue.PeekMessageAsync();
> 
> // 如果队列中有消息，输出消息内容
> if (peekedMessage != null)
> {
>     Console.WriteLine("The peeked message is: {0}", peekedMessage.AsString);
> }
> 
> // 异步获取并锁定队列中的下一条消息，消息在一定时间内对其他客户端不可见
> // 该消息需要后续显式删除，否则消息会重新变为可见
> CloudQueueMessage message = await queue.GetMessageAsync();
> ```

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses Azure Storage Queues. You have the following code. Question 2: The last message read remains in the queue after the code runs.

![Question 119](images/question118_119_120.jpg)

- [x] Yes.
- [ ] No.

> 代码调用了 `GetMessageAsync()` 取得并锁定了消息，但**没有调用 `DeleteMessageAsync()` 删除该消息**。
>
> 在 Azure Queue Storage 中，`GetMessageAsync()` 会将消息设为不可见一段时间（默认30秒），但如果不删除，消息会在锁定期结束后重新变为可见，供其他消费者再次读取。
>
> 所以这段代码只是“取出”了消息，但并没有“消费”并删除它。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses Azure Storage Queues. You have the following code. Question 3: The storage queue remains in the storage account after the code runs.

![Question 120](images/question118_119_120.jpg)

- [x] Yes.
- [ ] No.

> 代码调用了 `queue.CreateIfNotExistsAsync()`，如果队列不存在则创建，但**代码中没有调用删除队列的方法**，所以队列会一直保留。
>
> Azure 存储队列是持久资源，除非显式调用 `queue.DeleteAsync()` 才会被删除。
>
> 一般情况下，不会在处理消息时删除整个队列，队列通常长期存在，支持持续的消息生产和消费。

**[⬆ Back to Top](#table-of-contents)**

### You develop software solutions for a mobile delivery service. You are developing a mobile app that users can use to order from a restaurant in their area. The app uses the following workflow: 1. A driver selects the restaurants for which they will deliver orders. 2. Orders are sent to all available drivers in an area. 3. Only orders for the selected restaurants will appear for the driver. 4. The first driver to accept an order removes it from the list of available orders. You need to implement an Azure Service Bus solution. Which three actions should you perform in sequence?

![Question 121](images/question121.png)

- [x] Box 1: Create a single Service Bus Namespace. Box 2: Create a single Service Bus topic. Box 3: Create a Service Bus subscription for each restaurant for which a driver can receive orders.
- [ ] Box 1: Create a Service Bus subscription for each restaurant for which a driver can receive orders. Box 2: Create a Service Bus topic for each restaurant. Box 3: Create a Service Bus Namespace for each.
- [ ] Box 1: Create a single Service Bus topic. Box 2: Create a Service Bus subscription for each restaurant for which a driver can receive orders. Box 3: Create a single Service Bus topic.
- [ ] Box 1: Create a single Service Bus topic. Box 2: Create a Service Bus Namespace for each restaurant for which a driver can receive messages. Box 3: Create a Service Bus Namespace for each.

> ### 解析：
>
> 1. **单个 Service Bus Namespace**
>    - Namespace 是 Service Bus 的容器，管理成本和资源分配，通常一个应用或系统使用一个 Namespace 即可。
>    - 不建议为每个餐厅或每个用途创建多个 Namespace，成本高且复杂度增加。
> 2. **单个 Service Bus Topic**
>    - Topic 支持发布-订阅模式，适合多对多消息传递。
>    - 你只需要一个 Topic 来发布所有订单消息。
> 3. **每个餐厅一个订阅（Subscription）**
>    - 订阅可以应用过滤器（SQL Filter），只接收对应餐厅的订单消息。
>    - 驾驶员订阅自己感兴趣的餐厅的订阅，保证消息隔离且灵活。
>
>  Azure Service Bus架构核心组件:
>
> ```
>  [Sender App]
>       │
>       ▼
> ┌────────────┐
> │  Namespace │
> └────────────┘
>       │
> ┌───────┴────────┐
> │                │
> ▼                ▼
> Queue           Topic ──────► Subscription A ───► [Consumer A]
>                  │
>                  └──────► Subscription B ───► [Consumer B]
> ```

**[⬆ Back to Top](#table-of-contents)**

### You develop a news and blog content app for Windows devices. A notification must arrive on a user's device when there is a new article available for them to view. You need to implement push notifications. How should you complete the code segment?

![Question 122](images/question122.png)

- [x] Box 1: `NotificationHubClient`. Box 2: `NotificationHubClient`. Box 3: `CreateClientFromConnectionString`. Box 4: `SendWindowsNativeNotificationAsync`.
- [ ] Box 1: `NotificationHubJob`. Box 2: `NotificationHubJob`. Box 3: `PatchInstallation`. Box 4: `SendWindowsNativeNotificationAsync`.
- [ ] Box 1: `NotificationHubClientSettings`. Box 2: `NotificationHubClientSettings`. Box 3: `CreateOrUpdatelnstallation`. Box 4: `ScheduleNotificationAsync`.
- [ ] Box 1: `NotificationHubClientSettings`. Box 2: `NotificationDetails`. Box 3: `CreateOrUpdatelnstallation`. Box 4: `SendWindowsNativeNotificationAsync`.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure messaging solution. You need to ensure that the solution meets the following requirements: Provide transactional support. Provide duplicate detection. Store the messages for an unlimited period of time. Which two technologies will meet the requirements?

- [x] Azure Service Bus Topic.
- [x] Azure Service Bus Queue.
- [ ] Azure Storage Queue.
- [ ] Azure Event Hub.

> ### 1. **Azure Service Bus 标准版及以上（Premium 或 标准）**
>
> - **事务支持**：**支持跨队列/主题的事务操作**
> - **重复检测**：**内置消息重复检测**，自动丢弃重复消息（基于消息 ID）
> - **消息保留**：消息可配置最长可保留 14 天（默认7天），但不是无限期
> - 注意：消息最长保留期限有限制，不支持无限期存储
>
> ------
>
> ### 2. **Azure Storage Queues**
>
> - **事务支持**：不支持复杂事务，只有单条消息的原子操作
> - **重复检测**：不内置重复检测机制
> - **消息保留**：消息可以无限期保留，直到被消费或过期（最大7天，但可以延长消息的过期时间）
> - 不满足事务和重复检测需求
>
> ------
>
> ### 3. **Azure Event Hubs**
>
> - **事务支持**：不支持事务，面向事件流的高吞吐
>
> - **重复检测**：无重复检测机制
>
> - **消息保留**：默认最长7天，可配置最大90天，也不是无限期
>
>   
>
> Azure Service Bus Queue 和Azure Service Bus  Topic 的异同:
>
> | 特性           | Queue（队列）                  | Topic（主题）及 Subscription（订阅）        |
> | -------------- | ------------------------------ | ------------------------------------------- |
> | **消息模型**   | 点对点（Point-to-Point）       | 发布-订阅（Publish-Subscribe）              |
> | **消息流向**   | 一条消息被一个消费者接收       | 一条消息可被多个订阅独立接收                |
> | **消息消费**   | 单一消费者或多个消费者轮询消费 | 多个订阅可以独立消费同一条消息              |
> | **使用场景**   | 任务队列、命令分发             | 多订阅者监听不同条件、广播消息              |
> | **过滤机制**   | 不支持消息过滤                 | 订阅支持 SQL 过滤器，订阅只接收符合条件消息 |
> | **重复检测**   | 都支持重复检测                 | 都支持重复检测                              |
> | **事务支持**   | 都支持事务                     | 都支持事务                                  |
> | **消息保留期** | 最长14天                       | 最长14天                                    |
> | **示例应用**   | 单一消费者处理工作任务         | 不同服务或系统基于订阅处理消息              |

**[⬆ Back to Top](#table-of-contents)**

### You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and hosted in an Azure App Service instance. You need to configure back-end authentication for the API Management service instance. Which target and gateway credential type should you use?

![Question 124](images/question124.jpg)

- [ ] Target: Azure Resource. Gateway credentials: Client cert.
- [ ] Target: Client cert. Gateway credentials: Basic.
- [ ] Target: Azure Resource. Gateway credentials: Basic.
- [x] Target: HTTP(s) endpoint. Gateway credentials: Client cert.

> ### Target: **HTTP backend**
>
> - 因为你的后端是 **REST API**，部署在 Azure App Service 上，本质就是 HTTP 服务。
>
> 
>
> - ### ✅ `Target: HTTP(s) endpoint` + `Gateway credentials: Client cert`
>
>   - **适用于：**
>     - 后端（如 App Service）要求通过 **客户端证书（client certificate）** 验证调用方身份。
>   - **APIM 可以配置 client certificate** 作为调用后端服务时的身份凭证。
>   - **前提是**你已在 App Service 上配置了 client cert 验证（即：开启了 TLS mutual authentication）。
>
>   ✅ 你选的选项是 **技术上可行且合理的**，**前提是你的 App Service 后端确实使用客户端证书作为认证机制。**

**[⬆ Back to Top](#table-of-contents)**

### You are creating an app that uses Event Grid to connect with other services. Your app's event data will be sent to a serverless function that checks compliance. This function is maintained by your company. You write a new event subscription at the scope of your resource. The event must be invalidated after a specific period of time. You need to configure Event Grid. What should you do?

![Question 125](images/question125.jpg)

- [x] WebHook event delivery: SAS tokens. Topic publishing: ValidationCode handshake.
- [ ] WebHook event delivery: Key authentication. Topic publishing: ValidationCode handshake.
- [ ] WebHook event delivery: Management Access Control. Topic publishing: ValidationURL handshake.
- [ ] WebHook event delivery: SAS tokens. Topic publishing: ValidationURL handshake.

> 你题目的关键点是：
>
> > **“event must be invalidated after a specific period of time”**
>
> 这意味着：
>  👉 **事件订阅的访问权限必须“过期”**，即 Webhook 的认证方式应该具有“时效性”。
>
> ------
>
> ### ✅ **WebHook event delivery: SAS tokens**
>
> - SAS（Shared Access Signature）支持设置 **有效期**，因此可确保 **“事件在特定时间后失效”**，符合题意。
> - SAS tokens 提供临时授权访问，是推荐用于**安全传递事件到 Webhook**的方式。
>
> ------
>
> ### ✅ **Topic publishing: ValidationURL handshake**
>
> - Event Grid 创建订阅时，会向目标 endpoint（例如 Azure Function）发出验证请求。
> - **ValidationURL handshake** 是现在 Event Grid 官方推荐的验证方式。
> - 你的 endpoint 要求响应 HTTP GET 请求并返回 `validationResponse`。
> - ✅ 推荐使用此方式，而非 ValidationCode。
>
> ------
>
> ### ❌ **ValidationCode handshake**
>
> - 是早期版本中的一种验证方式。
>
> - **已不推荐使用**，并且会逐步淘汰。
>
> - 若选择它，将可能导致订阅验证失败或安全性不符合最佳实践。
>
>   
>
> **在 Event Grid + Azure Function 方案中，使用 Event Grid Trigger 时不支持 SAS 认证；如果想用 SAS（共享访问签名）认证，必须改用 HTTP Trigger，此时需要你自己设置并提供带 SAS 的 URL 给 Event Grid。**

**[⬆ Back to Top](#table-of-contents)**

### You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 1: The XML segment belongs in the `<inbound>` section of the policy.

![Question 127](images/question126_127_128.png)

- [x] Yes.
- [ ] No.

> 这段 Azure API Management（APIM）策略的代码逻辑是根据请求体的大小（`Content-Length`）进行条件判断和路由重写。下面是详细分析（含注释）：
>
> ```xml
> <set-variable name="bodySize" value="@(context.Request.Headers["Content-Length"][0])"/>
> ```
>
> - **功能**：从请求头中获取 `Content-Length` 的值（即请求体大小），并保存为变量 `bodySize`。
> - `context.Request.Headers["Content-Length"]` 返回的是 `IEnumerable<string>`，所以用 `[0]` 取第一个值。
>
> ------
>
> ```xml
> <choose>
>   <when condition="@(int.Parse(context.Variables.GetValueOrDefault<string>("bodySize")) < 512000)">
>   </when>
> ```
>
> - **功能**：判断请求体大小是否 **小于 512,000 字节（500 KB）**。
> - 如果满足条件，什么都不做（也可以在 `<when>` 里加逻辑，目前是空的）。
>
> ------
>
> ```xml
>   <otherwise>
>     <rewrite-uri template="/put"/>
>     <set-backend-service base-url="http://contoso.com/api/9.1/"/>
>   </otherwise>
> </choose>
> ```
>
> - **功能**：当请求体大小大于等于 512000 字节时，进入 `otherwise` 分支：
>   1. **重写 URI** 为 `/put`（表示把原始请求路径改写为 `/put`）。
>   2. **设置后端服务地址** 为 `http://contoso.com/api/9.1/`（即将请求发送到另一个后端）。

**[⬆ Back to Top](#table-of-contents)**

### You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 2: If the body size is >256k, an error will occur.

![Question 127](images/question126_127_128.png)

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 3: If the request is `<http://contoso.com/api/9.2/>`, the policy will retain the higher version.

![Question 128](images/question126_127_128.png)

- [ ] Yes.
- [x] No.

> **`<set-backend-service base-url="http://contoso.com/api/9.1/"/>`**
>
> - 这行是明确地**把所有后端调用重定向到 9.1 版本的 API**；
> - 它会覆盖调用者原始的路径（例如 `9.2`），只要策略中没有特别指定保留 URL 的参数。

**[⬆ Back to Top](#table-of-contents)**

### You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and uses an OpenAPI specification. You need to ensure that you can access the news API by using an Azure API Management service instance. Which Azure PowerShell command should you run?

- [x] `Import-AzureRmApiManagementApi -Context $ApiMgmtContext -SpecificationFormat 'Swagger' -SpecificationPath $SwaggerPath -Path $Path`.
- [ ] `New-AzureRmApiManagementBackend -Context $ApiMgmtContext-Url $Url -Protocol http`.
- [ ] `New-AzureRmApiManagement -ResourceGroupName $ResourceGroup -Name $Name 'Location $Location -Organization $Org -AdminEmail $AdminEmail`.
- [ ] `New-AzureRmApiManagementBackendProxy -Url $ApiUrl`.

> ```shell
> # 获取 APIM 实例上下文
> $apimContext = Get-AzApiManagement -ResourceGroupName "MyResourceGroup" -Name "MyAPIMService"
> 
> # 导入 OpenAPI 规范并注册 API
> Import-AzApiManagementApi `
>   -ResourceGroupName "MyResourceGroup" `
>   -Context $apimContext `
>   -Path "news" `                           # 对外暴露的 API 路径
>   -ApiId "news-api" `                      # API 的唯一 ID
>   -SpecificationFormat "OpenApi" `        # 使用 OpenAPI 格式
>   -SpecificationPath "https://contoso.com/openapi.json" `  # OpenAPI 文件 URL
>   -ServiceUrl "https://api.contoso.com"   # 后端 API 实际地址
> ```

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure function that connects to an Azure SQL Database instance. The function is triggered by an Azure Storage queue. You receive reports of numerous System.InvalidOperationExceptions with the following message: 'Timeout expired. The timeout period elapsed prior to obtaining a connection from the pool. This may have occurred because all pooled connections were in use and max pool size was reached.' You need to prevent the exception. What should you do?

- [ ] In the `host.json` file, decrease the value of the batchSize option.
- [ ] Convert the trigger to Azure Event Hub.
- [x] Convert the Azure Function to the Premium plan.
- [ ] In the `function.json` file, change the value of the type option to queueScaling.

> 这个错误提示表明：你的 **Azure Function** 在高并发或大量触发时，频繁打开数据库连接但没有及时释放，导致 **连接池耗尽（达到最大连接池上限）**。要解决这个问题，你需要优化数据库连接的使用方式。
>
> ###  详细解释
>
> #### ✅ 1. `host.json` 中减小 `batchSize`
>
> - `batchSize` 决定每次从 queue 中读取多少条消息。
> - 数值越大，同时运行的 function 实例就越多，数据库连接并发也越高。
> - 减少该值可降低连接池压力。
>
> ```
> jsonCopyEdit{
>   "extensions": {
>     "queues": {
>       "batchSize": 8, // 默认 16，建议调小
>       "newBatchThreshold": 4
>     }
>   }
> }
> ```
>
> ------
>
> #### ✅ 2. 使用 Premium Plan
>
> - **Premium Plan** 提供：
>   - 更好的资源隔离（dedicated VMs）
>   - 无连接池共享限制
>   - 长时间运行支持
>   - 高并发连接支持（数据库连接池也更多）

**[⬆ Back to Top](#table-of-contents)**

### You are developing a REST web service. Customers will access the service by using an Azure API Management instance. The web service does not correctly handle conflicts. Instead of returning an HTTP status code of 409, the service returns a status code of 500. The body of the status message contains only the word conflict. You need to ensure that conflicts produce the correct response. How should you complete the policy?

![Question 131](images/question131.png)

- [x] Box 1: `on-error`. Box 2: `context`. Box 3: `context`. Box 4: `set-status`. Box 5: `on-error`.
- [ ] Box 1: `when-error`. Box 2: `context`. Box 3: `server`. Box 4: `override-status`. Box 5:`on-error`.
- [ ] Box 1: `when-error`. Box 2: `context`. Box 3: `context`. Box 4: `set-status`. Box 5:`on-error`.
- [ ] Box 1: `on-error`. Box 2: `context`. Box 3: `server`. Box 4: `override-status`. Box 5:`on-error`.

> ```xml
> <on-error>
>   <base />
>   <choose>
>     <when condition = "@(context.Response.StatusCode == 500 && context.LastError.Message.Contains("conflict"))" >
>       <return-response>
>         <set-status code="409" reason="Conflict" />
>       </return-response>
>     </when>
>     <otherwise />
>   </choose>
> </on-error>
> ```
>
> `<override-status>` 并非 API Management policy 的合法策略指令。正确设置返回状态的指令是 `<set-status>`。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for a Software as a Service (SaaS) company. You develop solutions that provide the ability to send notifications by using Azure Notification Hubs. You need to create sample code that customers can use as a reference for how to send raw notifications to Windows Push Notification Services (WNS) devices. The sample code must not use external packages. How should you complete the code segment?

![Question 132](images/question132.jpg)

- [x] Box 1: `windows`. Box 2: `application/octet-stream`.
- [ ] Box 1: `windowsphone`. Box 2: `raw`.
- [ ] Box 1: `windows`. Box 2: `application/json`.
- [ ] Box 1: `windowsphone`. Box 2: `application/xml`.

> ```C#
> // 发送 Raw 通知
> public static async Task SendRawNotificationAsync(string deviceChannelUri, string rawPayload)
> {
>     // Notification Hub 发送端点，带 direct 参数表示直接发送
>     string wnsEndpoint = $"https://{hubNamespace}.servicebus.windows.net/{hubName}/messages/?direct&api-version=2015-01";
> 
>     // 生成访问用的 SAS Token
>     string sasToken = GenerateSasToken(wnsEndpoint, sasKeyName, sasKeyValue);
> 
>     using (var httpClient = new HttpClient())
>     {
>         // 创建请求内容，Content-Type 设为 application/octet-stream 表示原始二进制数据
>         var content = new StringContent(rawPayload, Encoding.UTF8, "application/octet-stream");
> 
>         // 添加 WNS 原始通知的特殊头部，标识通知类型为 raw
>         content.Headers.Add("X-WNS-Type", "wns/raw");
> 
>         // 添加认证信息（SAS Token）
>         httpClient.DefaultRequestHeaders.TryAddWithoutValidation("Authorization", sasToken);
> 
>         // 告诉 Notification Hub 这是 Windows 平台的通知格式
>         httpClient.DefaultRequestHeaders.TryAddWithoutValidation("ServiceBusNotification-Format", "windows");
> 
>         // 发送 POST 请求
>         var response = await httpClient.PostAsync(wnsEndpoint, content);
> 
>         if (response.IsSuccessStatusCode)
>         {
>             Console.WriteLine("Raw 通知发送成功！");
>         }
>         else
>         {
>             string error = await response.Content.ReadAsStringAsync();
>             Console.WriteLine($"发送失败，状态码：{response.StatusCode}，错误信息：{error}");
>         }
>     }
> }
> ```
>
> “octet” 在计算机领域就是**字节（byte）**的意思。
>
> “application/octet-stream” 表示的是**任意的二进制数据流**，也就是说，数据内容是“原始的”、“未指定格式”的二进制数据。
>
> 你发送的 **raw notification** 本质上是原始二进制数据，所以需要用 `application/octet-stream` 来告诉 WNS 这是“原始的、未编码的二进制内容”。
>
> 这样 WNS 会按原样传递给设备上的应用，由应用自行解析。

**[⬆ Back to Top](#table-of-contents)**

### You develop and deploy an ASP.NET web app to Azure App Service. You use Application Insights telemetry to monitor the app. You must test the app to ensure that the app is available and responsive from various points around the world and at regular intervals. If the app is not responding, you must send an alert to support staff. You need to configure a test for the web app. Which two test types can you use?

- [ ] Integration.
- [x] TrackAvailablity.
- [x] URL ping.
- [ ] Unit.
- [ ] Load.

> ### 解释：
>
> - **TrackAvailability**（可用性测试，Availability Test）是 Application Insights 提供的测试功能，用来定期检测 URL 是否可访问，响应是否正常。
> - **URL ping** 是其中最常用的可用性测试类型，简单地通过 HTTP GET 请求检测应用可用性。
>
> ------
>
> ### 其他选项说明：
>
> - **Integration**：集成测试，一般指的是代码级别的集成测试，不是 Application Insights 的可用性测试。
> - **Unit**：单元测试，属于开发阶段的测试类型，不是远程可用性监控。
> - **Load**：负载测试，用于测试应用在高并发情况下的性能，不是针对可用性和多地点监控的。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect inventory data from thousands of stores located around the world. Each store location will send the inventory data hourly to an Azure Blob storage account for processing. The solution must meet the following requirements: Begin processing when data is saved to Azure Blob storage. Filter data based on store location information. Trigger an Azure Logic App to process the data for output to Azure Cosmos DB. Enable high availability and geographic distribution. Allow 24-hours for retries. Implement an exponential back off data processing. You need to configure the solution. What should you implement?

![Question 134](images/question134.png)

- [ ] Event Source: Azure Event Grid. Event Receiver: Azure Logic App. Event Handler: Azure Service Bus.
- [ ] Event Source: Azure Service Bus. Event Receiver: Azure App Service. Event Handler: Azure Blob Storage.
- [ ] Event Source: Azure Event Grid. Event Receiver: Azure Service Bus. Event Handler: Azure Blob Storage.
- [x] Event Source: Azure Blob Storage. Event Receiver: Azure Event Grid. Event Handler: Azure Logic App.

> **事件触发来源**：当 Blob 存储中有新数据时触发处理 -> Blob Storage 是事件源。

**[⬆ Back to Top](#table-of-contents)**

### Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Enable Application Request Routing (ARR). Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 需求总结：
>
> - 你有多个 ASP.NET Web 应用部署在 Azure App Service 上。
> - 需要**共享会话状态（Session State）**，也就是说多个应用之间要用同一份 Session 数据。
> - 要支持对同一份 Session 数据的**多读单写（多读者单写者）的并发访问控制**。
> - 还要能**保存完整的 HTTP 响应**（即输出缓存，Output Cache），支持并发请求。
>
> ------
>
> ### 提议方案：
>
> - **启用 Application Request Routing (ARR)**。
>
> ------
>
> ### ARR 是什么？
>
> - ARR 是 IIS 的一个代理和负载均衡功能。
> - 它能实现请求的转发、负载均衡和缓存功能。
> - 还能启用“会话亲和性”（Sticky Sessions），让同一用户的请求都发到同一台后端服务器。
>
> ------
>
> ### ARR 能否满足需求？
>
> **共享 Session 状态？**
>
> - ARR 的“会话亲和性”只是把同一个用户的请求固定路由到同一台服务器，**并不是真正的共享 Session**。
> - 多个应用之间的 Session 还是分开的，没有统一存储。
> - 也就是说，ARR 本身**不提供集中式的 Session 存储机制**。

**[⬆ Back to Top](#table-of-contents)**

### Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure an Azure Database for PostgreSQL. Update the web applications. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 实际可行性与性能考虑：
>
> 虽然 PostgreSQL 技术上**能满足这些功能**，但从性能和实践角度来看：
>
> - **Session 状态管理**：
>   - PostgreSQL 可以作为 Session 存储，但不是 ASP.NET 中的默认或推荐方式。
>   - 更推荐使用如 **Azure Cache for Redis** 这类专门设计用于快速读取、高并发的缓存系统。
> - **HTTP 响应缓存**：
>   - 将 HTML 输出直接存到数据库中可行，但通常使用缓存系统（如 Redis、MemoryCache、CDN）更高效。

**[⬆ Back to Top](#table-of-contents)**

### Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure Azure Cache for Redis. Update the web applications. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> | 要求                        | Azure Cache for Redis 是否满足 | 说明                                                         |
> | --------------------------- | ------------------------------ | ------------------------------------------------------------ |
> | 1. 共享 Session 状态        | ✅ 是                           | Redis 是分布式缓存，支持跨多个实例/应用共享 Session，ASP.NET 本身提供 Redis Session Provider。 |
> | 2. 支持多读单写并发访问控制 | ✅ 是                           | Redis 支持事务（MULTI/EXEC）、锁（如 RedLock）、以及高性能并发读取，适合多读单写场景。 |
> | 3. 保存完整 HTTP 响应       | ✅ 是                           | Redis 可作为输出缓存（OutputCache）存储 HTML 响应，ASP.NET 中可通过中间件或自定义实现。 |

**[⬆ Back to Top](#table-of-contents)**

### A company is developing a gaming platform. Users can join teams to play online and see leaderboards that include player statistics. The solution includes an entity named `Team`. You plan to implement an Azure Redis Cache instance to improve the efficiency of data operations for entities that rarely change. You need to invalidate the cache when team data is changed. How should you complete the code?

![Question 138](images/question138.jpg)

- [ ] Box 1: `IDatabase cache = Connection.GetDatabase();`. Box 2: `cache.StringSet('Team', '');`.
- [x] Box 1: `IDatabase cache = Connection.GetDatabase();`. Box 2: `cache KeyDelete('Team');`.
- [ ] Box 1: `ICache cache = Connection.GetDatabase();`. Box 2: `cache KeyDelete('Team');`.
- [ ] Box 1: `ICache cache = Connection.GetDatabase();`. Box 2: `cache StringGet('Team', '');`.

> #### ✅ 正确答案：
>
> - `IDatabase cache = Connection.GetDatabase();`
>    👉 这是 `StackExchange.Redis` 提供的 Redis 客户端类型。
> - `cache.KeyDelete("Team");`
>    👉 删除名为 `"Team"` 的 key，实现缓存失效。
>
> ------
>
> #### ❌ 错误选项解释：
>
> - ❌ `cache.StringSet('Team', '');`
>    👉 这只是设置一个空字符串，并 **不会使缓存失效**，仍然会被命中。
> - ❌ `ICache cache = Connection.GetDatabase();`
>    👉 没有叫 `ICache` 的类型，应该是 `IDatabase`。
> - ❌ `cache.StringGet('Team', '');`
>    👉 `StringGet` 是**读取**操作，不是删除。

**[⬆ Back to Top](#table-of-contents)**

### A company has multiple warehouses. Each warehouse contains IoT temperature devices which deliver temperature data to an Azure Service Bus queue. You need to send email alerts to facility supervisors immediately if the temperature at a warehouse goes above or below specified threshold temperatures. Which five actions should you perform in sequence?

![Question 139](images/question139.png)

- [x] Box 1: Create a blank Logic app. Box 2: Add a logic app trigger that fires when one or more messages arrive in the queue. Box 3: Add an action that reads IoT temperature data from the Service Bus queue. Box 4: Add a condition that compares the temperature against the upper and lower thresholds. Box 5: Add an action that sends an email to
specified personnel if the temperature is outside of those thresholds.
- [ ] Box 1: Add a trigger that reads IoT temperature data from a Service Bus queue. Box 2: Add a condition that compares the temperature against the upper and lower thresholds. Box 3: Add a logic app action that fires when one or more messages arrive in the queue. Box 4: Create a blank Logic app. Box 5: Add an action that sends an email to specified personnel if the temperature is outside of those thresholds.
- [ ] Box 1: Add a condition that compares the temperature against the upper and lower thresholds. Box 2: Outbound. Box 3: Add a Recurence rigge that schedules the app to run every 15 minutes. Box 4: Add a trigger that reads IoT temperature data from a Service Bus queue. Box 5: Create a blank Logic app.
- [ ] Box 1: Create a blank Logic app. Box 2: Add a logic app action that fires when one or more messages arrive in the queue. Box 3: Add a condition that compares the temperature against the upper and lower thresholds. Box 4: Add an action that reads IoT temperature data from the Service Bus queue. Box 5: Add a condition that compares the temperature against the upper and lower thresholds.

> ### ✅ 理由解析：
>
> 要用 **Azure Logic App** 实现当某个仓库的温度超过或低于阈值时发送邮件告警，需按如下顺序配置：
>
> 1. **创建 Logic App**：先搭建流程框架。
> 2. **添加触发器（Trigger）**：当 **Service Bus Queue** 中有新消息时触发流程。
> 3. **读取数据（Action）**：从队列中获取 IoT 发送的温度数据。
> 4. **设置条件判断（Condition）**：检查温度是否超出上下限阈值。
> 5. **发送邮件通知（Action）**：如果条件满足（即温度异常），则通知相关人员。

**[⬆ Back to Top](#table-of-contents)**

### You are creating a hazard notification system that has a single signaling server which triggers audio and visual alarms to start and stop. You implement Azure Service Bus to publish alarms. Each alarm controller uses Azure Service Bus to receive alarm signals as part of a transaction. Alarm events must be recorded for audit purposes. Each transaction record must include information about the alarm type that was activated. You need to implement a reply trail auditing solution. Which two actions should you perform?

- [x] Assign the value of the hazard message `SessionID` property to the `ReplyToSessionId` property.
- [ ] Assign the value of the hazard message `MessageId` property to the `DevileryCount` property.
- [ ] Assign the value of the hazard message `SessionID` property to the `SequenceNumber` property.
- [x] Assign the value of the hazard message `MessageId` property to the `CorrelationId` property.
- [ ] Assign the value of the hazard message `SequenceNumber` property to the `DeliveryCount` property.
- [ ] Assign the value of the hazard message `MessageId` property to the `SequenceNumber` property.

> ###  原因解析：
>
> #### ✅ `MessageId ➝ CorrelationId`
>
> - `MessageId` 是消息的唯一标识符。
> - 将它赋值给响应消息的 `CorrelationId`，可以让系统或审计逻辑清楚地知道这条响应是与哪条原始消息关联的。
> - 这是标准做法，用于实现**请求-响应关联**。
>
> #### ✅ `SessionID ➝ ReplyToSessionId`
>
> - `SessionID` 用于将一组相关消息分组在一起，通常用于控制并发和顺序处理。
> - 将其设置为 `ReplyToSessionId` 意味着响应消息也会回到同一个会话，从而可以实现对话上下文的**消息轨迹追踪**。
>
> ------
>
> ### 🚫 错误选项说明：
>
> - ❌ `MessageId ➝ DeliveryCount`
>    `DeliveryCount` 是系统管理字段，用于记录消息的投递次数。它不能也不应手动设置。
> - ❌ `SessionID ➝ SequenceNumber`
>    `SequenceNumber` 是由 Service Bus 自动递增的消息序号，也不应手动赋值。
> - ❌ `MessageId ➝ SequenceNumber`
>    同上，`SequenceNumber` 是系统字段，不能用于消息相关性。
> - ❌ `SequenceNumber ➝ DeliveryCount`
>    两者都是系统生成字段，不应手动设置，也无法建立正确的审计关系。

**[⬆ Back to Top](#table-of-contents)**

### You are developing applications for a company. You plan to host the applications on Azure App Services. The company has the following requirements: Every five minutes verify that the websites are responsive. Verify that the websites respond within a specified time threshold. Dependent requests such as images and JavaScript files must load properly. Generate alerts if a website is experiencing issues. If a website fails to load, the system must attempt to reload the site three more times. You need to implement this process with the least amount of effort. What should you do?

- [ ] Create a Selenium web test and configure it to run from your workstation as a scheduled task.
- [x] Set up a URL ping test to query the home page.
- [ ] Create an Azure function to query the home page.
- [ ] Create a multi-step web test to query the home page.
- [ ] Create a Custom Track Availability Test to query the home page.

> ### ✅ 为什么选择 **Multi-step web test**：
>
> - 支持模拟浏览器行为，包括加载图像、脚本等。
> - 可以模拟多个请求（比如加载主页后再加载图像、JS 等资源）。
> - 允许在测试中添加逻辑判断，例如失败时重试。
> - 与 **Application Insights** 集成，可以自动运行、收集性能数据，并触发告警。
>
> ------
>
> ### 🚫 错误选项分析：
>
> #### ❌ `Create a Selenium web test and configure it to run from your workstation as a scheduled task`
>
> - 可行，但不建议：本地环境依赖强、不可扩展、不可靠。
>
> #### ❌ `Set up a URL ping test to query the home page`
>
> - 只能检查**单个 URL 的响应**，不会检测图像、JS 加载情况，也无法进行多步操作或重试逻辑。
>
> #### ❌ `Create an Azure function to query the home page`
>
> - 可自定义实现逻辑，但你需要编写较多代码，监控功能要自己开发，**并不“最省力”**。
>
> #### ❌ `Create a Custom Track Availability Test to query the home page`
>
> - 类似于 URL ping test，适合简单探测，**不支持依赖项验证和重试逻辑**。

**[⬆ Back to Top](#table-of-contents)**

### You develop and add several functions to an Azure Function app that uses the latest runtime host. The functions contain several REST API endpoints secured by using SSL. The Azure Function app runs in a Consumption plan. You must send an alert when any of the function endpoints are unavailable or responding too slowly. You need to monitor the availability and responsiveness of the functions. What should you do?

- [ ] Create a URL ping test.
- [x] Create a timer triggered function that calls `TrackAvailability()` and send the results to Application Insights.
- [ ] Create a timer triggered function that calls `GetMetric('Request Size')` and send the results to Application Insights.
- [ ] Add a new diagnostic setting to the Azure Function app. Enable the `FunctionAppLogs` and Send to Log Analytics options.

> ### ✅ 为什么选 `Create a URL ping test`？
>
> **URL ping test** 是 **Application Insights 中可用性测试的一种类型**，适合监控 HTTP(S) 端点是否正常工作，主要优势：
>
> - 可配置频率（如每 5 分钟）
> - 检查 REST API 是否返回 200 OK
> - 检查响应时间是否超过阈值
> - 可配置警报（如响应超时或失败次数超过 X 次）
> - 无需修改已有函数代码，**最小侵入**
>
> ------
>
> ### 🚫 其他选项分析：
>
> #### ❌ `Create a timer triggered function that calls TrackAvailability()`
>
> - `TrackAvailability()` 是手动发送可用性数据的方法，但你必须写代码并维护计时器函数。
> - 功能与 URL ping test 重叠，但实现成本更高。
> - 不如直接用 Application Insights 的可用性测试省事可靠。
>
> #### ❌ `Create a timer triggered function that calls GetMetric('Request Size')`
>
> - `Request Size` 是度量函数调用大小的指标，和“是否可用”、“响应慢”无关。
>
> #### ❌ `Add a new diagnostic setting...`
>
> - 这会把日志发到 Log Analytics，但不能直接实现“定时探测+判断响应时间+报警”功能。
> - 主要用于**诊断与查询分析**，不是主动式监控手段。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an e-commerce solution that uses a microservice architecture. You need to design a communication backplane for communicating transactional messages between various parts of the solution. Messages must be communicated in first-in-first-out (FIFO) order. What should you use?

- [ ] Azure Storage Queue.
- [ ] Azure Event Hub.
- [x] Azure Service Bus.
- [ ] Azure Event Grid.

> ### ✅ 解释：为什么选择 **Azure Service Bus**
>
> 你需要实现的是：
>
> - **微服务之间的通信**
> - **事务性消息**
> - **FIFO 顺序（先进先出）**
>
> 这三个要求最适合使用 **Azure Service Bus**，因为：
>
> | 要求       | Azure Service Bus 的支持                              |
> | ---------- | ----------------------------------------------------- |
> | 微服务通信 | 原生支持异步解耦、可靠交互                            |
> | 事务支持   | ✅ 支持原子性操作（发送+接收）                         |
> | FIFO 保证  | ✅ 使用 **Sessions** 或 **Message Ordering** 实现 FIFO |
>
> 
>
> ------
>
> ### ❌ 其他选项对比：
>
> | 选项                    | 缺点                                                         |
> | ----------------------- | ------------------------------------------------------------ |
> | **Azure Storage Queue** | 无法保证严格 FIFO，且不支持高级消息路由、事务                |
> | **Azure Event Hub**     | 适用于**遥测/日志流**场景，不能用于事务处理或消息确认（只支持处理流） |
> | **Azure Event Grid**    | 事件驱动架构，**非消息队列**，不保证 FIFO，也不适合事务处理  |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Service Bus Queue from the mobile application. Create an Azure Function App that uses an Azure Service Bus Queue trigger. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> #### ✔️ **队列大小限制不超过 80GB**
>
> - Azure Service Bus 的 **高级（Premium）层** 支持每个实体最多 **80GB 或更大**，满足要求。
> - 注意：标准层最多 1GB 或 5GB，需要使用高级层。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Notification Hub. Register all devices with the hub. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> #### ✔️ 推荐方案：
>
> 使用 **Azure Event Hubs** 或 **Azure IoT Hub** 来**接收设备上传的数据**，并通过后端服务将数据**写入 Azure Blob Storage**，按照 `device ID` 分类或打标签。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Service Bus. Configure a topic to receive the device data by using a correlation filter. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

>  **不满足目标**：
> Service Bus 设计用于企业级消息传递场景，**并不适合处理大规模设备遥测数据**（如 IoT 场景）。吞吐能力有限，难以支撑每天 20GB 数据、上万设备并发的情况.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure event filtering to evaluate the device identifier. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ❌ **不满足目标**：
>  Azure Event Grid 是事件通知系统，并非为高吞吐设备数据摄取场景设计，无法有效接收、处理并存储来自数千台设备的数据。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure Function App that uses an Azure Storage Queue trigger. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Azure **Storage Queue** 本质上不保证严格的 FIFO 顺序，只是**尽最大可能按插入顺序处理**，但并非严格 FIFO。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure VM that is triggered from Azure Storage Queue events. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that will use Azure messaging services. You need to ensure that the solution uses a publish-subscribe model and eliminates the need for constant polling. What are two possible ways to achieve the goal?

- [x] Service Bus.
- [ ] Event Hub.
- [x] Event Grid.
- [ ] Queue.

> **Azure Service Bus** 是一个功能非常强大的消息服务，它既支持传统的 **队列（Queue）** 模式，也支持 **发布-订阅（Publish-Subscribe）** 模式，具体如下：
>
> ------
>
> ### ✅ **1. Azure Service Bus Queue**
>
> - **模型**：点对点（Point-to-Point）
> - **发送者**：将消息发送到队列中。
> - **接收者**：一个接收者从队列中读取并处理消息。
> - **特点**：
>   - FIFO（先进先出）支持
>   - 支持重复检测、事务、死信队列（DLQ）
>   - 类似 Azure Storage Queue，但更强大（例如支持复杂消息类型、事务、消息会话）
>
> ------
>
> ### ✅ **2. Azure Service Bus Topic + Subscription**
>
> - **模型**：发布-订阅（Publish-Subscribe）
>
> - **发送者**：向 Topic 发布消息
>
> - **接收者**：多个 Subscription 可以各自独立接收同一条消息副本
>
> - **特点**：
>
>   - 每个 Subscription 都像一个独立的队列
>
>   - 支持 **过滤器**（Filter）和 **动作（Action）**，可以根据消息属性将消息分发给不同订阅
>
>   - 一条消息可以送达多个订阅者，无需轮询（可绑定 Azure Function 等自动触发处理）
>
>     
>
> **Azure Service Bus更像邮局，Event Grid更像新闻社，但是他们都支持 publish-subscribe model， 以及是事件驱动，无需像Azure Storage Queue那样自己去轮询**

**[⬆ Back to Top](#table-of-contents)**

### A company is implementing a publish-subscribe (Pub/Sub) messaging component by using Azure Service Bus. You are developing the first subscription application. In the Azure portal you see that messages are being sent to the subscription for each topic. You create and initialize a subscription client object by supplying the correct details, but the subscription application is still not consuming the messages. You need to ensure that the subscription client processes all messages. Which code segment should you use?

- [ ] `await subscriptionClient.AddRuleAsync(new RuleDescription(RuleDescription.DefaultRuleName, new TrueFilter()));`.
- [ ] `subscriptionClient = new SubscriptionClient(ServiceBusConnectionString, TopicName, SubscriptionName);`.
- [ ] `await subscriptionClient.CloseAsync();`.
- [x] `subscriptionClient.RegisterMessageHandler(ProcessMessagesAsync, messageHandlerOptions);`.

> ### 注意：
>
> 你提到“subscription client 仍然没有消费消息”，这可能是因为**缺少 StartProcessingAsync** 或 **没有注册 message handler**。
>
> ------
>
> ### 如果你用的是旧的 `Microsoft.Azure.ServiceBus` SDK，则应使用：
>
> ```C#
> SubscriptionClient client = new SubscriptionClient(connectionString, topicName, subscriptionName);
> 
> client.RegisterMessageHandler(
>     async (message, token) =>
>     {
>         string body = Encoding.UTF8.GetString(message.Body);
>         Console.WriteLine($"Received: {body}");
> 
>         await client.CompleteAsync(message.SystemProperties.LockToken);
>     },
>     new MessageHandlerOptions(args =>
>     {
>         Console.WriteLine(args.Exception);
>         return Task.CompletedTask;
>     })
> );
> ```
>
> ### 结论：
>
> 你需要添加或修正的是这一句核心代码：
>
> > ✅ `RegisterMessageHandler(...)`（旧 SDK）
> >  ✅ `processor.ProcessMessageAsync += ...` 并调用 `StartProcessingAsync()`（新 SDK）
>
> 这才是真正**开始消费订阅消息**的关键。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Hub. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> | 需求                      | 是否满足 | 说明                                                         |
> | ------------------------- | -------- | ------------------------------------------------------------ |
> | 高吞吐量写入              | ✅        | Event Hub 专为高吞吐量设计（百万级事件/秒）                  |
> | 可扩展性                  | ✅        | 支持数千个设备/生产者，未来扩展无忧                          |
> | 数据持久化到 Blob Storage | ✅        | 启用 **Event Hub Capture**，可将数据自动写入 Azure Blob Storage 或 Data Lake |
> | 基于设备ID聚合            | ✅        | 设置 **partition key 为 device ID**，这样可以确保同一个设备的事件进入同一个分区，便于按设备聚合和分析 |
> | 多设备多地区支持          | ✅        | 没有地理或设备数量限制                                       |
> | 成本效率                  | ✅        | 相比 Event Grid 或 IoT Hub，Event Hub 更适合**大批量、顺序性要求低**的事件数据 |

**[⬆ Back to Top](#table-of-contents)**

### A company is developing a solution that allows smart refrigerators to send temperature information to a central location. The solution must receive and store messages until they can be processed. You create an Azure Service Bus instance by providing a name, pricing tier, subscription, resource group, and location. You need to complete the configuration. Which Azure CLI or PowerShell command should you run?

- [ ] `az group create --name fridge-rg --location fridge-loc`.
- [ ] `New-AzureRmServiceBusNamespace -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Location fridge-loc`.
- [x] `New-AzureRmServiceBusQueue -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Name fridge-q -EnablePartitioning $False`.
- [ ] `az servicebus namespace create --resource-group fridge-rg --name fridge-rg --location fridge-loc`.

> ### 选项分析：
>
> 1. `az group create --name fridge-rg --location fridge-loc`
>    - 这是创建 **资源组** 的命令，不是配置 Service Bus。
>    - **不正确**，这是基础资源组创建。
> 2. `New-AzureRmServiceBusNamespace -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Location fridge-loc`
>    - 这是 PowerShell 命令，用于**创建 Service Bus 命名空间（Namespace）**。
>    - 这步是必需的，但题目说“已经创建了 Service Bus 实例”，所以可能已经完成。
>    - **不完全符合题目要求**（完成配置），但如果没有命名空间的话必须执行。
> 3. `New-AzureRmServiceBusQueue -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Name fridge-q -EnablePartitioning $False`
>    - 这是 PowerShell 命令，用于**创建 Service Bus 队列**。
>    - 这一步才是“完成配置”的关键：创建用于接收消息的队列。
>    - **正确答案**。
> 4. `az servicebus namespace create --resource-group fridge-rg --name fridge-rg --location fridge-loc`
>    - 这是用 Azure CLI 创建 Service Bus 命名空间的命令。
>    - 注意这里 `--name fridge-rg`，和资源组名相同，实际应是命名空间名称，不一定是资源组名。
>    - 同样这是创建命名空间，跟题意“完成配置”中创建队列相比，不是最终目标。
>    - **不是关键答案**。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Container` blade. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 问题回顾
>
> - 你想**识别 Jon Ross 使用的 Azure Resource Manager (ARM) 模板**，用于部署虚拟机和存储账户。
> - 你的操作是**访问了 Storage Account 里的 Container（容器）面板**。
>
> ------
>
> ### 为什么不满足目标？
>
> - **Container blade（容器面板）只是显示 Blob 存储容器内容**，与 ARM 模板无关。
> - ARM 模板是部署资源的 JSON 文件，通常存储在源码管理、模板库或部署历史中。
> - 通过 Container 面板，无法查看或追踪到哪个 ARM 模板被用来部署资源。
>
> ------
>
> ### 如何正确识别 ARM 模板？
>
> 你可以：
>
> 1. **查看部署历史（Deployments）**
>    - 在 Azure Portal 中，进入对应的 **资源组**，然后点击 **Deployments（部署）**。
>    - 这里会列出所有通过 ARM 模板或其他方式部署的记录，可以看到模板文件或参数。
> 2. **询问 Jon Ross**
>    - 直接联系他获取模板文件或源码仓库地址。
> 3. **查看版本控制系统**
>    - 如果团队使用 Git 或其他版本管理工具，ARM 模板通常会存储在仓库中。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Virtual Machine` blade. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Resource Group` blade. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ### 为什么访问 Resource Group 可以达成目的？
>
> 在 Azure Portal 中，**Resource Group（资源组）blade** 包含以下内容：
>
> - 已部署的所有资源清单（包括虚拟机、存储账户等）
> - 一个名为 **Deployments（部署）** 的子菜单
>   - 在这里你可以：
>     - 查看所有通过 ARM 模板进行的部署记录
>     - 查看每次部署中使用的模板（包括模板文件、参数、输出）
>     - 下载或导出模板文件

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then enable the Use for App service option. Does this meet the goal?

- [x] Yes.
- [ ] No.

> ### ✅ 正确的做法应包括：
>
> - 在 App Gateway 中添加一个 **HTTPS Listener**
> - 上传并绑定一个有效的 **SSL 证书**
> - 配置一个 Rule 使用该 HTTPS Listener，指向 `mywebapp1.azurewebsites.net`
> - 设置 HTTP 设置时启用 **“Use for App Service”**
> - 如果需要，开启 **SSL termination 或 end-to-end SSL**
>
> ------
>
> ### ✅ 补充说明：Override backend path 和 Use for App service 是做什么的？
>
> | 设置                      | 说明                                                         |
> | ------------------------- | ------------------------------------------------------------ |
> | **Override backend path** | 替换 Application Gateway 发送到后端的路径。例如路径重写。    |
> | **Use for App service**   | 启用 Application Gateway 与 Azure App Service 之间的专用集成通道（自动处理主机头、SNI、健康探测等）。 |
>
> 
>
> 它们只是**配置连接 App Service 的选项**，**本身并不启用 HTTPS 或实现加密通信**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You configure `mywebapp1` to run in an Azure App service environment (ASE). Does this meet the goal?

- [ ] Yes.
- [x] No.

> 将 Web App 部署到 **App Service Environment (ASE)** 本身：
>
> - ✅ 提供更高的网络隔离（运行在你自己的虚拟网络中）
> - ✅ 支持高级网络配置
> - ❌ **但它本身并不会启用或强制 HTTPS/SSL 通信**
>
> 你仍然需要：

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then add an authentication certificate for `mywebapp1.azurewebsites.net`. Does this meet the goal?

- [ ] Yes.
- [x] No.

> ### ❌ 为什么这个方案**不满足目标**：
>
> 虽然你添加了后端身份验证证书，这有助于：
>
> - 让 Application Gateway 与 App Service（mywebapp1）之间建立**受信任的 HTTPS 通信**
>
> 但这**只是保护了 Application Gateway → Web App 的流量**
>
> > ✅ “后端”是安全的
> >  ❌ “客户端（用户）→ Application Gateway”的那一段**仍然可能是 HTTP**

**[⬆ Back to Top](#table-of-contents)**

### Your company has a web app named `WebApp1`. You use the WebJobs SDK to design a triggered App Service background task that automatically invokes a function in the code every time new data is received in a queue. You are preparing to configure the service processes a queue data item. Which of the following is the service you should use?

- [ ] Logic Apps.
- [x] WebJobs.
- [ ] Flow.
- [ ] Functions.

> | 选项                       | 描述                                                         | 是否适合          |
> | -------------------------- | ------------------------------------------------------------ | ----------------- |
> | **✅ WebJobs**              | Azure App Service 的后台作业服务，**支持使用 WebJobs SDK**，可与队列（如 Azure Storage Queue）绑定，适合处理触发式任务 | ✅ 正确答案        |
> | **Azure Functions**        | 虽然也可以处理队列触发器，而且功能比 WebJobs 更现代化，但题干明确说使用了 “WebJobs SDK” | ❌（不是本题重点） |
> | **Logic Apps**             | 用于低代码自动化流程，适合业务流程编排，不是代码级触发任务的首选 | ❌                 |
> | **Flow（Power Automate）** | 旧称 Flow，面向业务用户的自动化工具，不适合后台服务开发      | ❌                 |

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformFaultDomainCount` property?

- [ ] 10.
- [ ] 30.
- [ ] Min Value.
- [x] Max Value.

> `platformFaultDomainCount` 控制可用性集跨越多少个物理故障域。
>
> 要在出现机架、电源或网络故障时仍保持最多虚拟机可用，你应选择该属性的 **最大可支持值**（通常为 3，部分地区为 2）。
>
> **选择 "Max Value"** 意味着你告诉 Azure：请尽可能地将虚拟机分布在多个故障域中。
>
> ### 🔧 Fault Domain 是什么？
>
> - 通常是 **不同的物理服务器机架（rack）**。
> - 每个 rack 有独立的：
>   - 电源
>   - 网络交换设备
>   - 冷却系统
>
> Azure 会将你的虚拟机**分布在多个 Fault Domain 中**，以确保：
>
> - 即使某个 rack 的硬件、电源或网络故障，
> - 其他 rack 上的 VM 仍然可以继续运行，
> - 从而提高你的应用高可用性。

**[⬆ Back to Top](#table-of-contents)**

### You have two Hyper-V hosts named `Host1` and `Host2`. Host1 has an Azure virtual machine named `VM1` that was deployed by using a custom Azure Resource Manager template. You need to move `VM1` to `Host2`. What should you do?

- [ ] From the `Update management` blade, click Enable.
- [ ] From the `Overview` blade, move `VM1` to a different subscription.
- [x] From the `Redeploy` blade, click Redeploy.
- [ ] From the `Profile` blade, modify the usage location.

> **Hyper-V** 是微软提供的一个虚拟化平台，允许你在一台物理计算机上运行多个虚拟机。每个虚拟机都像是一台独立的计算机，有自己的操作系统、内存、存储、网络等资源。
>
> - `Host1` 和 `Host2` 都是物理服务器，安装了 Windows Server，并启用了 Hyper-V。
> - `VM1` 是运行在 `Host1` 上的一个虚拟机，你可以把它迁移到 `Host2`。
>
> | 选项                                              | 作用                                                         | 是否满足目标 |
> | ------------------------------------------------- | ------------------------------------------------------------ | ------------ |
> | ✅ `Update management` → Enable                    | 这是启用自动更新管理，与 VM 迁移无关。                       | ❌            |
> | ✅ `Overview` → move VM1 to different subscription | 这是在 Azure 订阅之间移动资源，而不是在本地 Hyper-V 主机间迁移。 | ❌            |
> | ✅ `Redeploy` → click Redeploy                     | 在 Azure 中重新部署 VM 到另一个计算节点，但依然在 Azure 云中，不是本地迁移。 | ❌            |
> | ✅ `Profile` → modify usage location               | 用于设置计费相关的地理位置，与 VM 迁移完全无关。             | ❌            |

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the Azure CLI on the device and run the `kubectl apply -f myapp.yaml` command. Does this meet the goal?

- [x] Yes.
- [ ] No.

> ### ✅ 最完整的步骤：
>
> ```shell
> # 1. 登录 Azure
> az login
> 
> # 2. 安装 kubectl（如果还没装）
> az aks install-cli
> 
> # 3. 获取 AKS 集群凭据
> az aks get-credentials --resource-group <your-rg> --name <your-aks-name>
> 
> # 4. 部署 YAML 文件
> kubectl apply -f myapp.yaml
> ```

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the docker client on the device and run the `docker run -it microsoft/azure-cli:0.10.17` command. Does this meet the goal?

- [ ] Yes.
- [x] No.

> 你需要将一个已打包的容器镜像（`MyApp`）通过 **YAML manifest 文件** 部署到 AKS 集群中。
>
> 而题目中提供的操作：
>
> ```
> docker run -it microsoft/azure-cli:0.10.17
> ```
>
> 这只是 **在 Docker 容器中运行了一个旧版本的 Azure CLI**，并没有：
>
> - 部署 YAML 文件
> - 获取 AKS 集群凭据（`az aks get-credentials`）
> - 使用 `kubectl` 命令部署资源

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformUpdateDomainCount` property?

- [ ] 10.
- [x] 20.
- [ ] 30.
- [ ] 40.

> `platformUpdateDomainCount` 是一个用于 **Availability Set** 的属性，用于指定 Azure 在执行维护或升级时使用多少个更新域（Update Domains，UD）。
>
> 默认值是 `5`，最大值通常为 `20`（根据区域和订阅有细微差别）。
>
> 
>
> 一个 **更新域** 是一个**逻辑分组**，Azure 会**一次只更新一个更新域中的虚拟机**。
>
> ------
>
> ### 🔍 举个例子：
>
> 你有一个 Availability Set 中的 6 台虚拟机，设置 `platformUpdateDomainCount: 3`。
>
> Azure 会将它们分成 3 个更新域：
>
> | 更新域编号 | 包含的虚拟机 |
> | ---------- | ------------ |
> | UD0        | VM1, VM4     |
> | UD1        | VM2, VM5     |
> | UD2        | VM3, VM6     |
>
> 当 Azure 进行维护时，比如打补丁重启主机，会这样执行：
>
> 1. 首先只对 **UD0** 的机器做维护；
> 2. 然后等待完成，再对 **UD1** 做维护；
> 3. 最后是 **UD2**。
>
> ✅ 这样就不会一次性把所有 VM 全部重启，能保持服务连续性。

**[⬆ Back to Top](#table-of-contents)**

### You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Triggered WebJob type. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Azure WebJob 是 Azure App Service 中的一种后台任务功能，允许你在 Web 应用（Web App）所属的 App Service 环境中运行后台程序。你可以把它想象成一种“跟网站一起部署和运行的脚本/任务处理器”。
>
> | 类型                       | 描述                                           | 场景                                  |
> | -------------------------- | ---------------------------------------------- | ------------------------------------- |
> | **Continuous（持续运行）** | 应用启动后持续运行，适合监听型任务，如队列监控 | 如监听 Azure Storage Queue 中的新消息 |
> | **Triggered（触发运行）**  | 通过时间计划（cron）或手动调用                 | 如每天晚上运行清理脚本、定期数据导入  |
>
> | 项目     | WebJobs                        | Azure Functions                |
> | -------- | ------------------------------ | ------------------------------ |
> | 部署方式 | 与 Web App 一起部署            | 独立部署（Serverless）         |
> | 托管模式 | App Service Plan               | Consumption 或 Premium Plan    |
> | 成本     | 固定（取决于 App Service）     | 按需计费                       |
> | 推荐场景 | Web App 需要紧密集成的后台任务 | 独立、弹性、事件驱动的任务处理 |
>
> 要在 **Azure Web App** 中设计一个 **WebJob**，并满足以下两个条件：
>
> 1. ✅ 与 Web App **部署在同一实例**（共用资源）
> 2. ✅ 能够 **限制 WebJob 仅在一个实例上运行**
>
> 你应该选择的 **WebJob 类型** 是：
>
> ------
>
> ### ✅ **Continuous WebJob（持续运行型 WebJob）**
>
> **原因：**
>
> - Continuous WebJob 是与 Web App 一起持续运行的后台任务，常用于队列监听或持续执行的逻辑。
> - Azure 支持为 Continuous WebJob **配置“Always On”并限制只在一个实例上运行**。

**[⬆ Back to Top](#table-of-contents)**

### You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Continuous WebJob type. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You company has an on-premises deployment of MongoDB, and an Azure Cosmos DB account that makes use of the MongoDB API. You need to devise a strategy to migrate MongoDB to the Azure Cosmos DB account. You include the [Data Management Gateway] tool in your migration strategy.

- [ ] No change required.
- [x] mongorestore.
- [ ] Azure Storage Explorer.
- [ ] `AzCopy`.

> ## ✅ 推荐迁移策略
>
> 可以使用以下方法之一：
>
> ### 方法 1：Azure Data Factory + Self-hosted Integration Runtime
>
> 1. 在本地安装 **Self-hosted Integration Runtime（即 Data Management Gateway）**
> 2. 使用 Azure Data Factory：
>    - 源：本地 MongoDB
>    - 目标：Azure Cosmos DB（MongoDB API）
> 3. 创建数据迁移管道，进行一次性或定期同步迁移。
>
> ### 方法 2：MongoDB 原生工具（适用于一次性迁移）
>
> 使用如下工具：
>
> - `mongodump` + `mongorestore`（通过 Cosmos 提供的连接字符串）
> - `mongoimport` / `mongoexport`
>
> 但这类方法不适合定期同步或处理大型数据量。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Event Grid with a subscriber Azure Function app. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 这个解决方案并**不**能完全满足所有要求。
>
> 以下是详细分析：
>
> - **处理异步事件和元数据更改：** Azure Event Grid 非常适合这个需求。当 Azure Blob 存储中发生更改时，Event Grid 会立即发布事件，你的 Azure Function 应用作为订阅者可以异步地处理这些事件。这部分要求是满足的。
> - **按事件发生的顺序处理更改：** Event Grid **不保证**事件的顺序。虽然它通常会按照顺序发送事件，但在高负载或系统故障的情况下，事件可能会无序到达。因此，仅仅依赖 Event Grid 无法保证按顺序处理。
> - **保留更改以用于合规性：** Event Grid 的核心功能是传递事件，而不是持久化事件以供长期保留。Event Grid 事件在被传递给订阅者后，其生命周期就结束了。如果订阅者无法及时处理事件，Event Grid 会进行重试，但如果重试失败，事件可能会丢失。为了合规性，你需要一个单独的机制来持久化这些事件或处理结果，例如将事件写入一个持久性存储（如 Azure Blob 存储、Azure Cosmos DB）或者使用具有消息持久化能力的服务（如 Azure Service Bus 或 Azure Event Hubs）。仅仅使用 Event Grid 和 Azure Function 无法满足长期保留的要求。
>
> ##  满足该场景的推荐方式：
>
> - 使用 **Azure Event Grid + Azure Function** 来处理事件
> - 使用 **Service Bus Queue (with sessions)** 或 **Event Hubs** 保证事件顺序
> - 使用 **Cosmos DB / Azure Data Lake / Blob Archive Tier** 来做合规性数据持久存储

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Monitor HTTP Data Collector API. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the follows transact-SQL statement: `ALTER TABLE [dbo].[Weyland].[Customers] ALTER COLUMN [email_address] ADD MASKED WITH (FUNCTION = 'email()')`. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> Dynamic Data Masking 是 Azure SQL Database 的一项功能，可以**防止对敏感数据的非授权访问**，通过在查询结果中“掩码”数据来实现，比如邮箱、信用卡等字段。
>
> ```sql
> ALTER TABLE [dbo].[Customers]
> ALTER COLUMN [email_address] 
> ADD MASKED WITH (FUNCTION = 'email()');
> ```
>
> 在 `[dbo].[Customers]` 表中的 `email_address` 列上应用掩码函数 `email()`，使其在查询时自动显示为 `aXXX@XXXX.com` 这种形式（掩盖大部分 email 地址）。 
>
> =>题干中[dbo].[Weyland].[Customers]虽然有小错误，但推测是抄录笔误

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'` Powershell cmdlet Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 你运行的 PowerShell 命令 `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'`
>  这个命令只是在数据库层面**启用或禁用动态数据掩码策略**，
>  并**没有配置具体哪个表、哪个字段需要掩码**。
>
> 实现对 `Customers` 表中 `email_address` 字段的动态数据掩码，必须为该**特定列单独添加掩码规则**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingRule -DatabaseName 'Weyland' -SchemaName 'dbo' -TableName 'Customers' -ColumnName 'email_address' -MaskingFunction 'email'` Powershell cmdlet Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 关于在 Azure SQL 数据库中实现 **动态数据掩码（Dynamic Data Masking, DDM）**，主要有以下几种常见方式：
>
> ------
>
> ## 1. **使用 T-SQL 语句直接在数据库中配置**
>
> - 通过 `ALTER TABLE` 语句给指定列添加掩码规则：
>
> ```sql
> ALTER TABLE dbo.Customers
> ALTER COLUMN email_address
> ADD MASKED WITH (FUNCTION = 'email()');
> ```
>
> - 适合直接在数据库中操作，也可以放入迁移脚本。
>
> ------
>
> ## 2. **通过 Azure PowerShell 命令配置**
>
> - **启用数据库级别掩码策略**（可选，默认一般已启用）：
>
> ```
> Set-AzSqlDatabaseDataMaskingPolicy -ResourceGroupName "rg" -ServerName "server" -DatabaseName "Weyland" -DataMaskingState Enabled
> ```
>
> - **为具体字段添加掩码规则**：
>
> ```
> New-AzSqlDatabaseDataMaskingRule -ResourceGroupName "rg" -ServerName "server" -DatabaseName "Weyland" `
>   -SchemaName "dbo" -TableName "Customers" -ColumnName "email_address" -MaskingFunction "Email"
> ```
>
> - 或用 `Set-AzSqlDatabaseDataMaskingRule` 修改已存在规则。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an e-Commerce Web App. You want to use Azure Key Vault to ensure that sign-ins to the e-Commerce Web App are secured by using Azure App Service authentication and Microsoft Entra ID. What should you do on the e-Commerce Web App?

- [ ] Run the `az keyvault secret` command.
- [ ] Enable Microsoft Entra ID Connect.
- [x] Enable Managed Service Identity (MSI).
- [ ] Create an Microsoft Entra ID service principal.

> ### 关键点：
>
> - Azure App Service Authentication（也叫 Easy Auth）本身支持集成 Microsoft Entra ID 进行用户认证。
> - 使用 **Azure Key Vault** 的主要目的是安全地管理和存储敏感信息（如客户端机密 `client secret`），避免在应用配置中直接暴露。
> - 你需要将 Key Vault 中存储的机密（比如 Azure AD 应用的客户端机密）与 App Service 的认证配置集成起来。
>
> ------
>
> ### 应该做的步骤：
>
> 1. **在 Azure Key Vault 中存储 Microsoft Entra ID 应用的机密**（Client Secret）。
> 2. **为 Azure App Service 启用托管身份（Managed Identity）**，允许它访问 Key Vault。
> 3. **在 Azure Key Vault 访问策略中授权该托管身份，允许读取机密**。
> 4. **配置 e-Commerce Web App 的身份验证设置**，使其使用托管身份从 Key Vault 获取客户端机密，或通过配置将机密引用为应用设置中的 Key Vault 机密引用。
> 5. **在 Azure App Service 的应用设置中，通过 Key Vault 引用配置敏感信息**
> 6. **启用并配置 Azure App Service Authentication，选择 Microsoft Entra ID 作为身份提供者。**
>
> 如果只回答针对“**在 e-Commerce Web App 上你应该做什么**”，最核心的动作是：
>
> > **启用托管身份（Managed Identity），并在应用设置中通过 Key Vault 机密引用方式来使用 Azure AD 应用的客户端机密。**
>
> =>“Managed Service Identity”（MSI）和“Managed Identity”（MI）其实指的是同一个概念，Microsoft 后来正式将名称统一成了 **Managed Identity**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app that uses Microsoft Entra ID for authentication. You want to configure the web app to use multifactor authentication. What should you do?

- [ ] Enable mobile app authentication.
- [ ] In Microsoft Entra ID conditional access, enable the baseline policy.
- [x] In Microsoft Entra ID, create a conditional access policy.
- [ ] Install the Azure Multi-Factor Authentication Server.

> 要为使用 **Microsoft Entra ID（原 Azure AD）进行身份验证** 的 **Web 应用** 配置 **多重身份验证（MFA）**，你应该从 **Entra ID（Azure AD）配置 MFA 策略**，而不是直接在 Web App 中配置。以下是推荐的做法：
>
> ------
>
> ### ✅ **解决方案步骤**
>
> 1. **在 Microsoft Entra ID 中启用 MFA 策略**：
>    - 登录 Microsoft Entra 管理中心。
>    - 进入 `Protection` > `Conditional Access`。
>    - 创建新的 **条件访问策略**，指定：
>      - **分配对象**：要启用 MFA 的用户或组（例如 Web 应用使用者）。
>      - **云应用或操作**：选择你的 Web 应用（或 All cloud apps）。
>      - **授予控制**：选择 **Require multifactor authentication**。
> 2. **确保用户已注册 MFA**：
>    - 用户需要在第一次登录时完成 MFA 注册（手机验证、认证器 App、FIDO2 密钥等方式）。
> 3. （可选）**确保 Web 应用启用了 Microsoft Entra ID 认证**：
>    - 在 Azure Portal 中进入 Web App。
>    - 选择 **Authentication** > 启用身份验证。
>    - 添加身份提供者，选择 **Microsoft Entra ID**，配置客户端 ID 和重定向 URI。
>
> ### ✅ 正确选项（多选题场景中）
>
> -  **Create a Conditional Access policy in Microsoft Entra ID that requires MFA for the app**

**[⬆ Back to Top](#table-of-contents)**

### You are creating an Azure key vault using PowerShell. Objects deleted from the key vault must be kept for a set period of 90 days. Which two of the following parameters must be used in conjunction to meet the requirement? (Choose two.)

- [ ] `EnabledForDeployment`.
- [x] `EnablePurgeProtection`.
- [ ] `EnabledForTemplateDeployment`.
- [x] `EnableSoftDelete`.

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Azure Key Vault. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 要达到这个目的，你应该使用 **Microsoft Entra Conditional Access（条件访问）策略** 搭配 **风险策略（Risk-based policies）** 或 **Identity Protection**。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Identity Protection. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ### 正确的解决方案：
>
> #### ✔ 使用 **Microsoft Entra ID Identity Protection**
>
> 它可以：
>
> - 识别**未知或可疑 IP 地址**的登录（例如匿名代理、旅行时间不可能等）
> - 判断登录风险等级（Low / Medium / High）
> - 配置策略，在风险较高时：
>   - 要求用户重置密码 ✅
>   - 阻止访问
>   - 强制 MFA

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Privileged Identity Management. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Microsoft Entra ID Privileged Identity Management 的作用是：
>
> - **管理和审核**管理员权限（例如全局管理员、用户管理员等）
> - 提供临时的“按需分配”权限
> - 设置激活审批、多因素身份验证、访问期限等
>
> 👉 PIM 关注的是 **权限角色** 的生命周期管理，不具备：
>
> - 识别风险登录来源（例如未知 IP）
> - 自动触发密码更改操作的能力

**[⬆ Back to Top](#table-of-contents)**

### You manage an Azure SQL database that allows for Microsoft Entra ID authentication. You need to make sure that database developers can connect to the SQL database via Microsoft SQL Server Management Studio (SSMS). You also need to make sure the developers use their on-premises Active Directory account for authentication. Your strategy should allow for authentication prompts to be kept to a minimum. Which of the following should you implement?

- [ ] Microsoft Entra ID token.
- [ ] Azure Multi-Factor authentication.
- [ ] Active Directory integrated authentication.
- [ ] OATH software tokens.

> ###  **正确答案：**
>
> **✔️ Active Directory integrated authentication**
>
> ------
>
> ### 原因：
>
> - **Active Directory integrated authentication** 允许使用本地 Active Directory 登录。
> - 如果开发者的机器加入了域，并与域控制器连接，他们可以使用 **单点登录（SSO）** 连接 Azure SQL，无需重复输入用户名/密码。
> - 它通过 SSMS 使用 `Active Directory - Integrated` 模式，认证流程无缝对接，**认证提示最少**。
> - 前提是已配置好 Microsoft Entra Connect（Azure AD Connect）并启用了适当的身份验证桥接。
>
> ------
>
> ### ❌ 其他选项说明：
>
> | 选项                                  | 是否符合 | 原因                                                         |
> | ------------------------------------- | -------- | ------------------------------------------------------------ |
> | **Microsoft Entra ID token**          | ❌        | SSMS 不支持使用 token 直接连接 Azure SQL，需借助 CLI 工具等中转。 |
> | **Azure Multi-Factor Authentication** | ❌        | 增强安全性但会增加提示频率，与“认证提示最少”目标冲突。       |
> | **OATH software tokens**              | ❌        | 用于 MFA，不适用于主要身份验证，且增加操作步骤。             |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application to transfer data between on-premises file servers and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault and makes use of the Azure Key Vault APIs. You want to configure the application to allow recovery of an accidental deletion of the key vault or key vault objects for 90 days after deletion. What should you do?

- [ ] Run the `Add-AzKeyVaultKey` cmdlet.
- [x] Run the `az keyvault update --enable-soft-delete true --enable-purge-protection true` CLI.
- [ ] Implement virtual network service endpoints for Azure Key Vault.
- [ ] Run the `az keyvault update --enable-soft-delete false` CLI.

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of Azure Redis Cache in your design. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ###  为什么 Azure Redis Cache **不满足目标**？
>
> Azure Redis Cache 用于：
>
> - 提高应用程序的数据读取速度
> - 缓存数据库查询结果或 session 数据
> - 适合用于频繁访问的“小型数据对象”（如键值对）
>
> 但它**不是用于视频流媒体传输**，也**不具备地理分布式内容分发的能力**，也**无法提升视频播放的流畅度**。

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of an Azure Content Delivery Network (CDN) in your design. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ###  使用 Azure CDN 的效果：
>
> | 要求                     | Azure CDN 是否满足 | 说明                                                         |
> | ------------------------ | ------------------ | ------------------------------------------------------------ |
> | 高可用性                 | ✅ 是               | CDN 的 POP 节点遍布全球，避免单点故障                        |
> | 流畅播放体验（低延迟）   | ✅ 是               | 靠近用户分发内容，减少网络延迟                               |
> | 靠近用户地理位置存储数据 | ✅ 是               | CDN 自动缓存内容到离用户最近的边缘节点                       |
> | CI/CD                    | ⚠️ 需另外配置       | CDN 本身不提供 CI/CD，需要配合 Azure DevOps、GitHub Actions 等工具实现 |

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of a Storage Area Network (SAN) in your design. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **Storage Area Network (SAN)** 是一种高速专用网络，用于连接存储设备和服务器，主要用于企业内部数据存储，提供块级存储访问。
>
> 它适合于数据中心内部的存储需求，比如数据库服务器的磁盘存储。

**[⬆ Back to Top](#table-of-contents)**

### You develop a Web App on a tier D1 app service plan. You notice that page load times increase during periods of peak traffic. You want to implement automatic scaling when CPU load is above 80 percent. Your solution must minimize costs. What should you do first?

- [ ] Enable autoscaling on the Web App.
- [ ] Switch to the Premium App Service tier plan.
- [x] Switch to the Standard App Service tier plan.
- [ ] Switch to the Azure App Services consumption plan.

> App Service tier plan
>
> | 层级                       | 自动扩展能力（含实例上限）        | 部署槽支持         | 备份   | VNet 集成支持                   | 关键特性补充说明                         |
> | -------------------------- | --------------------------------- | ------------------ | ------ | ------------------------------- | ---------------------------------------- |
> | **Free (F1)**              | ❌ 不支持（每天 60 分钟 CPU 限制） | ❌ 不支持           | ❌ 无   | ❌ 无                            | 无法绑定自定义域名，仅用于学习测试       |
> | **Shared (D1)**            | ❌ 不支持（固定资源，低优先）      | ❌ 不支持           | ❌ 无   | ❌ 无                            | 与他人共享资源，功能受限                 |
> | **Basic (B1~B3)**          | ✅ 支持（最多 3 实例）             | ❌ 不支持           | ✅ 支持 | ❌ 无                            | 支持自定义域名与 SSL                     |
> | **Standard (S1~S3)**       | ✅ 支持（最多 10 实例）            | ✅ 支持最多 5 个槽  | ✅ 支持 | ✅ 支持基础集成                  | 适合中等流量应用，性价比高               |
> | **Premium v2 (P1v2~P3v2)** | ✅ 支持（最多 20 实例）            | ✅ 支持最多 20 个槽 | ✅ 支持 | ✅ 强化集成                      | 更高性能、更大内存、SSD 存储             |
> | **Premium v3 (P1v3~P3v3)** | ✅ 支持（最多 30+ 实例）           | ✅ 支持最多 30 个槽 | ✅ 支持 | ✅ 支持 Zone 冗余                | 高性能与企业级功能，推荐生产使用         |
> | **Isolated (I1~I3)**       | ✅ 支持（最多 100 实例）           | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ App Service Environment (ASE) | 网络完全隔离，适合高合规需求             |
> | **Isolated v2**            | ✅ 支持（最多 100 实例，按需扩展） | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ ASEv3，支持私有 IP            | 最强隔离性与性能，适合大型企业或政府项目 |

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the Azure resource. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 你需要为 Azure API Management (APIM) 配置后端身份验证，以确保 APIM 调用你 Azure App Service 中托管的 API 时，能够通过身份验证。
>
> ### 解析：
>
> - **Basic Gateway Credentials** 指的是在 Azure API Management (APIM) 中为后端服务配置的基本身份验证（用户名和密码）。
> - 如果你的 Azure App Service 托管的 API 后端要求使用 Basic Authentication，这种配置能确保 APIM 调用时携带正确的认证信息，从而完成身份验证。
>
> 
>
> ------
>
> ## 常见方案及步骤：
>
> ### 1. **选择认证类型**
>
> 后端认证常见类型有：
>
> - **基本认证（Basic Authentication）**：用户名+密码    =>**Basic Gateway Credentials** 是 APIM 配置后端 Basic Authentication 的一种具体实现。
> - **客户端证书认证（Client Certificate）**：APIM 用证书与后端建立 TLS 连接
> - **OAuth 2.0 / JWT 令牌认证**：APIM 作为客户端获取访问令牌，调用后端
>
> ------
>
> ### 2. **配置 APIM 后端身份验证**
>
> #### 示例：设置基本认证
>
> 在 APIM 中：
>
> - 进入 API Management 实例 > APIs > 选择对应 API > Settings
> - 找到 **“Backend”** 部分的 **Authentication Settings**
> - 启用 Basic Authentication，填写用户名和密码
>
> ------
>
> #### 示例：使用客户端证书
>
> - 在 APIM 的“安全性”部分上传客户端证书
> - 绑定客户端证书到后端 API 调用配置
> - 后端 API 要配置为接受该客户端证书
>
> ------
>
> ### 3. **在 API 中配置策略（Policy）**
>
> 可在 APIM API 的 Inbound 或 Backend 节点配置策略，比如添加 Authorization header：
>
> ```
> xmlCopyEdit<inbound>
>   <base />
>   <set-header name="Authorization" exists-action="override">
>     <value>Bearer @{your_access_token}</value>
>   </set-header>
> </inbound>
> ```
>
> ------
>
> ## 总结
>
> - **确保后端 API 支持你配置的认证方式**（如Basic、证书或OAuth）
> - **在 APIM 中配置相应的身份验证信息**
> - **通过策略动态注入身份验证令牌或头部**

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 解析：
>
> - **Client cert gateway credentials** 是指在 Azure API Management (APIM) 中配置客户端证书，APIM 在调用后端 HTTPS 服务时，会使用该证书完成双向 TLS（mutual TLS）认证。
> - 适用于后端服务需要通过客户端证书来验证调用方身份的场景。
> - 这样可以确保 APIM 与后端之间的通信安全，且满足后端认证要求。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Basic gateway credentials for the HTTP(s) endpoint” 是指 APIM 为调用 HTTPS（支持安全传输）的后端 API 时，配置的 Basic Authentication 凭据。它是建立在 HTTPS 安全传输基础上的身份认证机制
>
> =>这么看来也可以...

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the Azure resource. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 非要挑刺，只能说**“for the Azure resource”** 的措辞不准确...

**[⬆ Back to Top](#table-of-contents)**

### You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation venues. You want the application to list holiday accommodation venues that fall within a specific price range and are within a specified distance to an airport. What should you do?

- [ ] Configure the `SearchMode` property of the `SearchParameters` class.
- [ ] Configure the `QueryType` property of the `SearchParameters` class.
- [ ] Configure the `Facets` property of the `SearchParameters` class.
- [x] Configure the `Filter` property of the `SearchParameters` class.

> ### 选项解析：
>
> **SearchMode**：控制是匹配任何词还是全部词，主要影响全文搜索的匹配行为，不适合范围或距离筛选。
>
> **QueryType**：控制查询的解析方式，支持简单查询（simple）和全文查询（full，支持 Lucene 查询语法，如布尔运算符、字段搜索和通配符），但不影响筛选条件。
>
> **Facets**：用于对结果做分面聚合，比如统计某个字段的值的分布，也不是筛选条件。
>
> **Filter**：用于根据条件筛选文档，比如数值范围、布尔值、地理距离等，是实现价格范围和距离筛选的正确属性。
>
> ------
>
> ### 答案：
>
> -  配置 `SearchParameters` 类的 **`Filter`** 属性。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer at your company. You need to edit the workflows for an existing Logic App. What should you use?

- [ ] The Enterprise Integration Pack (EIP).
- [ ] The Logic App Code View.
- [ ] The API Connections.
- [x] The Logic Apps Designer.

> ### ✅ 解释：
>
> 如果你要**编辑 Logic App 的工作流（workflow）**，以下是两种主要方式：
>
> 1. **Logic Apps Designer**：
>     图形化界面，可以通过拖放操作编辑工作流步骤。最适合大多数开发者和业务人员使用。
>     👉 **这是最常用、推荐的方式。**
> 2. **Logic App Code View**：
>     直接编辑工作流的 JSON 定义（Logic App 是以 ARM JSON 模板形式存在的）。适合高级用户或需要精细控制的情况。
>
> ✅ **Logic App Code View 也可以用来编辑 workflows**，但它不是**最适合大多数开发者**的方式，尤其是在**图形工作流设计**场景中。
>
> ## 🧠 示例说明：
>
> 比如你想编辑这样一个工作流：
>
> - Step 1: HTTP trigger
> - Step 2: Parse JSON
> - Step 3: 条件判断
> - Step 4: 写入到 SharePoint
>
> 在 **Logic App Designer** 中，你只需点击几下、拖动、配置字段，就可以完成。
>  在 **Code View** 中，你需要写出完整的 JSON 表达。
>
> 
>
> ## ✅ **适合使用 Code View 的典型场景**
>
> ### 1. **DevOps / CI/CD 自动化部署**
>
> - **使用代码管理工作流定义（Infrastructure as Code）**
> - 在 CI/CD pipeline 中将 Logic App JSON 文件部署到多个环境（Dev / QA / Prod）
> - 易于版本控制（在 Git 中查看变更差异）
>
> 🛠 推荐工具：
>
> - ARM templates 或 Bicep + Logic App workflow JSON
> - Azure CLI / PowerShell 自动部署
>
> ------
>
> ### 2. **复杂逻辑微调 / 定制语法**
>
> 有些 Logic App Designer 无法完全支持的复杂语法只能手动写 JSON，例如：
>
> - 使用 `@equals(triggerBody()?['status'], 'Success')` 这种复杂表达式
> - 自定义 `splitOn` 语法、循环控制条件、嵌套表达式等

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that applies a set of governance policies for internal and external services, as well as for applications. You develop a stateful ASP.NET Core 2.1 web application named `PolicyApp` and deploy it to an Azure App Service Web App. The `PolicyApp` reacts to events from Azure Event Grid and performs policy actions based on those events. You have the following requirements: Authentication events must be used to monitor users when they sign in and sign out. All authentication events must be processed by `PolicyApp`. Sign outs must be processed as fast as possible. What should you do?

- [ ] Create a new Azure Event Grid subscription for all authentication events. Use the subscription to process sign-out events.
- [ ] Create a separate Azure Event Grid handler for sign-in and sign-out events.
- [ ] Create separate Azure Event Grid topics and subscriptions for sign-in and sign-out events.
- [x] Add a subject prefix to sign-out events. Create an Azure Event Grid subscription. Configure the subscription to use the subjectBeginsWith filter.

> #### ✅ **选项 D：Add a subject prefix to sign-out events. Create an Azure Event Grid subscription. Configure the subscription to use the subjectBeginsWith filter.**
>
> - **优势：**
>   - 你可以把 sign-out 事件打上特定的前缀，例如 `"signout/"`。
>   - 然后使用 `subjectBeginsWith` 过滤器，只让带这个前缀的事件触发这个订阅。
>   - 这样可以为 **sign-out** 单独开辟一个 **高优先级处理通道**，**加速处理登出事件**。
> - **同时可以搭配另一个订阅处理所有事件**，确保 “all events are processed”。
>
> ✅ **这是最符合题意的答案。**

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM09 to ensure that users can review content using ContentAnalysisService. How should you complete the code?

![Question 193 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 193 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 193 part 3](images/question193.jpeg)

- [ ] Box 1: `"oauth2Permissions": ["login"]`. Box 2: `"oauth2AllowImplicitFlow": true`.
- [x] Box 1: `"oauth2AllowIdTokenImplicitFlow": true`. Box 2: `"oauth2AllowImplicitFlow": true`.
- [ ] Box 1: `"allowPublicClient": true`. Box 2: `"knownClientApplications": ["ContentAnalysisService"]`.
- [ ] Box 1: `"oauth2Permissions": ["login"]`. Box 2: `"preAuthorizedApplications": ["SPA"]`.

> 这四组选项中，针对 SPA 和内容审核服务的 Azure AD 应用配置，最合适的是：
>
> - **Box 1:** `"oauth2AllowIdTokenImplicitFlow": true`
> - **Box 2:** `"oauth2AllowImplicitFlow": true`
>
> 理由：
>
> - `oauth2AllowImplicitFlow` 和 `oauth2AllowIdTokenImplicitFlow` 两个配置一起，表示允许使用 OAuth 2.0 的隐式授权流，并且允许 ID Token 通过隐式流返回，这对单页应用（SPA）非常重要，用于客户端进行无缝登录认证。
> - 这是针对 SPA 最常用的设置，能够保证前端认证顺利进行。
>
> 其他选项：
>
> - `"allowPublicClient": true` 和 `"knownClientApplications"` 主要用在公有客户端和其他受信任客户端，但缺少隐式流配置，可能不完整。
> - `"oauth2Permissions": ["login"]` 是定义权限范围，但单独使用无法保证隐式流的支持。
> - `"preAuthorizedApplications"` 是用于预授权其他客户端的，不是最核心配置。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM10 of the application manifest to ensure that the requirement for manually reviewing content can be met. How should you complete the code?

![Question 194 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 194 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 194 part 3](images/question194.jpeg)

- [x] Box 1: `sid`. Box 2: `email`.
- [ ] Box 1: `platf`. Box 2: `sid`.
- [ ] Box 1: `tenant_ctry`. Box 2: `upn`.
- [ ] Box 1: `sid`. Box 2: `enfpolids`.

> ### optionalClaims 作用简介
>
> `optionalClaims` 用于 Azure AD 应用注册的 manifest 中，定义应用期望从令牌（ID token 或 Access token）中获取的额外声明（Claims），例如用户的邮箱（email）、安全标识符（sid）、帐户类型（acct）等。
>
> Box 1: `sid`，Box 2: `email`
>
> - `sid`（会话ID）对追踪用户会话有帮助，`email`是必须的，满足审计要求。
> - 这是最合理的组合，既包含了用户身份追踪（sid），又包含邮箱（email）用于审核。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that network security policies are met. How should you configure network security?

![Question 195 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 195 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 195 part 3](images/question195.jpeg)

- [ ] SSL certificate: Self-signed certificate. Proxy type: nginx.
- [ ] SSL certificate: Self-signed certificate. Proxy type: Azure Application Gateway.
- [ ] SSL certificate: Valid root certificate. Proxy type: nginx.
- [x] SSL certificate: Valid root certificate. Proxy type: Azure Application Gateway.

> 基于题目中对安全性的要求：
>
> - **所有网站和服务都必须使用由有效根证书颁发的 SSL 证书**，所以 SSL certificate 应该选择 **Valid root certificate**，而非自签名证书。
> - **网络层面要保护 Web 服务，且题目中提到已用 Azure Web Application Firewall (WAF)**，而 Azure Application Gateway 本身集成了 WAF 功能，是 Azure 上的标准 Web 反向代理服务，适合保护 Web App。

**[⬆ Back to Top](#table-of-contents)**

### You are building a website to access project data related to teams within your organization. The website does not allow anonymous access. Authentication is performed using an Microsoft Entra ID app named internal. The website has the following authentication requirements: Microsoft Entra ID users must be able to login to the website. Personalization of the website must be based on membership in Active Directory groups. You need to configure the application's manifest to meet the authentication requirements. How should you configure the manifest?

![Question 196](images/question196.png)

- [ ] Box 1: "optionalClaims". Box 2: "allowPublicClient".
- [ ] Box 1: "optionalClaims". Box 2: "requiredResourceAccess".
- [ ] Box 1: "groupMembershipClaims". Box 2: "oauth2Permissions".
- [x] Box 1: "groupMembershipClaims". Box 2: "oauth2AllowimplicitFlow".

> ### ✅【解决方案目标】
>
> 通过配置应用的 Manifest（应用程序清单），确保：
>
> - 应用在用户登录后可以**获取用户的组成员信息**；
> - 正确设置必要的权限字段
>
> 你需要修改 Entra 应用的 manifest（清单），重点是下面两个属性：
>
> #### 1. `"groupMembershipClaims"` 属性
>
> 这是 **关键字段**，用于告诉 Entra ID 在发出的 ID 令牌或访问令牌中，是否应包含用户所属的组。
>
> **解释**：设置为 `"SecurityGroup"` 表示包含用户所属于的所有 **安全组** 的 Object ID。
>
> 其他选项：
>
> - `"All"`：包含安全组和Office 365组
> - `null` 或省略：不返回组信息（默认）
>
> #### 2. （可选）设置 `requiredResourceAccess` 权限
>
> 虽然主问题重点在 manifest，但为了能让网站读取用户组信息，还需要：
>
> - 向 Entra 应用授予 Microsoft Graph 的相关权限，如：
>
> ```json
> "requiredResourceAccess": [
>   {
>     "resourceAppId": "00000003-0000-0000-c000-000000000000", // Microsoft Graph 的 appId
>     "resourceAccess": [
>       {
>         "id": "e1fe6dd8-ba31-4d61-89e7-88639da4683d", // User.Read
>         "type": "Scope"
>       },
>       {
>         "id": "5b567255-7703-4780-807c-7be8301ae99b", // GroupMember.Read.All
>         "type": "Role"
>       }
>     ]
>   }
> ]
> ```
>
> 但第二个 Dropdown 后面是 `true`，而 `"requiredResourceAccess"` 无法赋值为 `true`
>
> ###  分析两个可选字段的含义：
>
> 1. `"allowPublicClient": true`
>    - 含义：允许此应用作为**公共客户端**使用（例如：原生客户端、移动应用等）。
>    - 用于场景：桌面或移动 app，通过授权码流交互 Entra ID。
> 2. `"oauth2AllowImplicitFlow": true`
>    - 含义：允许使用 OAuth2 隐式授权流（现在已不推荐，但有些老的 SPA 使用它）。
>    - 用于场景：单页应用（SPA）直接从 URL 中获取令牌，不通过后端。
>
> 题干回顾：网站为组织内访问，不允许匿名访问；
>
> ### ✅ 最终答案：
>
> | 填空项     | 答案                      |
> | ---------- | ------------------------- |
> | Dropdown 1 | `groupMembershipClaims`   |
> | Dropdown 2 | `oauth2AllowImplicitFlow` |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution. You need to develop code to access a secret stored in Azure Key Vault. How should you complete the code segment?

![Question 197](images/question197.png)

- [ ] Box 1: `DefaultAzureCredential`. Box 2: `ClientSecretCredential`.
- [ ] Box 1: `CloudClients`. Box 2: `ClientSecretCredential`.
- [ ] Box 1: `ClientSecretCredential`. Box 2: `SecretClient`.
- [x] Box 1: `SecretClient`. Box 2: `DefaultAzureCredential`.

> ## ✅ C# 示例（.NET Azure SDK）
>
> ```C#
> using Azure.Identity;
> using Azure.Security.KeyVault.Secrets;
> 
> var keyVaultName = "<your-key-vault-name>";
> var kvUri = $"https://{keyVaultName}.vault.azure.net/";
> 
> var client = new SecretClient(new Uri(kvUri), new DefaultAzureCredential());
> 
> // Fill in the blank
> KeyVaultSecret secret = client.GetSecret("<secret-name>");
> Console.WriteLine(secret.Value);
> ```
>
> ## ✅【选项分析】
>
> 题目提供的四个选项：
>
> 1. `DefaultAzureCredential` ✅
>     → 用于身份认证的默认推荐方式，适配开发环境 & Azure 托管环境。
> 2. `ClientSecretCredential` ✅
>     → 另一种身份认证方式，使用客户端ID/密钥，需要更多配置。
> 3. `CloudClients` ❌
>     → 错误项，不是 Azure SDK 的类名。
> 4. `SecretClient` ✅
>     → 连接 Azure Key Vault 的客户端类，用于操作 secrets。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web application that makes calls to the Microsoft Graph API. You register the application in the Azure portal and upload a valid `X509` certificate. You create an appsettings.json file containing the certificate name, client identifier for the application, and the tenant identifier of the Microsoft Entra ID. You create a method named `ReadCertificate` to return the `X509` certificate by name. You need to implement code that acquires a token by using the certificate. How should you complete the code segment?

![Question 198](images/question198.jpg)

- [ ] Box 1: `ConfidentialClientApplicationBuilder`. Box 2: `app`.
- [x] Box 1: `ConfidentialClientApplicationBuilder`. Box 2: `scopes`.
- [ ] Box 1: `GetAccountAsync()`. Box 2: `scopes`.
- [ ] Box 1: `ConfidentialClientApplication`. Box 2: `config`.

> 我们要完成的代码结构类似这样（C# 伪代码）：
>
> ```C#
> var cert = ReadCertificate("myCertName");
> //创建客户端应用
> var clientApp = ConfidentialClientApplicationBuilder
>     .Create(clientId)
>     .WithCertificate(cert)
>     .WithTenantId(tenantId)
>     .Build();
> // 定义作用域
> string[] scopes = new[] { "https://graph.microsoft.com/.default" };
> // 获取访问令牌
> var result = await clientApp.AcquireTokenForClient(scopes).ExecuteAsync();
> ```
>
> 因为访问令牌是有“权限范围”的，定义 scope 就是告诉授权服务器：我这个令牌要用来访问哪个资源、要干什么事。
>
> ## 🧠 类比理解：
>
> 想象你去政府办事，需要办“驾照”或“护照”：
>
> - 你提交申请（相当于：AcquireToken）
> - 要说明你想要哪种证件（相当于：scope = 驾照 或 护照）
> - 系统就会给你一张对应用途的证件（access token）

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server. You need to ensure that dependency tracking works for calls to the third-party database. Which two dependency telemetry properties should you use?

- [ ] `Telemetry.Context.Cloud.RoleInstance`.
- [x] `Telemetry.Id`.
- [ ] `Telemetry.Name`.
- [x] `Telemetry.Context.Operation.Id`.
- [ ] `Telemetry.Context.Session.Id`.

> ## 【重点术语：Dependency Telemetry】
>
> Application Insights 会自动或手动收集对外部服务的调用，称为 **DependencyTelemetry**。
>
> ## ✅ 目标
>
> **你需要设置哪些属性，才能确保 AI 可以正确追踪到这类数据库调用？**
>
> ------
>
> ## 🎯 选项分析：
>
> 我们看看这些属性能不能帮 Application Insights 准确理解 “这是一个依赖项调用”：
>
> ### - [ ] `Telemetry.Context.Cloud.RoleInstance`
>
> - 表示服务的部署实例（如 VM 名称）。用于定位是哪台机器，但**和依赖项本身没关系** ❌。
>
> ------
>
> ### - [x] `Telemetry.Id`
>
> - **这个是依赖项的唯一 ID**，用于构建调用链和分布式追踪中的“Span ID”。
> - 尤其在构建复杂链路时，这个字段必须唯一。✅
>
> ------
>
> ### - [x] `Telemetry.Name`
>
> - 表示依赖项调用的名称，比如 `"Insert Order"`、`"GET /products"`。
> - Application Insights UI 会直接显示这个作为依赖的名字，是非常关键的一个字段。✅
>
> ------
>
> ### - [ ] `Telemetry.Context.Operation.Id`
>
> - 用于标识一次大的操作（比如请求、用户动作），虽然重要，但属于**Context**部分，**不会影响依赖项本身的记录** ❌。
>
> ------
>
> ### - [ ] `Telemetry.Context.Session.Id`
>
> - 表示用户会话，用于分组分析用户行为（UX 分析），和依赖关系无直接关系 ❌。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`. All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node. You need to configure Azure CDN caching rules. Which options should you use?

![Question 200](images/question200.jpeg)

- [x] Caching behavior: Override. Cache expiration duration: 1 hour. Query string caching behavior: Cache every unique URL.
- [ ] Caching behavior: Bypass cache. Cache expiration duration: 1 day. Query string caching behavior: Bypass caching for query strings.
- [ ] Caching behavior: Set if missing. Cache expiration duration: 1 second. Query string caching behavior: Ignore query strings.
- [ ] Caching behavior: Override. Cache expiration duration: 1 hour. Query string caching behavior: Ignore query strings.

> #### ✅ 选项 1（正确）
>
> > - **Caching behavior**: Override
> > - **Cache expiration duration**: 1 hour
> > - **Query string caching behavior**: Cache every unique URL
>
> 📌 **分析：**
>
> - 覆盖缓存设置为 **1小时** ✅
> - **每一个不同的 query string URL 都单独缓存**，例如 `content.mp4?quality=1` 和 `content.mp4?quality=2` 是两个缓存对象 ✅
> - 完全符合题目“缓存1小时 + 区分不同质量视频”的需求 ✅

**[⬆ Back to Top](#table-of-contents)**

### You develop a web app that uses tier D1 app service plan by using the Web Apps feature of Microsoft Azure App Service. Spikes in traffic have caused increases in page load times. You need to ensure that the web app automatically scales when CPU load is about 85 percent and minimize costs. Which four actions should you perform in sequence?

![Question 201](images/question201.jpg)

- [x] Box 1: Configure the web app to the Standard App Service tier. Box 2: Enable autoscaling on the web app. Box 3: Add a Scale rule. Box 4: Configure a Scale condition.
- [ ] Box 1: Enable autoscaling on the web app. Box 2: Add a Scale rule. Box 3:Configure a Scale condition. Box 4:Switch to an Azure App Services consumption plan.
- [ ] Box 1: Configure the web app to the Standard App Service tier. Box 2: Enable autoscaling on the web app. Box 3: Configure a Scale condition. Box 4: SecretClient.
- [ ] Box 1: Switch to an Azure App Services consumption plan. Box 2: Configure the web app to the Premium App Service tier. Box 3: Enable autoscaling on the web app. Box 4: Configure a Scale condition.

> 1. ### 解析如下：
>
>    #### 🔹 Box 1: Configure the web app to the Standard App Service tier
>
>    - 当前是 D1（Shared）层，不支持 Autoscale。
>    - **Standard** 层是支持自动缩放的最低成本层。
>
>    #### 🔹 Box 2: Enable autoscaling on the web app
>
>    - 开启自动缩放功能（AutoScale）。
>
>    #### 🔹 Box 3: Add a Scale rule
>
>    - 设置缩放的**触发条件**，例如：
>      - CPU > 85% → 增加实例
>      - CPU < 50% → 减少实例
>
>    #### 🔹 Box 4: Configure a Scale condition
>
>    - 配置完整的缩放条件组（如：最小实例数、最大实例数、冷却时间等）。

**[⬆ Back to Top](#table-of-contents)**

### A company backs up all manufacturing data to Azure Blob Storage. Admins move blobs from hot storage to archive tier storage every month. You must automatically move blobs to Archive tier after they have not been modified within 180 days. The path for any item that is not archived must be placed in an existing queue. This operation must be performed automatically once a month. You set the value of TierAgeInDays to -180. How should you configure the Logic App?

![Question 202](images/question202.jpeg)

- [ ] Box 1: Put a message on a queue. Box 2: Recurrence. Box 3: Condition. Box 4: When there are messages in a queue. Box 5: List blobs 2.
- [ ] Box 1: Recurrence. Box 2: Condition. Box 3: When there are messages in a queue. Box 4: Tier blob. Box 5: List blobs 2.
- [ ] Box 1: Recurrence. Box 2: Condition. Box 3: Put a message on a queue. Box 4: When there are messages in a queue. Box 5: Tier blob.
- [x] Box 1: Recurrence. Box 2: Condition. Box 3: Put a message on a queue. Box 4: Tier blob. Box 5: List blobs 2.

> 好的，这是一个关于如何使用 Azure Logic Apps 自动化管理 Blob Storage 数据的配置方案。
>
> **任务目标：**
>
> - 每月自动将超过 180 天未修改的 Blob 从热存储（hot storage）移动到归档层（archive tier）。
> - 对于不符合归档条件的 Blob，将其路径信息放入一个名为 `processing` 的现有队列中。
>
> **Logic App 配置步骤：**
>
> 以下是按照正确的顺序和配置，将每个逻辑应用块拖放到画布中的方式：
>
> 
>
> ### 1. **触发器：每月执行一次**
>
> 
>
> - **块：Recurrence (重复)**
> - **作用：** 这是整个工作流的起点。它将确保这个逻辑应用每月自动运行一次。
> - **配置：**
>   - **Interval (间隔)：** 1
>   - **Frequency (频率)：** Month (月)
>
> 
>
> ### 2. **操作：设置归档年龄变量**
>
> 
>
> - **块：Set tier age variable (设置分层年龄变量)**
> - **作用：** 在执行检查之前，计算一个时间戳，这个时间戳代表着“180天前的日期”。这样，后面的步骤就可以用这个时间戳来判断一个 Blob 是否足够旧。
> - **配置：**
>   - **值 (Value)：** `addDays(utcNow(), variables('TierAgeInDays'))`
>   - **解释：** `utcNow()` 获取当前时间，`variables('TierAgeInDays')` 是你预设的 `-180` 天，所以这个表达式会计算出当前日期减去 180 天的日期。
>
> 
>
> ### 3. **操作：列出所有 Blob**
>
> 
>
> - **块：List blobs (列出 Blob)**
> - **作用：** 获取指定存储容器或路径下的所有 Blob 列表。
> - **配置：**
>   - **Folder (文件夹)：** `Path X` (或你实际存储数据的路径)
>
> 
>
> ### 4. **操作：遍历每一个 Blob**
>
> 
>
> - **块：For each (对于每一个)**
> - **作用：** 这是一个循环，它会遍历上一步获取到的所有 Blob，并对每个 Blob 执行后续的检查和操作。
> - **配置：**
>   - **选择一个输出：** `value` (这是来自 `List blobs` 步骤的 Blob 列表)
>
> 
>
> ### 5. **操作：检查修改日期**
>
> 
>
> - **块：Condition (条件)**
> - **作用：** 这是工作流中的一个决策点。它会检查当前循环到的 Blob 的“上次修改时间”是否早于我们之前设置的“180天前的日期”。
> - **配置：**
>   - **左侧：** `ticks(items('For_each')?['LastModified'])`
>   - **比较器：** `is less than` (小于)
>   - **右侧：** `ticks(addDays(utcNow(), variables('TierAgeInDays')))`
>   - **解释：** 这个表达式将 Blob 的上次修改时间转换为一个数字（ticks），然后与 180 天前的日期转换的数字进行比较。如果 Blob 的修改时间戳小于 180 天前的时间戳，那么条件为 `True`。
>
> 
>
> ### 6. **操作：根据条件执行不同的任务**
>
> 
>
> - **块：Tier blob (分层 Blob)**
> - **作用：** 如果上一步的条件为 **`True`**（即 Blob 超过 180 天未修改），则执行此操作。
> - **配置：**
>   - **Blob path (Blob 路径)：** `Path X` (当前循环到的 Blob 的路径)
>   - **Blob tier (Blob 层级)：** `Archive` (归档)
> - **块：Put a message on a queue (将消息放入队列)**
> - **作用：** 如果上一步的条件为 **`False`**（即 Blob 在 180 天内被修改过），则执行此操作。
> - **配置：**
>   - **Queue Name (队列名称)：** `processing`
>   - **Message (消息)：** `Path X` (当前循环到的 Blob 的路径)

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 1: The minimum throughput for the container is 400 R/Us.

- [ ] Yes.
- [x] No.

> ### 🔹**容器创建脚本回顾**
>
> ```shell
> $resourceGroupName = 'testResourceGroup'
> $accountName = 'testCosmosAccount'
> $databaseName = 'testDatabase'
> $containerName = 'testContainer'
> $partitionKeyPath = '/EmployeeId'
> $autoscaleMaxThroughput = 5000
> 
> New-AzCosmosDBSqlContainer `
>   -ResourceGroupName $resourceGroupName `
>   -AccountName $accountName `
>   -DatabaseName $databaseName `
>   -Name $containerName `
>   -PartitionKeyKind Hash `
>   -PartitionKeyPath $partitionKeyPath `
>   -AutoscaleMaxThroughput $autoscaleMaxThroughput
> ```
>
> - 使用了 **Autoscale**，最大吞吐量为 `5000 RU/s`。
> - 使用了 **分区键为 `/EmployeeId`**。
> - 创建的是 **SQL API 的容器（Cosmos DB）**。
>
> ### 🔹**Autoscale 相关重点**
>
> 启用 autoscale 时，Cosmos DB 会根据负载自动调整吞吐量，**其最小吞吐量为 `max throughput` 的 10%**。
>
> > 🚩 所以：
> >  **5000 RU/s × 10% = 500 RU/s**
>
> ⚠️ **不是 400 RU/s**，所以题中说“最小吞吐量为 400 RU/s”这个说法是 **❌错误** 的。

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 2: The first query statement is an in-partition query.

- [ ] Yes.
- [x] No.

> ## ✅ 定义：什么是 In-Partition Query？
>
> **In-partition query（单分区查询）** 的意思是：查询只会命中某一个具体分区，而不会跨多个分区读取数据。
>
> 要做到这一点，必须满足以下条件之一：
>
> 1. 查询的 **过滤条件中包含具体的分区键值**，例如：
>
>    ```sql
>    SELECT * FROM c WHERE c.EmployeeId = '12345'
>    ```
>
>    → 明确告诉 Cosmos DB 要查哪个分区。
>
> 2. 使用 SDK 查询时，**在代码中提供 partition key 的值**。
>
> ## ❌ 为什么题目中的查询 *不是* In-Partition Query？
>
> 你的查询是：
>
> ```
> sql
> 
> 
> CopyEdit
> SELECT * FROM c WHERE c.EmployeeId > '12345'
> ```
>
> ### 分析：
>
> - ✅ 使用了分区键字段（`EmployeeId`），这是一个好的开始。
> - ❌ 但是是 **范围查询**，并没有指定一个具体的 `EmployeeId` 值。
>
> > Cosmos DB 不知道你想查哪一个分区，因为它无法根据 `> '12345'` 判断唯一分区 —— 所以必须 **检查所有分区** 才能返回结果。
>
> 这就会触发所谓的 **跨分区查询（cross-partition query）**。

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 3: The second query statement is a cross-partition query.

- [x] Yes.
- [ ] No.

> ## 🔍 Cosmos DB 查询是否为跨分区（cross-partition）的判断逻辑
>
> 如果查询中 **没有使用容器的分区键字段 `EmployeeId`**，那 Cosmos DB 就无法通过查询直接确定要访问哪一个分区，**必须扫描所有分区** —— 也就是说：
>
> > ✅ **只要查询里没包含分区键字段，就一定是 cross-partition query。**
>
> ------
>
> ## ✅ 分析当前这个查询
>
> 查询：
>
> ```sql
> SELECT * FROM c WHERE c.UserID = '12345'
> ```
>
> - 它使用了 `UserID`，但你的容器是按 `/EmployeeId` 分区的。
> - **没有使用分区键字段 `EmployeeId`**。
> - 因此，**Cosmos DB 无法推断出具体目标分区**，只能执行 **cross-partition 查询**。

**[⬆ Back to Top](#table-of-contents)**

### Your Microsoft Entra ID tenant has an Azure subscription linked to it. Your developer has created a mobile application that obtains Microsoft Entra ID access tokens using the OAuth 2 implicit grant type. The mobile application must be registered in Microsoft Entra ID. You require [a redirect URI] from the developer for registration purposes.

- [x] No change required.
- [ ] a secret.
- [ ] a login hint.
- [ ] a client ID.

> ## 🔄 背景：OAuth 2.0 Implicit Grant Type 是什么？
>
> 这是 OAuth 的一种授权模式，**专门为客户端（如SPA、移动应用）设计**，这些客户端 **无法安全存储机密（client secret）**。
>
> - 这种模式下，客户端**直接从浏览器地址栏**中获得 `access_token`。
> - 适合浏览器运行或运行在不安全环境中的应用程序（如 JS 单页应用、移动 App）。
> - 现在推荐用 Authorization Code + PKCE 代替，但一些老项目仍然使用 implicit flow。
>
> ## 🧭 整体流程图
>
> ```
> [用户打开App] 
>      ↓
> [App 重定向用户到 Entra ID 登录页面]
>      ↓
> [用户登录成功 → Entra ID 重定向回注册的 Redirect URI]
>      ↓
> [重定向 URI 上附带 access_token]
>      ↓
> [App 拿到 access_token，调用受保护API]
> ```
>
> ### ✅ 为什么选 `No change required`
>
> 在使用 implicit grant 时：
>
> - **注册应用时必须提供 redirect URI**
> - 所以要求开发者提供 redirect URI 是 **完全合理且必要的**
> - 因此：**No change required** ✅
>
> ------
>
> ### ❌ 为什么其他选项错：
>
> | 选项           | 是否需要 | 原因                                                         |
> | -------------- | -------- | ------------------------------------------------------------ |
> | `a secret`     | ❌ 不需要 | 移动应用为 public client，不能安全存储 secret                |
> | `a login hint` | ❌ 不需要 | login_hint 是优化登录体验的参数，不用于注册                  |
> | `a client ID`  | ❌ 不需要 | client ID 是你注册应用之后**平台生成**的，不是开发者提前提供的 |

**[⬆ Back to Top](#table-of-contents)**

### You develop an ASP.NET Core MVC application. You configure the application to track webpages and custom events. You need to identify trends in application usage. Which Azure Application Insights Usage Analysis features should you use?

![Question 207](images/question207.png)

- [x] Box 1: Funnels. Box 2: Impact. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Impact. Box 2: Funnels. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Users. Box 2: Impact. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Impact. Box 2: Users. Box 3: User Flows. Box 4: Funnels.

> | 需求描述                                           | 功能（Feature）            |
> | -------------------------------------------------- | -------------------------- |
> | 用户访问哪些页面最常与产品购买有关？               | **Funnels（转化漏斗）**    |
> | 产品展示页面的加载时间如何影响用户购买产品的决策？ | **Impact（影响分析）**     |
> | 哪些事件最能影响用户决定继续使用该应用程序？       | **Retention（用户留存）**  |
> | 应用中是否存在用户经常执行重复操作的位置？         | **User Flows（用户路径）** |
>
> ###  功能解释：
>
> - **Funnels（转化漏斗）**：用来分析用户完成某个目标（如购买）前所经过的页面或步骤，有助于找出哪些页面与转化相关。
> - **Impact（影响分析）**：用于分析性能指标（如加载时间）如何影响用户行为，比如是否决定购买。
> - **Retention（用户留存）**：帮助识别哪些行为或事件有助于用户持续使用你的应用。
> - **User Flows（用户路径）**：可视化用户在应用中的点击路径，识别用户常走的路线和重复操作的区域。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 1: Block blobs prefixed with container1/salesorders or container2/inventory which have not been modified in over 60 days are moved to cool storage. Blobs that have not been modified in 120 days are moved to the archive tier.

![Question 208](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> ### ✅ 1. `agingDataRule`：老化数据分层规则
>
> ```json
> {
>   "name": "agingDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   ...
> }
> ```
>
> #### **规则目标：**
>
> - 仅适用于 `"container1/salesorders"` 和 `"container2/inventory"` 目录中的 **blockBlob**
> - 如果 blob 被修改超过 60 天：移至 **Cool** 层（较低频访问）
> - 如果 blob 被修改超过 120 天：移至 **Archive** 层（极少访问）
>
> #### **用途：**
>
> 适用于处理不再频繁访问的销售订单或库存文件，通过自动冷/归档降低存储成本。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 2: Blobs are moved to cool storage if they have not been accessed for 30 days.

![Question 209](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> ### ✅ 2. `lastAccessedDataRule`：访问频率分层规则
>
> ```json
> {
>   "name": "lastAccessedDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   ...
> }
> ```
>
> #### **规则目标：**
>
> - 适用于所有的 **blockBlob**
> - 如果 **30 天未被访问**：移至 Cool 层
> - 如果之后又被访问，支持 **自动从 Cool 层升回 Hot 层**
>
> #### **用途：**
>
> 自动调整 blob 的访问层级（Hot↔Cool）以提高性能与成本效率，适合动态访问的数据。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 3: Blobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.

![Question 210](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> 你在规则 `lastAccessedDataRule` 中设置了以下策略：
>
> ```
> jsonCopyEdit"baseBlob": {
>   "enableAutoTierToHotFromCool": true,
>   "tierToCool": { "daysAfterLastAccessTimeGreaterThan": 30 }
> }
> ```
>
> - `tierToCool`: 如果 **30 天未访问**，Blob 会被自动转为 **Cool 层**。
> - `enableAutoTierToHotFromCool: true`：表示如果某个 Blob **再次被访问**，它会被自动从 **Cool 层提升回 Hot 层**。
>
> 这个功能用于 **Premium block blob 存储账户**，并且前提是启用了 **“最后访问时间追踪（last access time tracking）”** 功能。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 4: All block blobs older than 730 days will be deleted.

![Question 211](images/question208_209_210_211.png)

- [ ] Yes.
- [x] No.

> ### 解析：
>
> 来看你的第三条规则 `expirationDataRule`：
>
> ```json
> {
>   "name": "expirationDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   "definition": {
>     "filters": {
>       "blobTypes": [ "blockBlob" ]
>     },
>     "actions": {
>       "baseBlob": {
>         "delete": { "daysAfterModificationGreaterThan": 730 }
>       }
>     }
>   }
> }
> ```
>
> #### ✔ 意义如下：
>
> - 这个规则表示：**“当 block blob 的最后修改时间超过 730 天”**，就会被 **自动删除**。
> - 也就是说：
>   - 如果 blob 仍在 730 天内被修改过，则不会删除。
>   - 如果是 appendBlob 或 pageBlob，也不会被处理（因为只针对 blockBlob）。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to store the user agreements. Where should you store the agreement after it is completed?

![Question 212 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 212 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] Azure Storage queue.
- [x] Azure Event Hub.
- [ ] Azure Service Bus topic.
- [ ] Azure Event Grid topic.

> 这四个选项都不适合作为“存储用户协议”的方案。
>
> 存储用户协议用数据库，如Azure Cosmos DB或Azure SQL。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to monitor `ContentUploadService` according to the requirements. Which command should you use?

![Question 213 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 213 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "avg Percentage CPU > 8"`.
- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "avg Percentage CPU > 800"`.
- [x] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "CPU Usage > 800"`.
- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "CPU Usage > 8"`.

> 正确选项是：
>
> -  `az monitor metrics alert create Cn alert Cg … --scopes … --condition "avg Percentage CPU > 8"`
>
> **解析：**
>
> - **指标名称是 `Percentage CPU`**，不是 `CPU Usage`。
> - 命令中的条件表达式一般是类似 `"avg Percentage CPU > 80"`（注意阈值应为 80，题中 8 可能是笔误）。
> - 选项中正确指标名是 `Percentage CPU`，用法是 `avg Percentage CPU > 80`（这里给出的8应是80）。
> - 其他选项要么指标名错，要么阈值不合理（800% 这种值不可能）。
>
> 如果题目中只有给出的选项，可以选择第一个，但应确认阈值是否应该是80。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to investigate the http server log output to resolve the issue with the `ContentUploadService`. Which command should you use first?

![Question 214 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 214 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] `az webapp log`.
- [ ] `az ams live-output`.
- [ ] `az monitor activity-log`.
- [x] `az container attach`.

> 调查 ACI 中容器的日志，排查 HTTP 502 问题，第一步用 `az container logs` 等命令。
>
> 正确答案是：
>
> -  `az container attach`
>
> 原因：
>
> - `az container attach` 可以实时连接到 Azure Container Instance（ACI）运行的容器的控制台输出流，适合用来查看容器的标准输出和错误日志，帮助排查问题，包括 HTTP 502 错误。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to implement the bindings for the CheckUserContent function. How should you complete the code segment?

![Question 215 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 215 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 215 part 3](images/question215.jpeg)

- [ ] Box 1: [CosmosDBTrigger("content", "userContent")]. Box 2: [Table("content", "userContent", "{name}")].
- [ ] Box 1: [CosmosDBTrigger("content", "userContent")]. Box 2: [Queue("userContent")].
- [ ] Box 1: [BlobTrigger("userContent/{name}")]. Box 2: [Blob("userContent/{name}", FileAccess.Write)].
- [x] Box 1: [QueueTrigger("userContent")]. Box 2: [Blob("userContent/{name}", FileAccess.Write)].

> #### Box 1: `[QueueTrigger("userContent")]`
>
> - 当用户上传内容信息后，由 `ContentUploadService` 把元数据（如内容名称、路径、用户 ID）发送到名为 `"userContent"` 的 Azure Storage Queue。
> - 使用 Storage Queue 的优势：**极低成本**，适合处理**大量异步任务**，**支持大规模并发触发** Azure Functions。
>
> #### Box 2: `[Blob("userContent/{name}", FileAccess.Write)]`
>
> - 函数审核内容后，可以将结果写入 blob 存储（如审核状态报告、审查标记、结果文件等）。
> - `{name}` 变量来自触发器中传入的消息体，具有一致性。
> - Blob 输出绑定同样**便宜可靠**，可以存储结构化或非结构化数据（例如 JSON、图像标签结果等）。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add markup at line AM04 to implement the ContentReview role. How should you complete the markup?

![Question 216 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 216 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 216 part 3](images/question216.jpeg)

- [ ] Box 1: allowedAccountTypes. Box 2: User. Box 3: value.
- [ ] Box 1: role. Box 2: User. Box 3: value.
- [x] Box 1: allowedMemberTypes. Box 2: User. Box 3: value.
- [ ] Box 1: allowedMemberTypes. Box 2: value. Box 3: User.

> 要在 `ApplicationManifest` 中实现 `ContentReview` 角色（即：将用户加入名为 `ContentReviewer` 的 Microsoft Entra ID 角色），你需要在 AM04 添加标记，使该 SPA 应用能够识别和授权该角色的成员。
>
> ```json
> "appRoles": [
>   {
>     "allowedMemberTypes": [
>       "User"
>     ],
>     "description": "Allows the user to review flagged content",
>     "displayName": "ContentReviewer",
>     "id": "GUID",  // 使用实际的 GUID
>     "isEnabled": true,
>     "value": "ContentReviewer"
>   }
> ]
> ```
>
> ### 中文解释：
>
> 这是在 Azure AD 应用注册的 **manifest** 中添加 **应用角色 (App Roles)** 的格式：
>
> | 字段                 | 说明                                                         |
> | -------------------- | ------------------------------------------------------------ |
> | `allowedMemberTypes` | 表示哪些类型的主体可以分配此角色，常见值是 `"User"`。        |
> | `description`        | 角色的描述，用于 Azure 门户中的提示信息。                    |
> | `displayName`        | 角色的显示名称。                                             |
> | `id`                 | 每个角色必须有唯一的 GUID。你可以用工具（如 `uuidgen`）生成一个。 |
> | `isEnabled`          | 是否启用此角色。必须为 `true`。                              |
> | `value`              | 角色的程序使用值（用于 `roles` claim 中）。                  |
>
> 
>
> ### 使用建议：
>
> 1. **添加后保存 manifest** 并重新加载应用注册页面。
> 2. 在 Enterprise Applications 里将用户分配到 `ContentReviewer` 角色。
> 3. 用户登录时，会从 token 中获取 `roles` claim，其中会包含 `ContentReviewer`。
>
> 
>
> 这个 **`ApplicationManifest`（应用清单 / manifest）** 是 Azure 中**应用注册（App registration）**的一部分，主要存在于 Microsoft Entra ID（原 Azure AD）中，用于描述和配置你的应用的身份验证和授权行为。
>
> ### ✅ **它存在在哪里？**
>
> 它存在于：
>  **Azure Portal > Microsoft Entra ID > App registrations > 你的应用 > Manifest**
>
> 或通过 Azure CLI / Microsoft Graph API 访问。
>
> ### 🧾 **这个 Manifest 是给谁用的？**
>
> | 使用者             | 说明                                                         |
> | ------------------ | ------------------------------------------------------------ |
> | **Azure 系统本身** | 解析此 manifest 来配置应用的权限、角色、安全性行为等。       |
> | **管理员/开发者**  | 你（开发者/管理员）通过编辑这个 JSON 文件定义应用角色（如 `ContentReviewer`）、API 权限、重定向 URI 等。 |
> | **前端/后端应用**  | 当用户登录后，其 JWT token 中会包含你定义的角色（如 `roles: ["ContentReviewer"]`），供你的应用做授权检查。 |

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add YAML markup at line CS17 to ensure that the `ContentUploadService` can access Azure Storage access keys. How should you complete the YAML markup?

![Question 217 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 217 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 217 part 3](images/question217.jpeg)

- [ ] Box 1: volumes. Box 2: volumeMounts. Box 3: secret.
- [x] Box 1: volumeMounts. Box 2: volumes. Box 3: secret.
- [ ] Box 1: envVar. Box 2: secretValues. Box 3: environmentVariables.
- [ ] Box 1: secret. Box 2: environmentVariables. Box 3: secretValues.

> - ### ✅ 完整示例：挂载 Secret 到容器 `/mnt/secrets` 路径
>
>   ```yaml
>   apiVersion: v1
>   kind: Pod
>   metadata:
>     name: secret-volume-pod
>   spec:
>     containers:
>     - name: myapp
>       image: nginx
>       volumeMounts:
>       - mountPath: /mnt/secrets
>         name: accesskey   # Box 2: volumeMounts
>     volumes:
>     - name: accesskey       # Box 1: volumes
>       secret:
>         secretName: my-secret   # 这个名字必须和下面 Secret 定义的 metadata.name 一致
>             
>   ---
>             
>   apiVersion: v1
>   kind: Secret
>   metadata:
>     name: my-secret
>   type: Opaque
>   data:
>     key: TXkgZmljY3Qgc2VjcmV0IEZPTwo=   # Box 3: secret（base64 编码的 secret 值）
>   ```

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to deploy the CheckUserContent Azure Function. The solution must meet the security and cost requirements. Which hosting model should you use?

![Question 218 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 218 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] Premium plan.
- [x] App Service plan.
- [ ] Consumption plan.

> Consumption Plan不支持 VNet 集成, 无法连接 ContentAnalysisService，违反“**所有内部服务必须只能通过 VNet 访问**”这一关键安全要求
>
> 题干内容看不出已有 App Service plan 可复用,  并且App Service plan 虽然部分 SKU 可以 VNet 集成，但缺点是 **不支持自动扩展 Function 实例数量**，需要你手动设定 instance 数量。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that validation testing is triggered per the requirements. How should you complete the code segment?

![Question 219 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 219 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 219 part 3](images/question219.jpeg)

- [x] Box 1: ImagePushed. Box 2: repository. Box 3: topic.
- [ ] Box 1: ImageDeployed. Box 2: service. Box 3: imageCollection.
- [ ] Box 1: RepositoryUpdated. Box 2: service. Box 3: imageCollection.
- [ ] Box 1: RepositoryItem. Box 2: aci. Box 3: topic.

> ## 看题干核心要求：
>
> > “Handler must trigger validation **only when** the `ContentAnalysisService` has a new image **deployed** from the `contosoimages` repository.”
>
> ### 🔍 逐项解释下拉选项选择：
>
> #### ✅ 第一空：`event.eventType === "ImageDeployed"`
>
> - 表示容器镜像已被部署。
> - 这是触发验证的时机：当新的镜像部署到 ContentAnalysisService 时。
>
> > 其他选项说明：
> >
> > - `ImagePushed`：指镜像被推送到 ACR，不一定被部署；
> > - `RepositoryUpdated`：表示有仓库变化，但可能非部署事件；
> > - 所以只有 `ImageDeployed` 是正确触发验证的事件类型。
>
> ------
>
> #### ✅ 第二空：`event.data.target.service === "contentanalysisservice"`
>
> - 指定部署目标的服务名称。
> - `ContentAnalysisService` 是系统中负责内容分析的服务，题干已经说明它部署在 Azure Container Instances 上。
>
> > 其他选项如 `image`, `repository`, `aci` 都不是指目标服务，语义不符。
>
> ------
>
> #### ✅ 第三空：`event.data.repository.contains("contosoimages")`
>
> - 仓库名中包含 `contosoimages`，说明使用的是 Contoso 的私有 ACR。
> - 用于判断部署镜像来源是否为预期仓库。
>
> 
>
> ### 四个选项回顾与逐个分析：
>
> ------
>
> ### ✅ 选项 1（你最初选择的）：
>
> > **Box 1: `ImagePushed`**, Box 2: `repository`, Box 3: `topic`
>
> - ❌ `ImagePushed`: **仅表示推送到 ACR**，还没部署。
> - ✅ `repository`: 是仓库字段（合理）。
> - ❌ `topic`: 事件源标识，不用于判断部署逻辑。
>
> ✅ 结论：**不符合“已部署”要求 → 错**
>
> ------
>
> ### ❌ 选项 2：
>
> > **Box 1: `ImageDeployed`**, Box 2: `service`, Box 3: `imageCollection`
>
> - ✅ `ImageDeployed`: ✅ 是部署完成后的事件！
> - ✅ `service`: ✅ 是部署目标（`ContentAnalysisService`）。
> - ❌ `imageCollection`: ❌ 没有这个字段（错误字段名）。
>
> ✅ 结论：**接近正确，但因 Box 3 错误字段 → 错**
>
> ------
>
> ### ❌ 选项 3：
>
> > **Box 1: `RepositoryUpdated`**, Box 2: `service`, Box 3: `imageCollection`
>
> - ❌ `RepositoryUpdated`: 没有这种有效事件类型
> - ✅ `service`: 合理
> - ❌ `imageCollection`: 同上，不存在
>
> ✅ 结论：**完全错误**
>
> ------
>
> ### ❌ 选项 4：
>
> > **Box 1: `RepositoryItem`**, Box 2: `aci`, Box 3: `topic`
>
> - ❌ `RepositoryItem`: 不是 ACR 的标准事件类型
> - ❌ `aci`: 这是一个资源类型，不是字段名
> - ❌ `topic`: 非部署相关字段
>
> ✅ 结论：**完全错误**

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to configure the `ContentUploadService` deployment. Which two actions should you perform?

![Question 220 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 220 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [x] Add the following markup to line CS23: `type: Private`.
- [ ] Add the following markup to line CS24: `osType: Windows`.
- [x] Add the following markup to line CS24: `osType: Linux`.
- [ ] Add the following markup to line CS23: `type: Public`.

> | 选项                | 分析                                                         |
> | ------------------- | ------------------------------------------------------------ |
> | ❌ `type: Public`    | **错误**，因为题干要求服务应为**内部服务**，只能通过内部虚拟网络访问。Public 会暴露给互联网，不安全。 |
> | ✅ `type: Private`   | **正确**，符合“只能从内部虚拟网络访问”的要求。               |
> | ❌ `osType: Windows` | **错误**，题干没有任何地方提到使用 Windows 容器，反而因为使用了 Azure Container Instances（通常为 Linux 镜像），应该是 Linux。 |
> | ✅ `osType: Linux`   | **正确**，考虑到 `ContentAnalysisService` 是数据科学团队构建的分析服务，且部署于 Azure Container Instances 上，**通常使用 Linux 容器镜像**，成本也更低。 |

**[⬆ Back to Top](#table-of-contents)**
