## Table of Contents

| No. | Questions |
| --- | --------------------------- |
| 1   | [You are implementing a software as a service (SaaS) ASP.NET Core web service that will run as an Azure Web App. The web service will use an on-premises SQL Server database for storage. The web service also includes a WebJob that processes data updates. Four customers will use the web service. Each instance of the WebJob processes data for a single customer and must run as a singleton instance. Each deployment must be tested by using deployment slots prior to serving production data. Azure costs must be minimized. Azure resources must be located in an isolated network. You need to configure the App Service plan for the Web App. How should you configure the App Service plan?](#you-are-implementing-a-software-as-a-service-saas-aspnet-core-web-service-that-will-run-as-an-azure-web-app-the-web-service-will-use-an-on-premises-sql-server-database-for-storage-the-web-service-also-includes-a-webjob-that-processes-data-updates-four-customers-will-use-the-web-service-each-instance-of-the-webjob-processes-data-for-a-single-customer-and-must-run-as-a-singleton-instance-each-deployment-must-be-tested-by-using-deployment-slots-prior-to-serving-production-data-azure-costs-must-be-minimized-azure-resources-must-be-located-in-an-isolated-network-you-need-to-configure-the-app-service-plan-for-the-web-app-how-should-you-configure-the-app-service-plan)
| 2   | [You are a developer for a software as a service (SaaS) company that uses an Azure Function to process orders. The Azure Function currently runs on an Azure Function app that is triggered by an Azure Storage queue. You are preparing to migrate the Azure Function to Kubernetes using Kubernetes-based Event Driven Autoscaling (KEDA). You need to configure Kubernetes Custom Resource Definitions (CRD) for the Azure Function. Which CRDs should you configure?](#you-are-a-developer-for-a-software-as-a-service-saas-company-that-uses-an-azure-function-to-process-orders-the-azure-function-currently-runs-on-an-azure-function-app-that-is-triggered-by-an-azure-storage-queue-you-are-preparing-to-migrate-the-azure-function-to-kubernetes-using-kubernetes-based-event-driven-autoscaling-keda-you-need-to-configure-kubernetes-custom-resource-definitions-crd-for-the-azure-function-which-crds-should-you-configure)
| 3   | [You are creating a CLI script that creates an Azure web app and related services in Azure App Service. The web app uses the following variables. You need to automatically deploy code from GitHub to the newly created web app. How should you complete the script?](#you-are-creating-a-cli-script-that-creates-an-azure-web-app-and-related-services-in-azure-app-service-the-web-app-uses-the-following-variables-you-need-to-automatically-deploy-code-from-github-to-the-newly-created-web-app-how-should-you-complete-the-script)
| 4   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Trigger the photo processing from Blob storage events. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-trigger-the-photo-processing-from-blob-storage-events-does-the-solution-meet-the-goal)
| 5   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the web.config file to include the applicationInitialization configuration element. Specify custom initialization actions to run the scripts. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-update-the-webconfig-file-to-include-the-applicationinitialization-configuration-element-specify-custom-initialization-actions-to-run-the-scripts-does-the-solution-meet-the-goal)
| 6   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Enable auto swap for the Testing slot. Deploy the app to the Testing slot. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-enable-auto-swap-for-the-testing-slot-deploy-the-app-to-the-testing-slot-does-the-solution-meet-the-goal)
| 7   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Disable auto swap. Update the app with a method named `statuscheck` to run the scripts. Re-enable auto swap and deploy the app to the Production slot. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-disable-auto-swap-update-the-app-with-a-method-named-statuscheck-to-run-the-scripts-re-enable-auto-swap-and-deploy-the-app-to-the-production-slot-does-the-solution-meet-the-goal)
| 8   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Convert the Azure Storage account to a BlockBlobStorage storage account. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-convert-the-azure-storage-account-to-a-blockblobstorage-storage-account-does-the-solution-meet-the-goal)
| 9   | [You are developing an Azure Web App. You configure TLS mutual authentication for the web app. You need to validate the client certificate in the web app.](#you-are-developing-an-azure-web-app-you-configure-tls-mutual-authentication-for-the-web-app-you-need-to-validate-the-client-certificate-in-the-web-app)
| 10   | [You are developing a Docker/Go using Azure App Service Web App for Containers. You plan to run the container in an App Service on Linux. You identify a Docker container image to use. None of your current resource groups reside in a location that supports Linux. You must minimize the number of resource groups required. You need to create the application and perform an initial deployment. Which three Azure CLI commands should you use to develop the solution?](#you-are-developing-a-dockergo-using-azure-app-service-web-app-for-containers-you-plan-to-run-the-container-in-an-app-service-on-linux-you-identify-a-docker-container-image-to-use-none-of-your-current-resource-groups-reside-in-a-location-that-supports-linux-you-must-minimize-the-number-of-resource-groups-required-you-need-to-create-the-application-and-perform-an-initial-deployment-which-three-azure-cli-commands-should-you-use-to-develop-the-solution)
| 11   | [Fourth Coffee has an ASP.NET Core web app that runs in Docker. The app is mapped to the `www.fourthcoffee.com` domain. Fourth Coffee is migrating this application to Azure. You need to provision an App Service Web App to host this docker image and map the custom domain to the App Service web app. A resource group named `FourthCoffeePublicWebResourceGroup` has been created in the WestUS region that contains an App Service Plan named `AppServiceLinuxDockerPlan`. Which order should the CLI commands be used to develop the solution?](#fourth-coffee-has-an-aspnet-core-web-app-that-runs-in-docker-the-app-is-mapped-to-the-wwwfourthcoffeecom-domain-fourth-coffee-is-migrating-this-application-to-azure-you-need-to-provision-an-app-service-web-app-to-host-this-docker-image-and-map-the-custom-domain-to-the-app-service-web-app-a-resource-group-named-fourthcoffeepublicwebresourcegroup-has-been-created-in-the-westus-region-that-contains-an-app-service-plan-named-appservicelinuxdockerplan-which-order-should-the-cli-commands-be-used-to-develop-the-solution)
| 12   | [You are developing a serverless Java application on Azure. You create a new Azure Key Vault to work with secrets from a new Azure Functions application. The application must meet the following requirements: Reference the Azure Key Vault without requiring any changes to the Java code. Dynamically add and remove instances of the Azure Functions host based on the number of incoming application events. Ensure that instances are perpetually warm to avoid any cold starts. Connect to a VNet. Authentication to the Azure Key Vault instance must be removed if the Azure Function application is deleted. You need to grant the Azure Functions application access to the Azure Key Vault. Which three actions should you perform in sequence?](#you-are-developing-a-serverless-java-application-on-azure-you-create-a-new-azure-key-vault-to-work-with-secrets-from-a-new-azure-functions-application-the-application-must-meet-the-following-requirements-reference-the-azure-key-vault-without-requiring-any-changes-to-the-java-code-dynamically-add-and-remove-instances-of-the-azure-functions-host-based-on-the-number-of-incoming-application-events-ensure-that-instances-are-perpetually-warm-to-avoid-any-cold-starts-connect-to-a-vnet-authentication-to-the-azure-key-vault-instance-must-be-removed-if-the-azure-function-application-is-deleted-you-need-to-grant-the-azure-functions-application-access-to-the-azure-key-vault-which-three-actions-should-you-perform-in-sequence)
| 13   | [You develop a website. You plan to host the website in Azure. You expect the website to experience high traffic volumes after it is published. You must ensure that the website remains available and responsive while minimizing cost. You need to deploy the website. What should you do?](#you-develop-a-website-you-plan-to-host-the-website-in-azure-you-expect-the-website-to-experience-high-traffic-volumes-after-it-is-published-you-must-ensure-that-the-website-remains-available-and-responsive-while-minimizing-cost-you-need-to-deploy-the-website-what-should-you-do)
| 14   | [A company is developing a Java web app. The web app code is hosted in a GitHub repository located at `https://github.com/Contoso/webapp`. The web app must be evaluated before it is moved to production. You must deploy the initial code release to a deployment slot named `staging`. You need to create the web app and deploy the code. How should you complete the commands?](#a-company-is-developing-a-java-web-app-the-web-app-code-is-hosted-in-a-github-repository-located-at-httpsgithubcomcontosowebapp-the-web-app-must-be-evaluated-before-it-is-moved-to-production-you-must-deploy-the-initial-code-release-to-a-deployment-slot-named-staging-you-need-to-create-the-web-app-and-deploy-the-code-how-should-you-complete-the-commands)
| 15   | [You have a web service that is used to pay for food deliveries. The web service uses Azure Cosmos DB as the data store. You plan to add a new feature that allows users to set a tip amount. The new feature requires that a property named tip on the document in Cosmos DB must be present and contain a numeric value. There are many existing websites and mobile apps that use the web service that will not be updated to set the tip property for some time. How should you complete the trigger?](#you-have-a-web-service-that-is-used-to-pay-for-food-deliveries-the-web-service-uses-azure-cosmos-db-as-the-data-store-you-plan-to-add-a-new-feature-that-allows-users-to-set-a-tip-amount-the-new-feature-requires-that-a-property-named-tip-on-the-document-in-cosmos-db-must-be-present-and-contain-a-numeric-value-there-are-many-existing-websites-and-mobile-apps-that-use-the-web-service-that-will-not-be-updated-to-set-the-tip-property-for-some-time-how-should-you-complete-the-trigger)
| 16   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Use the Durable Function async pattern to process the blob data. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-use-the-durable-function-async-pattern-to-process-the-blob-data-does-the-solution-meet-the-goal)
| 17   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Pass the HTTP trigger payload into an Azure Service Bus queue to be processed by a queue trigger function and return an immediate HTTP success response. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-pass-the-http-trigger-payload-into-an-azure-service-bus-queue-to-be-processed-by-a-queue-trigger-function-and-return-an-immediate-http-success-response-does-the-solution-meet-the-goal)
| 18   | [You develop an HTTP triggered Azure Function app to process Azure Storage blob data. The app is triggered using an output binding on the blob. The app continues to time out after four minutes. The app must process the blob data. You need to ensure the app does not time out and processes the blob data. Solution: Configure the app to use an App Service hosting plan and enable the Always On setting. Does the solution meet the goal?](#you-develop-an-http-triggered-azure-function-app-to-process-azure-storage-blob-data-the-app-is-triggered-using-an-output-binding-on-the-blob-the-app-continues-to-time-out-after-four-minutes-the-app-must-process-the-blob-data-you-need-to-ensure-the-app-does-not-time-out-and-processes-the-blob-data-solution-configure-the-app-to-use-an-app-service-hosting-plan-and-enable-the-always-on-setting-does-the-solution-meet-the-goal)
| 19   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Move photo processing to an Azure Function triggered from the blob upload. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-move-photo-processing-to-an-azure-function-triggered-from-the-blob-upload-does-the-solution-meet-the-goal)
| 20   | [You are developing an application that uses Azure Blob storage. The application must read the transaction logs of all the changes that occur to the blobs and the blob metadata in the storage account for auditing purposes. The changes must be in the order in which they occurred, include only create, update, delete, and copy operations and be retained for compliance reasons. You need to process the transaction logs asynchronously. What should you do?](#you-are-developing-an-application-that-uses-azure-blob-storage-the-application-must-read-the-transaction-logs-of-all-the-changes-that-occur-to-the-blobs-and-the-blob-metadata-in-the-storage-account-for-auditing-purposes-the-changes-must-be-in-the-order-in-which-they-occurred-include-only-create-update-delete-and-copy-operations-and-be-retained-for-compliance-reasons-you-need-to-process-the-transaction-logs-asynchronously-what-should-you-do)
| 21   | [You plan to create a Docker image that runs an ASP.NET Core application named `ContosoApp`. You have a setup script named `setupScript.ps1` and a series of application files including `ContosoApp.dll`. You need to create a Dockerfile document that meets the following requirements: Call setupScripts.ps1 when the container is built. Run `ContosoApp.dll` when the container starts. The Dockerfile document must be created in the same folder where `ContosoApp.dll` and `setupScript.ps1` are stored. Which five commands should you use to develop the solution?](#you-plan-to-create-a-docker-image-that-runs-an-aspnet-core-application-named-contosoapp-you-have-a-setup-script-named-setupscriptps1-and-a-series-of-application-files-including-contosoappdll-you-need-to-create-a-dockerfile-document-that-meets-the-following-requirements-call-setupscriptsps1-when-the-container-is-built-run-contosoappdll-when-the-container-starts-the-dockerfile-document-must-be-created-in-the-same-folder-where-contosoappdll-and-setupscriptps1-are-stored-which-five-commands-should-you-use-to-develop-the-solution)
| 22   | [You are developing an Azure Function App that processes images that are uploaded to an Azure Blob container. Images must be processed as quickly as possible after they are uploaded, and the solution must minimize latency. You create code to process images when the Function App is triggered. You need to configure the Function App. What should you do?](#you-are-developing-an-azure-function-app-that-processes-images-that-are-uploaded-to-an-azure-blob-container-images-must-be-processed-as-quickly-as-possible-after-they-are-uploaded-and-the-solution-must-minimize-latency-you-create-code-to-process-images-when-the-function-app-is-triggered-you-need-to-configure-the-function-app-what-should-you-do)
| 23   | [You are configuring a new development environment for a Java application. The environment requires a Virtual Machine Scale Set (VMSS), several storage accounts, and networking components. The VMSS must not be created until the storage accounts have been successfully created and an associated load balancer and virtual network is configured. How should you complete the Azure Resource Manager template?](#you-are-configuring-a-new-development-environment-for-a-java-application-the-environment-requires-a-virtual-machine-scale-set-vmss-several-storage-accounts-and-networking-components-the-vmss-must-not-be-created-until-the-storage-accounts-have-been-successfully-created-and-an-associated-load-balancer-and-virtual-network-is-configured-how-should-you-complete-the-azure-resource-manager-template)
| 24   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 1: The code will log the time that the order was processed from the queue.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-1-the-code-will-log-the-time-that-the-order-was-processed-from-the-queue)
| 25   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 2: When the ProcessOrders function fails, the function will retry up to five times for a given order, including the first try.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-2-when-the-processorders-function-fails-the-function-will-retry-up-to-five-times-for-a-given-order-including-the-first-try)
| 26   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 3: When there are multiple orders in the queue, a batch of orders will be received from the queue and the ProcessOrders function will run multiple instances concurrently to process the orders.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-3-when-there-are-multiple-orders-in-the-queue-a-batch-of-orders-will-be-received-from-the-queue-and-the-processorders-function-will-run-multiple-instances-concurrently-to-process-the-orders)
| 27   | [You are developing an Azure Function App by using Visual Studio. The app will process orders input by an Azure Web App. The web app places the order information into Azure Queue Storage. You need to review the Azure Function App code shown below. Question 4: The ProcessOrders function will output the order to an Orders table in Azure Table Storage.](#you-are-developing-an-azure-function-app-by-using-visual-studio-the-app-will-process-orders-input-by-an-azure-web-app-the-web-app-places-the-order-information-into-azure-queue-storage-you-need-to-review-the-azure-function-app-code-shown-below-question-4-the-processorders-function-will-output-the-order-to-an-orders-table-in-azure-table-storage)
| 28   | [You are developing a solution for a hospital to support the following use cases: The most recent patient status details must be retrieved even if multiple users in different locations have updated the patient record. Patient health monitoring data retrieved must be the current version or the prior version. After a patient is discharged and all charges have been assessed, the patient billing record contains the final charges. You provision a Cosmos DB NoSQL database and set the default consistency level for the database account to Strong. You set the value for Indexing Mode to Consistent. You need to minimize latency and any impact to the availability of the solution. You must override the default consistency level at the query level to meet the required consistency guarantees for the scenarios. Which consistency levels should you implement?](#you-are-developing-a-solution-for-a-hospital-to-support-the-following-use-cases-the-most-recent-patient-status-details-must-be-retrieved-even-if-multiple-users-in-different-locations-have-updated-the-patient-record-patient-health-monitoring-data-retrieved-must-be-the-current-version-or-the-prior-version-after-a-patient-is-discharged-and-all-charges-have-been-assessed-the-patient-billing-record-contains-the-final-charges-you-provision-a-cosmos-db-nosql-database-and-set-the-default-consistency-level-for-the-database-account-to-strong-you-set-the-value-for-indexing-mode-to-consistent-you-need-to-minimize-latency-and-any-impact-to-the-availability-of-the-solution-you-must-override-the-default-consistency-level-at-the-query-level-to-meet-the-required-consistency-guarantees-for-the-scenarios-which-consistency-levels-should-you-implement)
| 29   | [You are configuring a development environment for your team. You deploy the latest Visual Studio image from the Azure Marketplace to your Azure subscription. The development environment requires several software development kits (SDKs) and third-party components to support application development across the organization. You install and customize the deployed virtual machine (VM) for your development team. The customized VM must be saved to allow provisioning of a new team member development environment. You need to save the customized VM for future provisioning. Which tools or services should you use?](#you-are-configuring-a-development-environment-for-your-team-you-deploy-the-latest-visual-studio-image-from-the-azure-marketplace-to-your-azure-subscription-the-development-environment-requires-several-software-development-kits-sdks-and-third-party-components-to-support-application-development-across-the-organization-you-install-and-customize-the-deployed-virtual-machine-vm-for-your-development-team-the-customized-vm-must-be-saved-to-allow-provisioning-of-a-new-team-member-development-environment-you-need-to-save-the-customized-vm-for-future-provisioning-which-tools-or-services-should-you-use)
| 30   | [You are preparing to deploy a website to an Azure Web App from a GitHub repository. The website includes static content generated by a script. You plan to use the Azure Web App continuous deployment feature. You need to run the static generation script before the website starts serving traffic. What are two possible ways to achieve this goal?](#you-are-preparing-to-deploy-a-website-to-an-azure-web-app-from-a-github-repository-the-website-includes-static-content-generated-by-a-script-you-plan-to-use-the-azure-web-app-continuous-deployment-feature-you-need-to-run-the-static-generation-script-before-the-website-starts-serving-traffic-what-are-two-possible-ways-to-achieve-this-goal)
| 31   | [You are developing an application to use Azure Blob storage. You have configured Azure Blob storage to include change feeds. A copy of your storage account must be created in another region. Data must be copied from the current storage account to the new storage account directly between the storage servers. You need to create a copy of the storage account in another region and copy the data. In which order should you perform the actions?](#you-are-developing-an-application-to-use-azure-blob-storage-you-have-configured-azure-blob-storage-to-include-change-feeds-a-copy-of-your-storage-account-must-be-created-in-another-region-data-must-be-copied-from-the-current-storage-account-to-the-new-storage-account-directly-between-the-storage-servers-you-need-to-create-a-copy-of-the-storage-account-in-another-region-and-copy-the-data-in-which-order-should-you-perform-the-actions)
| 32   | [You are preparing to deploy an Azure virtual machine (VM)-based application. The VMs that run the application have the following requirements: When a VM is provisioned the firewall must be automatically configured before it can access Azure resources. Supporting services must be installed by using an Azure PowerShell script that is stored in Azure Storage. You need to ensure that the requirements are met. Which features should you use?](#you-are-preparing-to-deploy-an-azure-virtual-machine-vm-based-application-the-vms-that-run-the-application-have-the-following-requirements-when-a-vm-is-provisioned-the-firewall-must-be-automatically-configured-before-it-can-access-azure-resources-supporting-services-must-be-installed-by-using-an-azure-powershell-script-that-is-stored-in-azure-storage-you-need-to-ensure-that-the-requirements-are-met-which-features-should-you-use)
| 33   | [A company is developing a Node.js web app. The web app code is hosted in a GitHub repository located at `https://github.com/TailSpinToys/webapp`. The web app must be reviewed before it is moved to production. You must deploy the initial code release to a deployment slot named `review`. You need to create the web app and deploy the code. How should you complete the commands?](#a-company-is-developing-a-nodejs-web-app-the-web-app-code-is-hosted-in-a-github-repository-located-at-httpsgithubcomtailspintoyswebapp-the-web-app-must-be-reviewed-before-it-is-moved-to-production-you-must-deploy-the-initial-code-release-to-a-deployment-slot-named-review-you-need-to-create-the-web-app-and-deploy-the-code-how-should-you-complete-the-commands)
| 34   | [You are developing an application that needs access to an Azure virtual machine (VM). The access lifecycle for the application must be associated with the VM service instance. You need to enable managed identity for the VM. How should you complete the PowerShell segment?](#you-are-developing-an-application-that-needs-access-to-an-azure-virtual-machine-vm-the-access-lifecycle-for-the-application-must-be-associated-with-the-vm-service-instance-you-need-to-enable-managed-identity-for-the-vm-how-should-you-complete-the-powershell-segment)
| 35   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Create an Azure Function app that uses the Consumption hosting model and that is triggered from the blob upload. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-create-an-azure-function-app-that-uses-the-consumption-hosting-model-and-that-is-triggered-from-the-blob-upload-does-the-solution-meet-the-goal)
| 36   | [You develop and deploy an Azure App Service API app to a Windows-hosted deployment slot named Development. You create additional deployment slots named `Testing` and `Production`. You enable auto swap on the Production deployment slot. You need to ensure that scripts run and resources are available before a swap operation occurs. Solution: Update the app with a method named `statuscheck` to run the scripts. Update the app settings for the app. Set the `WEBSITE_SWAP_WARMUP_PING_PATH` and `WEBSITE_SWAP_WARMUP_PING_STATUSES` with a path to the new method and appropriate response codes. Does the solution meet the goal?](#you-develop-and-deploy-an-azure-app-service-api-app-to-a-windows-hosted-deployment-slot-named-development-you-create-additional-deployment-slots-named-testing-and-production-you-enable-auto-swap-on-the-production-deployment-slot-you-need-to-ensure-that-scripts-run-and-resources-are-available-before-a-swap-operation-occurs-solution-update-the-app-with-a-method-named-statuscheck-to-run-the-scripts-update-the-app-settings-for-the-app-set-the-website_swap_warmup_ping_path-and-website_swap_warmup_ping_statuses-with-a-path-to-the-new-method-and-appropriate-response-codes-does-the-solution-meet-the-goal)
| 37   | [You create the following PowerShell script. Question 1: A log alert is created that sends an email when the CPU percentage is above 60 percent for five minutes.](#you-create-the-following-powershell-script-question-1-a-log-alert-is-created-that-sends-an-email-when-the-cpu-percentage-is-above-60-percent-for-five-minutes)
| 38   | [You create the following PowerShell script. Question 2: A log alert is created that sends an email when the number of machine heartbeats in the past hour is less than five.](#you-create-the-following-powershell-script-question-2-a-log-alert-is-created-that-sends-an-email-when-the-number-of-machine-heartbeats-in-the-past-hour-is-less-than-five)
| 39   | [You create the following PowerShell script. Question 3: The log alert is scheduled to run every two hours.](#you-create-the-following-powershell-script-question-3-the-log-alert-is-scheduled-to-run-every-two-hours)
| 40   | [You are developing an Azure Function app. The app must meet the following requirements: Enable developers to write the functions by using the Rust language. Declaratively connect to an Azure Blob Storage account. You need to implement the app. Which Azure Function app features should you use?](#you-are-developing-an-azure-function-app-the-app-must-meet-the-following-requirements-enable-developers-to-write-the-functions-by-using-the-rust-language-declaratively-connect-to-an-azure-blob-storage-account-you-need-to-implement-the-app-which-azure-function-app-features-should-you-use)
| 41   | [You are developing an ASP.NET Core web application. You plan to deploy the application to Azure Web App for Containers. The application needs to store runtime diagnostic data that must be persisted across application restarts. You have the following code. You need to configure the application settings so that diagnostic data is stored as required. How should you configure the web app's settings?](#you-are-developing-an-aspnet-core-web-application-you-plan-to-deploy-the-application-to-azure-web-app-for-containers-the-application-needs-to-store-runtime-diagnostic-data-that-must-be-persisted-across-application-restarts-you-have-the-following-code-you-need-to-configure-the-application-settings-so-that-diagnostic-data-is-stored-as-required-how-should-you-configure-the-web-apps-settings)
| 42   | [You are developing a web app that is protected by Azure Web Application Firewall (WAF). All traffic to the web app is routed through an Azure Application Gateway instance that is used by multiple web apps. The web app address is `contoso.azurewebsites.net`. All traffic must be secured with SSL. The Azure Application Gateway instance is used by multiple web apps. You need to configure the Azure Application Gateway for the web app. Which two actions should you perform?](#you-are-developing-a-web-app-that-is-protected-by-azure-web-application-firewall-waf-all-traffic-to-the-web-app-is-routed-through-an-azure-application-gateway-instance-that-is-used-by-multiple-web-apps-the-web-app-address-is-contosoazurewebsitesnet-all-traffic-must-be-secured-with-ssl-the-azure-application-gateway-instance-is-used-by-multiple-web-apps-you-need-to-configure-the-azure-application-gateway-for-the-web-app-which-two-actions-should-you-perform)
| 43   | [You develop a software as a service (SaaS) offering to manage photographs. Users upload photos to a web service which then stores the photos in Azure Storage Blob storage. The storage account type is General-purpose V2. When photos are uploaded, they must be processed to produce and save a mobile-friendly version of the image. The process to produce a mobile-friendly version of the image must start in less than one minute. You need to design the process that starts the photo processing. Solution: Use the Azure Blob Storage change feed to trigger photo processing. Does the solution meet the goal?](#you-develop-a-software-as-a-service-saas-offering-to-manage-photographs-users-upload-photos-to-a-web-service-which-then-stores-the-photos-in-azure-storage-blob-storage-the-storage-account-type-is-general-purpose-v2-when-photos-are-uploaded-they-must-be-processed-to-produce-and-save-a-mobile-friendly-version-of-the-image-the-process-to-produce-a-mobile-friendly-version-of-the-image-must-start-in-less-than-one-minute-you-need-to-design-the-process-that-starts-the-photo-processing-solution-use-the-azure-blob-storage-change-feed-to-trigger-photo-processing-does-the-solution-meet-the-goal)
| 44   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 1: SaveScore will work with Cosmos DB.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-1-savescore-will-work-with-cosmos-db)
| 45   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 2: SaveScore will update and replace a record if one already exists with the same playerId and gameId.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-2-savescore-will-update-and-replace-a-record-if-one-already-exists-with-the-same-playerid-and-gameid)
| 46   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 3: Leader board data for the game will be automatically partitioned using gameId.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-3-leader-board-data-for-the-game-will-be-automatically-partitioned-using-gameid)
| 47   | [A company develops a series of mobile games. All games use a single leaderboard service. You have the following requirements: Code must be scalable and allow for growth. Each record must consist of a playerId, gameId, score, and time played. When users reach a new high score, the system will save the new score using the SaveScore function below. Each game is assigned an Id based on the series title. You plan to store customer information in Azure Cosmos DB. The following data already exists in the database: You develop the following code to save scores in the data store. (Line numbers are included for reference only.) You develop the following code to query the database. (Line numbers are included for reference only.). Question 4: SaveScore will store the values for the gameId and playerId parameters in the database.](#a-company-develops-a-series-of-mobile-games-all-games-use-a-single-leaderboard-service-you-have-the-following-requirements-code-must-be-scalable-and-allow-for-growth-each-record-must-consist-of-a-playerid-gameid-score-and-time-played-when-users-reach-a-new-high-score-the-system-will-save-the-new-score-using-the-savescore-function-below-each-game-is-assigned-an-id-based-on-the-series-title-you-plan-to-store-customer-information-in-azure-cosmos-db-the-following-data-already-exists-in-the-database-you-develop-the-following-code-to-save-scores-in-the-data-store-line-numbers-are-included-for-reference-only-you-develop-the-following-code-to-query-the-database-line-numbers-are-included-for-reference-only-question-4-savescore-will-store-the-values-for-the-gameid-and-playerid-parameters-in-the-database)
| 48   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 1: The code creates an infinite lease.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-1-the-code-creates-an-infinite-lease)
| 49   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 2: The code at line 06 always creates a new blob.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-2-the-code-at-line-06-always-creates-a-new-blob)
| 50   | [You are developing a solution that uses the Azure Storage Client library for .NET. You have the following code: (Line numbers are included for reference only.). Question 3: The finally block releases the lease.](#you-are-developing-a-solution-that-uses-the-azure-storage-client-library-for-net-you-have-the-following-code-line-numbers-are-included-for-reference-only-question-3-the-finally-block-releases-the-lease)
| 51   | [You are building a website that uses Azure Blob storage for data storage. You configure Azure Blob storage lifecycle to move all blobs to the archive tier after 30 days. Customers have requested a service-level agreement (SLA) for viewing data older than 30 days. You need to document the minimum SLA for data recovery. Which SLA should you use?](#you-are-building-a-website-that-uses-azure-blob-storage-for-data-storage-you-configure-azure-blob-storage-lifecycle-to-move-all-blobs-to-the-archive-tier-after-30-days-customers-have-requested-a-service-level-agreement-sla-for-viewing-data-older-than-30-days-you-need-to-document-the-minimum-sla-for-data-recovery-which-sla-should-you-use)
| 52   | [You are developing a ticket reservation system for an airline. The storage solution for the application must meet the following requirements: Ensure at least 99.99% availability and provide low latency. Accept reservations even when localized network outages or other unforeseen failures occur. Process reservations in the exact sequence as reservations are submitted to minimize overbooking or selling the same seat to multiple travelers. Allow simultaneous and out-of-order reservations with a maximum five-second tolerance window. You provision a resource group named `airlineResourceGroup` in the Azure South-Central US region. You need to provision a SQL API Cosmos DB account to support the app. How should you complete the Azure CLI commands?](#you-are-developing-a-ticket-reservation-system-for-an-airline-the-storage-solution-for-the-application-must-meet-the-following-requirements-ensure-at-least-9999-availability-and-provide-low-latency-accept-reservations-even-when-localized-network-outages-or-other-unforeseen-failures-occur-process-reservations-in-the-exact-sequence-as-reservations-are-submitted-to-minimize-overbooking-or-selling-the-same-seat-to-multiple-travelers-allow-simultaneous-and-out-of-order-reservations-with-a-maximum-five-second-tolerance-window-you-provision-a-resource-group-named-airlineresourcegroup-in-the-azure-south-central-us-region-you-need-to-provision-a-sql-api-cosmos-db-account-to-support-the-app-how-should-you-complete-the-azure-cli-commands)
| 53   | [You are preparing to deploy a Python website to an Azure Web App using a container. The solution will use multiple containers in the same container group. The Dockerfile that builds the container is as follows. You build a container by using the following command. The Azure Container Registry instance named `images` is a private registry. The user name and password for the registry is admin. The Web App must always run the same version of the website regardless of future builds. You need to create an Azure Web App to run the website. How should you complete the commands?](#you-are-preparing-to-deploy-a-python-website-to-an-azure-web-app-using-a-container-the-solution-will-use-multiple-containers-in-the-same-container-group-the-dockerfile-that-builds-the-container-is-as-follows-you-build-a-container-by-using-the-following-command-the-azure-container-registry-instance-named-images-is-a-private-registry-the-user-name-and-password-for-the-registry-is-admin-the-web-app-must-always-run-the-same-version-of-the-website-regardless-of-future-builds-you-need-to-create-an-azure-web-app-to-run-the-website-how-should-you-complete-the-commands)
| 54   | [You are developing a back-end Azure App Service that scales based on the number of messages contained in a Service Bus queue. A rule already exists to scale up the App Service when the average queue length of unprocessed and valid queue messages is greater than 1000. You need to add a new rule that will continuously scale down the App Service as long as the scale up condition is not met. How should you configure the Scale rule?](#you-are-developing-a-back-end-azure-app-service-that-scales-based-on-the-number-of-messages-contained-in-a-service-bus-queue-a-rule-already-exists-to-scale-up-the-app-service-when-the-average-queue-length-of-unprocessed-and-valid-queue-messages-is-greater-than-1000-you-need-to-add-a-new-rule-that-will-continuously-scale-down-the-app-service-as-long-as-the-scale-up-condition-is-not-met-how-should-you-configure-the-scale-rule)
| 55   | [You have an application that uses Azure Blob storage. You need to update the metadata of the blobs. Which three methods should you use to develop the solution?](#you-have-an-application-that-uses-azure-blob-storage-you-need-to-update-the-metadata-of-the-blobs-which-three-methods-should-you-use-to-develop-the-solution)
| 56   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-grid-configure-the-machine-identifier-as-the-partition-key-and-enable-capture-does-the-solution-meet-the-goal)
| 57   | [You develop Azure solutions. A .NET application needs to receive a message each time an Azure virtual machine finishes processing data. The messages must NOT persist after being processed by the receiving application. You need to implement the .NET object that will receive the messages. Which object should you use?](#you-develop-azure-solutions-a-net-application-needs-to-receive-a-message-each-time-an-azure-virtual-machine-finishes-processing-data-the-messages-must-not-persist-after-being-processed-by-the-receiving-application-you-need-to-implement-the-net-object-that-will-receive-the-messages-which-object-should-you-use)
| 58   | [You are maintaining an existing application that uses an Azure Blob GPv1 Premium storage account. Data older than three months is rarely used. Data newer than three months must be available immediately. Data older than a year must be saved but does not need to be available immediately. You need to configure the account to support a lifecycle management rule that moves blob data to archive storage for data not modified in the last year. Which three actions should you perform in sequence?](#you-are-maintaining-an-existing-application-that-uses-an-azure-blob-gpv1-premium-storage-account-data-older-than-three-months-is-rarely-used-data-newer-than-three-months-must-be-available-immediately-data-older-than-a-year-must-be-saved-but-does-not-need-to-be-available-immediately-you-need-to-configure-the-account-to-support-a-lifecycle-management-rule-that-moves-blob-data-to-archive-storage-for-data-not-modified-in-the-last-year-which-three-actions-should-you-perform-in-sequence)
| 59   | [You develop Azure solutions. You must connect to a No-SQL globally-distributed database by using the .NET API. You need to create an object to configure and execute requests in the database. Which code segment should you use?](#you-develop-azure-solutions-you-must-connect-to-a-no-sql-globally-distributed-database-by-using-the-net-api-you-need-to-create-an-object-to-configure-and-execute-requests-in-the-database-which-code-segment-should-you-use)
| 60   | [You have an existing Azure storage account that stores large volumes of data across multiple containers. You need to copy all data from the existing storage account to a new storage account. The copy process must meet the following requirements: Automate data movement. Minimize user input required to perform the operation. Ensure that the data movement process is recoverable. What should you use?](#you-have-an-existing-azure-storage-account-that-stores-large-volumes-of-data-across-multiple-containers-you-need-to-copy-all-data-from-the-existing-storage-account-to-a-new-storage-account-the-copy-process-must-meet-the-following-requirements-automate-data-movement-minimize-user-input-required-to-perform-the-operation-ensure-that-the-data-movement-process-is-recoverable-what-should-you-use)
| 61   | [You are developing a web service that will run on Azure virtual machines that use Azure Storage. You configure all virtual machines to use managed identities. You have the following requirements: Secret-based authentication mechanisms are not permitted for accessing an Azure Storage account. Must use only Azure Instance Metadata Service endpoints. You need to write code to retrieve an access token to access Azure Storage.](#you-are-developing-a-web-service-that-will-run-on-azure-virtual-machines-that-use-azure-storage-you-configure-all-virtual-machines-to-use-managed-identities-you-have-the-following-requirements-secret-based-authentication-mechanisms-are-not-permitted-for-accessing-an-azure-storage-account-must-use-only-azure-instance-metadata-service-endpoints-you-need-to-write-code-to-retrieve-an-access-token-to-access-azure-storage)
| 62   | [You are developing a new page for a website that uses Azure Cosmos DB for data storage. The feature uses documents that have the following format. You must display data for the new page in a specific order. You create the following query for the page. You need to configure a Cosmos DB policy to support the query. How should you configure the policy?](#you-are-developing-a-new-page-for-a-website-that-uses-azure-cosmos-db-for-data-storage-the-feature-uses-documents-that-have-the-following-format-you-must-display-data-for-the-new-page-in-a-specific-order-you-create-the-following-query-for-the-page-you-need-to-configure-a-cosmos-db-policy-to-support-the-query-how-should-you-configure-the-policy)
| 63   | [You are building a traffic monitoring system that monitors traffic along six highways. The system produces time series analysis-based reports for each highway. Data from traffic sensors are stored in Azure Event Hub. Traffic data is consumed by four departments. Each department has an Azure Web App that displays the time series-based reports and contains a WebJob that processes the incoming data from Event Hub. All Web Apps run on App Service Plans with three instances. Data throughput must be maximized. Latency must be minimized. You need to implement the Azure Event Hub. Which settings should you use?](#you-are-building-a-traffic-monitoring-system-that-monitors-traffic-along-six-highways-the-system-produces-time-series-analysis-based-reports-for-each-highway-data-from-traffic-sensors-are-stored-in-azure-event-hub-traffic-data-is-consumed-by-four-departments-each-department-has-an-azure-web-app-that-displays-the-time-series-based-reports-and-contains-a-webjob-that-processes-the-incoming-data-from-event-hub-all-web-apps-run-on-app-service-plans-with-three-instances-data-throughput-must-be-maximized-latency-must-be-minimized-you-need-to-implement-the-azure-event-hub-which-settings-should-you-use)
| 64   | [You are developing a microservices solution. You plan to deploy the solution to a multinode Azure Kubernetes Service (AKS) cluster. You need to deploy a solution that includes the following features: reverse proxy capabilities configurable traffic routing TLS termination with a custom certificate. Which components should you use?](#you-are-developing-a-microservices-solution-you-plan-to-deploy-the-solution-to-a-multinode-azure-kubernetes-service-aks-cluster-you-need-to-deploy-a-solution-that-includes-the-following-features-reverse-proxy-capabilities-configurable-traffic-routing-tls-termination-with-a-custom-certificate-which-components-should-you-use)
| 65   | [You are implementing an order processing system. A point of sale application publishes orders to topics in an Azure Service Bus queue. The Label property for the topic includes the following data. The system has the following requirements for subscriptions. You need to implement filtering and maximize throughput while evaluating filters. Which filter types should you implement?](#you-are-implementing-an-order-processing-system-a-point-of-sale-application-publishes-orders-to-topics-in-an-azure-service-bus-queue-the-label-property-for-the-topic-includes-the-following-data-the-system-has-the-following-requirements-for-subscriptions-you-need-to-implement-filtering-and-maximize-throughput-while-evaluating-filters-which-filter-types-should-you-implement)
| 66   | [Your company has several websites that use a company logo image. You use Azure Content Delivery Network (CDN) to store the static image. You need to determine the correct process of how the CDN and the Point of Presence (POP) server will distribute the image and list the items in the correct order. In which order do the actions occur?](#your-company-has-several-websites-that-use-a-company-logo-image-you-use-azure-content-delivery-network-cdn-to-store-the-static-image-you-need-to-determine-the-correct-process-of-how-the-cdn-and-the-point-of-presence-pop-server-will-distribute-the-image-and-list-the-items-in-the-correct-order-in-which-order-do-the-actions-occur)
| 67   | [You are developing an Azure Cosmos DB solution by using the Azure Cosmos DB SQL API. The data includes millions of documents. Each document may contain hundreds of properties. The properties of the documents do not contain distinct values for partitioning. Azure Cosmos DB must scale individual containers in the database to meet the performance needs of the application by spreading the workload evenly across all partitions over time. You need to select a partition key. Which two partition keys can you use?](#you-are-developing-an-azure-cosmos-db-solution-by-using-the-azure-cosmos-db-sql-api-the-data-includes-millions-of-documents-each-document-may-contain-hundreds-of-properties-the-properties-of-the-documents-do-not-contain-distinct-values-for-partitioning-azure-cosmos-db-must-scale-individual-containers-in-the-database-to-meet-the-performance-needs-of-the-application-by-spreading-the-workload-evenly-across-all-partitions-over-time-you-need-to-select-a-partition-key-which-two-partition-keys-can-you-use)
| 68   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 1: A database named `SalesOrders` is created. The database will include two containers.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-1-a-database-named-salesorders-is-created-the-database-will-include-two-containers)
| 69   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 2: Container1 will contain two items.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-2-container1-will-contain-two-items)
| 70   | [You are developing an Azure-hosted e-commerce web application. The application will use Azure Cosmos DB to store sales orders. You are using the latest SDK to manage the sales orders in the database. You create a new Azure Cosmos DB instance. You include a valid endpoint and valid authorization key to an appSettings.json file in the code project. You are evaluating the following application code: (Line number are included for reference only.). Question 3: Container2 will contain one item.](#you-are-developing-an-azure-hosted-e-commerce-web-application-the-application-will-use-azure-cosmos-db-to-store-sales-orders-you-are-using-the-latest-sdk-to-manage-the-sales-orders-in-the-database-you-create-a-new-azure-cosmos-db-instance-you-include-a-valid-endpoint-and-valid-authorization-key-to-an-appsettingsjson-file-in-the-code-project-you-are-evaluating-the-following-application-code-line-number-are-included-for-reference-only-question-3-container2-will-contain-one-item)
| 71   | [You develop an Azure solution that uses Cosmos DB. The current Cosmos DB container must be replicated and must use a partition key that is optimized for queries. You need to implement a change feed processor solution. Which change feed processor components should you use?](#you-develop-an-azure-solution-that-uses-cosmos-db-the-current-cosmos-db-container-must-be-replicated-and-must-use-a-partition-key-that-is-optimized-for-queries-you-need-to-implement-a-change-feed-processor-solution-which-change-feed-processor-components-should-you-use)
| 72   | [You develop a web application. You need to register the application with an active Microsoft Entra ID tenant. Which three actions should you perform in sequence?](#you-develop-a-web-application-you-need-to-register-the-application-with-an-active-microsoft-entra-id-tenant-which-three-actions-should-you-perform-in-sequence)
| 73   | [You have a new Azure subscription. You are developing an internal website for employees to view sensitive data. The website uses Microsoft Entra ID for authentication. You need to implement multifactor authentication for the website. Which two actions should you perform?](#you-have-a-new-azure-subscription-you-are-developing-an-internal-website-for-employees-to-view-sensitive-data-the-website-uses-microsoft-entra-id-for-authentication-you-need-to-implement-multifactor-authentication-for-the-website-which-two-actions-should-you-perform)
| 74   | [You are developing a Java application that uses Cassandra to store key and value data. You plan to use a new Azure Cosmos DB resource and the Cassandra API in the application. You create an Microsoft Entra ID group named Cosmos DB Creators to enable provisioning of Azure Cosmos accounts, databases, and containers. The Microsoft Entra ID group must not be able to access the keys that are required to access the data. You need to restrict access to the Microsoft Entra ID group. Which role-based access control should you use?](#you-are-developing-a-java-application-that-uses-cassandra-to-store-key-and-value-data-you-plan-to-use-a-new-azure-cosmos-db-resource-and-the-cassandra-api-in-the-application-you-create-an-microsoft-entra-id-group-named-cosmos-db-creators-to-enable-provisioning-of-azure-cosmos-accounts-databases-and-containers-the-microsoft-entra-id-group-must-not-be-able-to-access-the-keys-that-are-required-to-access-the-data-you-need-to-restrict-access-to-the-microsoft-entra-id-group-which-role-based-access-control-should-you-use)
| 75   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure the Azure Web App for the website to allow only authenticated requests and require Microsoft Entra ID log on. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-configure-the-azure-web-app-for-the-website-to-allow-only-authenticated-requests-and-require-microsoft-entra-id-log-on-does-the-solution-meet-the-goal)
| 76   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, set value of the `groupMembershipClaims` option to All. In the website, use the value of the groups claim from the JWT for the user to determine permissions. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-create-a-new-microsoft-entra-id-application-in-the-applications-manifest-set-value-of-the-groupmembershipclaims-option-to-all-in-the-website-use-the-value-of-the-groups-claim-from-the-jwt-for-the-user-to-determine-permissions-does-the-solution-meet-the-goal)
| 77   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Create a new Microsoft Entra ID application. In the application's manifest, define application roles that match the required permission levels for the application. Assign the appropriate Microsoft Entra ID group to each role. In the website, use the value of the roles claim from the JWT for the user to determine permissions. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-create-a-new-microsoft-entra-id-application-in-the-applications-manifest-define-application-roles-that-match-the-required-permission-levels-for-the-application-assign-the-appropriate-microsoft-entra-id-group-to-each-role-in-the-website-use-the-value-of-the-roles-claim-from-the-jwt-for-the-user-to-determine-permissions-does-the-solution-meet-the-goal)
| 78   | [You are developing an application to securely transfer data between on-premises file systems and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault. The application uses the Azure Key Vault APIs. The application must allow recovery of an accidental deletion of the key vault or key vault objects. Key vault objects must be retained for 90 days after deletion. You need to protect the key vault and key vault objects. Which Azure Key Vault feature should you use?](#you-are-developing-an-application-to-securely-transfer-data-between-on-premises-file-systems-and-azure-blob-storage-the-application-stores-keys-secrets-and-certificates-in-azure-key-vault-the-application-uses-the-azure-key-vault-apis-the-application-must-allow-recovery-of-an-accidental-deletion-of-the-key-vault-or-key-vault-objects-key-vault-objects-must-be-retained-for-90-days-after-deletion-you-need-to-protect-the-key-vault-and-key-vault-objects-which-azure-key-vault-feature-should-you-use)
| 79   | [You provide an Azure API Management managed web service to clients. The back-end web service implements HTTP Strict Transport Security (HSTS). Every request to the backend service must include a valid HTTP authorization header. You need to configure the Azure API Management instance with an authentication policy. Which two policies can you use?](#you-provide-an-azure-api-management-managed-web-service-to-clients-the-back-end-web-service-implements-http-strict-transport-security-hsts-every-request-to-the-backend-service-must-include-a-valid-http-authorization-header-you-need-to-configure-the-azure-api-management-instance-with-an-authentication-policy-which-two-policies-can-you-use)
| 80   | [You are developing an ASP.NET Core website that can be used to manage photographs which are stored in Azure Blob Storage containers. Users of the website authenticate by using their Microsoft Entra ID credentials. You implement role-based access control (RBAC) role permissions on the containers that store photographs. You assign users to RBAC roles. You need to configure the website's Microsoft Entra ID Application so that user's permissions can be used with the Azure Blob containers. How should you configure the application?](#you-are-developing-an-aspnet-core-website-that-can-be-used-to-manage-photographs-which-are-stored-in-azure-blob-storage-containers-users-of-the-website-authenticate-by-using-their-microsoft-entra-id-credentials-you-implement-role-based-access-control-rbac-role-permissions-on-the-containers-that-store-photographs-you-assign-users-to-rbac-roles-you-need-to-configure-the-websites-microsoft-entra-id-application-so-that-users-permissions-can-be-used-with-the-azure-blob-containers-how-should-you-configure-the-application)
| 81   | [You are developing an ASP.NET Core app that includes feature flags which are managed by Azure App Configuration. You create an Azure App Configuration store named `AppFeatureFlagStore` that contains a feature flag named `Export`. You need to update the app to meet the following requirements: Use the `Export` feature in the app without requiring a restart of the app. Validate users before users are allowed access to secure resources. Permit users to access secure resources. How should you complete the code segment?](#you-are-developing-an-aspnet-core-app-that-includes-feature-flags-which-are-managed-by-azure-app-configuration-you-create-an-azure-app-configuration-store-named-appfeatureflagstore-that-contains-a-feature-flag-named-export-you-need-to-update-the-app-to-meet-the-following-requirements-use-the-export-feature-in-the-app-without-requiring-a-restart-of-the-app-validate-users-before-users-are-allowed-access-to-secure-resources-permit-users-to-access-secure-resources-how-should-you-complete-the-code-segment)
| 82   | [You have an application that includes an Azure Web app and several Azure Function apps. Application secrets including connection strings and certificates are stored in Azure Key Vault. Secrets must not be stored in the application or application runtime environment. Changes to Microsoft Entra ID must be minimized. You need to design the approach to loading application secrets. What should you do?](#you-have-an-application-that-includes-an-azure-web-app-and-several-azure-function-apps-application-secrets-including-connection-strings-and-certificates-are-stored-in-azure-key-vault-secrets-must-not-be-stored-in-the-application-or-application-runtime-environment-changes-to-microsoft-entra-id-must-be-minimized-you-need-to-design-the-approach-to-loading-application-secrets-what-should-you-do)
| 83   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Key Vault key named `skey`. 2. Encrypt the intake forms using the public key portion of skey. 3. Store the encrypted data in Azure Blob storage. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-1-create-an-azure-key-vault-key-named-skey-2-encrypt-the-intake-forms-using-the-public-key-portion-of-skey-3-store-the-encrypted-data-in-azure-blob-storage-does-the-solution-meet-the-goal)
| 84   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: 1. Create an Azure Cosmos DB database with Storage Service Encryption enabled. 2. Store the intake forms in the Azure Cosmos DB database. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-1-create-an-azure-cosmos-db-database-with-storage-service-encryption-enabled-2-store-the-intake-forms-in-the-azure-cosmos-db-database-does-the-solution-meet-the-goal)
| 85   | [You are developing a medical records document management website. The website is used to store scanned copies of patient intake forms. If the stored intake forms are downloaded from storage by a third party, the contents of the forms must not be compromised. You need to store the intake forms according to the requirements. Solution: Store the intake forms as Azure Key Vault secrets. Does the solution meet the goal?](#you-are-developing-a-medical-records-document-management-website-the-website-is-used-to-store-scanned-copies-of-patient-intake-forms-if-the-stored-intake-forms-are-downloaded-from-storage-by-a-third-party-the-contents-of-the-forms-must-not-be-compromised-you-need-to-store-the-intake-forms-according-to-the-requirements-solution-store-the-intake-forms-as-azure-key-vault-secrets-does-the-solution-meet-the-goal)
| 86   | [You plan to deploy a new application to a Linux virtual machine (VM) that is hosted in Azure. The entire VM must be secured at rest by using industry-standard encryption technology to address organizational security and compliance requirements. You need to configure Azure Disk Encryption for the VM. How should you complete the Azure CLI commands?](#you-plan-to-deploy-a-new-application-to-a-linux-virtual-machine-vm-that-is-hosted-in-azure-the-entire-vm-must-be-secured-at-rest-by-using-industry-standard-encryption-technology-to-address-organizational-security-and-compliance-requirements-you-need-to-configure-azure-disk-encryption-for-the-vm-how-should-you-complete-the-azure-cli-commands)
| 87   | [Your company is developing an Azure API hosted in Azure. You need to implement authentication for the Azure API to access other Azure resources. You have the following requirements: All API calls must be authenticated. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?](#your-company-is-developing-an-azure-api-hosted-in-azure-you-need-to-implement-authentication-for-the-azure-api-to-access-other-azure-resources-you-have-the-following-requirements-all-api-calls-must-be-authenticated-callers-to-the-api-must-not-send-credentials-to-the-api-which-authentication-mechanism-should-you-use)
| 88   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 1: The file MIME type is supported by the service.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-1-the-file-mime-type-is-supported-by-the-service)
| 89   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 2: Edge nodes must be purged of all cache assets.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-2-edge-nodes-must-be-purged-of-all-cache-assets)
| 90   | [You are using Azure Front Door Service. You are expecting inbound files to be compressed by using Brotli compression. You discover that inbound XML files are not compressed. The files are 9 megabytes (MB) in size. You need to determine the root cause for the issue. Question 3: The compression type is supported.](#you-are-using-azure-front-door-service-you-are-expecting-inbound-files-to-be-compressed-by-using-brotli-compression-you-discover-that-inbound-xml-files-are-not-compressed-the-files-are-9-megabytes-mb-in-size-you-need-to-determine-the-root-cause-for-the-issue-question-3-the-compression-type-is-supported)
| 91   | [You are developing an application. You have an Azure user account that has access to two subscriptions. You need to retrieve a storage account key secret from Azure Key Vault. In which order should you arrange the PowerShell commands to develop the solution?](#you-are-developing-an-application-you-have-an-azure-user-account-that-has-access-to-two-subscriptions-you-need-to-retrieve-a-storage-account-key-secret-from-azure-key-vault-in-which-order-should-you-arrange-the-powershell-commands-to-develop-the-solution)
| 92   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use an `X.509` certificate to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-use-an-x509-certificate-to-authenticate-the-vm-with-azure-resource-manager-does-the-solution-meet-the-goal)
| 93   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Use the Reader role-based access control (RBAC) role to authenticate the VM with Azure Resource Manager. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-use-the-reader-role-based-access-control-rbac-role-to-authenticate-the-vm-with-azure-resource-manager-does-the-solution-meet-the-goal)
| 94   | [You are building a website that is used to review restaurants. The website will use an Azure CDN to improve performance and add functionality to requests. You build and deploy a mobile app for Apple iPhones. Whenever a user accesses the website from an iPhone, the user must be redirected to the app store. You need to implement an Azure CDN rule that ensures that iPhone users are redirected to the app store. How should you complete the Azure Resource Manager template?](#you-are-building-a-website-that-is-used-to-review-restaurants-the-website-will-use-an-azure-cdn-to-improve-performance-and-add-functionality-to-requests-you-build-and-deploy-a-mobile-app-for-apple-iphones-whenever-a-user-accesses-the-website-from-an-iphone-the-user-must-be-redirected-to-the-app-store-you-need-to-implement-an-azure-cdn-rule-that-ensures-that-iphone-users-are-redirected-to-the-app-store-how-should-you-complete-the-azure-resource-manager-template)
| 95   | [You are developing a website that will run as an Azure Web App. Users will authenticate by using their Microsoft Entra ID credentials. You plan to assign users one of the following permission levels for the website: `admin`, `normal`, and `reader`. A user's Microsoft Entra ID group membership must be used to determine the permission level. You need to configure authorization. Solution: Configure and use Integrated Windows Authentication in the website. In the website, query Microsoft Graph API to load the group to which the user is a member. Does the solution meet the goal?](#you-are-developing-a-website-that-will-run-as-an-azure-web-app-users-will-authenticate-by-using-their-microsoft-entra-id-credentials-you-plan-to-assign-users-one-of-the-following-permission-levels-for-the-website-admin-normal-and-reader-a-users-microsoft-entra-id-group-membership-must-be-used-to-determine-the-permission-level-you-need-to-configure-authorization-solution-configure-and-use-integrated-windows-authentication-in-the-website-in-the-website-query-microsoft-graph-api-to-load-the-group-to-which-the-user-is-a-member-does-the-solution-meet-the-goal)
| 96   | [You develop Azure solutions. You must grant a virtual machine (VM) access to specific resource groups in Azure Resource Manager. You need to obtain an Azure Resource Manager access token. Solution: Run the `Invoke-RestMethod` cmdlet to make a request to the local managed identity for Azure resources endpoint. Does the solution meet the goal?](#you-develop-azure-solutions-you-must-grant-a-virtual-machine-vm-access-to-specific-resource-groups-in-azure-resource-manager-you-need-to-obtain-an-azure-resource-manager-access-token-solution-run-the-invoke-restmethod-cmdlet-to-make-a-request-to-the-local-managed-identity-for-azure-resources-endpoint-does-the-solution-meet-the-goal)
| 97   | [Your company's Azure subscription includes an Azure Log Analytics workspace. Your company has a hundred on-premises servers that run either Windows Server 2012 R2 or Windows Server 2016, and is linked to the Azure Log Analytics workspace. The Azure Log Analytics workspace is set up to gather performance counters associated with security from these linked servers. You must configure alerts based on the information gathered by the Azure Log Analytics workspace. You have to make sure that alert rules allow for dimensions, and that alert creation time should be kept to a minimum. Furthermore, a single alert notification must be created when the alert is created and when the alert is resolved. You need to make use of the necessary signal type when creating the alert rules. Which of the following is the option you should use?](#your-companys-azure-subscription-includes-an-azure-log-analytics-workspace-your-company-has-a-hundred-on-premises-servers-that-run-either-windows-server-2012-r2-or-windows-server-2016-and-is-linked-to-the-azure-log-analytics-workspace-the-azure-log-analytics-workspace-is-set-up-to-gather-performance-counters-associated-with-security-from-these-linked-servers-you-must-configure-alerts-based-on-the-information-gathered-by-the-azure-log-analytics-workspace-you-have-to-make-sure-that-alert-rules-allow-for-dimensions-and-that-alert-creation-time-should-be-kept-to-a-minimum-furthermore-a-single-alert-notification-must-be-created-when-the-alert-is-created-and-when-the-alert-is-resolved-you-need-to-make-use-of-the-necessary-signal-type-when-creating-the-alert-rules-which-of-the-following-is-the-option-you-should-use)
| 98   | [You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation. You want the application to allow customers to search the index by using regular expressions. What should you do?](#you-are-developing-a-net-core-mvc-application-that-allows-customers-to-research-independent-holiday-accommodation-providers-you-want-to-implement-azure-search-to-allow-the-application-to-search-the-index-by-using-various-criteria-to-locate-documents-related-to-accommodation-you-want-the-application-to-allow-customers-to-search-the-index-by-using-regular-expressions-what-should-you-do)
| 99   | [You are a developer at your company. You need to update the definitions for an existing Logic App. What should you use?](#you-are-a-developer-at-your-company-you-need-to-update-the-definitions-for-an-existing-logic-app-what-should-you-use)
| 100   | [The cluster uses Azure Monitor for containers to monitor the cluster. The application has sticky sessions enabled on the ingress controller. Some customers report a large number of errors in the application over the last 24 hours. You need to determine on which virtual machines (VMs) the errors are occurring. How should you complete the Azure Monitor query?](#the-cluster-uses-azure-monitor-for-containers-to-monitor-the-cluster-the-application-has-sticky-sessions-enabled-on-the-ingress-controller-some-customers-report-a-large-number-of-errors-in-the-application-over-the-last-24-hours-you-need-to-determine-on-which-virtual-machines-vms-the-errors-are-occurring-how-should-you-complete-the-azure-monitor-query)
| 101   | [You plan to deploy a web app to App Service on Linux. You create an App Service plan. You create and push a custom Docker image that contains the web app to Azure Container Registry. You need to access the console logs generated from inside the container in real-time. How should you complete the Azure CLI command?](#you-plan-to-deploy-a-web-app-to-app-service-on-linux-you-create-an-app-service-plan-you-create-and-push-a-custom-docker-image-that-contains-the-web-app-to-azure-container-registry-you-need-to-access-the-console-logs-generated-from-inside-the-container-in-real-time-how-should-you-complete-the-azure-cli-command)
| 102   | [You develop an app that allows users to upload photos and videos to Azure storage. The app uses a storage REST API call to upload the media to a blob storage account named `Account1`. You have blob storage containers named `Container1` and `Container2`. Uploading of videos occurs on an irregular basis. You need to copy specific blobs from `Container1` to `Container2` when a new video is uploaded. What should you do?](#you-develop-an-app-that-allows-users-to-upload-photos-and-videos-to-azure-storage-the-app-uses-a-storage-rest-api-call-to-upload-the-media-to-a-blob-storage-account-named-account1-you-have-blob-storage-containers-named-container1-and-container2-uploading-of-videos-occurs-on-an-irregular-basis-you-need-to-copy-specific-blobs-from-container1-to-container2-when-a-new-video-is-uploaded-what-should-you-do)
| 103   | [A web service provides customer summary information for e-commerce partners. The web service is implemented as an Azure Function app with an HTTP trigger. Access to the API is provided by an Azure API Management instance. The API Management instance is configured in consumption plan mode. All API calls are authenticated by using OAuth. API calls must be cached. Customers must not be able to view cached data for other customers. You need to configure API Management policies for caching. How should you complete the policy statement?](#a-web-service-provides-customer-summary-information-for-e-commerce-partners-the-web-service-is-implemented-as-an-azure-function-app-with-an-http-trigger-access-to-the-api-is-provided-by-an-azure-api-management-instance-the-api-management-instance-is-configured-in-consumption-plan-mode-all-api-calls-are-authenticated-by-using-oauth-api-calls-must-be-cached-customers-must-not-be-able-to-view-cached-data-for-other-customers-you-need-to-configure-api-management-policies-for-caching-how-should-you-complete-the-policy-statement)
| 104   | [You are developing an ASP.NET Core website that uses Azure FrontDoor. The website is used to build custom weather data sets for researchers. Data sets are downloaded by users as Comma Separated Value (CSV) files. The data is refreshed every 10 hours. Specific files must be purged from the FrontDoor cache based upon Response Header values. You need to purge individual assets from the Front Door cache. Which type of cache purge should you use?](#you-are-developing-an-aspnet-core-website-that-uses-azure-frontdoor-the-website-is-used-to-build-custom-weather-data-sets-for-researchers-data-sets-are-downloaded-by-users-as-comma-separated-value-csv-files-the-data-is-refreshed-every-10-hours-specific-files-must-be-purged-from-the-frontdoor-cache-based-upon-response-header-values-you-need-to-purge-individual-assets-from-the-front-door-cache-which-type-of-cache-purge-should-you-use)
| 105   | [Contoso, Ltd. provides an API to customers by using Azure API Management (APIM). The API authorizes users with a JWT token. You must implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID. You need to add the following policies to the policies file: a set-variable policy to store the detected user identity a cache-lookup-value policy a cache-store-value policy a find-and-replace policy to update the response body with the user profile information To which policy section should you add the policies?](#contoso-ltd-provides-an-api-to-customers-by-using-azure-api-management-apim-the-api-authorizes-users-with-a-jwt-token-you-must-implement-response-caching-for-the-apim-gateway-the-caching-mechanism-must-detect-the-user-id-of-the-client-that-accesses-data-for-a-given-location-and-cache-the-response-for-that-user-id-you-need-to-add-the-following-policies-to-the-policies-file-a-set-variable-policy-to-store-the-detected-user-identity-a-cache-lookup-value-policy-a-cache-store-value-policy-a-find-and-replace-policy-to-update-the-response-body-with-the-user-profile-information-to-which-policy-section-should-you-add-the-policies)
| 106   | [You are developing an application to retrieve user profile information. The application will use the Microsoft Graph SDK. The app must retrieve user profile information by using a Microsoft Graph API call. You need to call the Microsoft Graph API from the application. In which order should you perform the actions?](#you-are-developing-an-application-to-retrieve-user-profile-information-the-application-will-use-the-microsoft-graph-sdk-the-app-must-retrieve-user-profile-information-by-using-a-microsoft-graph-api-call-you-need-to-call-the-microsoft-graph-api-from-the-application-in-which-order-should-you-perform-the-actions)
| 107   | [You develop and deploy an Azure Logic App that calls an Azure Function app. The Azure Function App includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Logic App must use Azure Monitor logs to record and store information about runtime data and events. The logs must be stored in the Azure Blob storage account. You need to set up Azure Monitor logs and collect diagnostics data for the Azure Logic App. Which three actions should you perform in sequence?](#you-develop-and-deploy-an-azure-logic-app-that-calls-an-azure-function-app-the-azure-function-app-includes-an-openapi-swagger-definition-and-uses-an-azure-blob-storage-account-all-resources-are-secured-by-using-microsoft-entra-id-the-logic-app-must-use-azure-monitor-logs-to-record-and-store-information-about-runtime-data-and-events-the-logs-must-be-stored-in-the-azure-blob-storage-account-you-need-to-set-up-azure-monitor-logs-and-collect-diagnostics-data-for-the-azure-logic-app-which-three-actions-should-you-perform-in-sequence)
| 108   | [You develop an application. You plan to host the application on a set of virtual machines (VMs) in Azure. You need to configure Azure Monitor to collect logs from the application. Which four actions should you perform in sequence?](#you-develop-an-application-you-plan-to-host-the-application-on-a-set-of-virtual-machines-vms-in-azure-you-need-to-configure-azure-monitor-to-collect-logs-from-the-application-which-four-actions-should-you-perform-in-sequence)
| 109   | [You have an application that provides weather forecasting data to external partners. You use Azure API Management to publish APIs. You must change the behavior of the API to meet the following requirements: Support alternative input parameters. Remove formatting text from responses. Provide additional context to back-end services. Which types of policies should you implement?](#you-have-an-application-that-provides-weather-forecasting-data-to-external-partners-you-use-azure-api-management-to-publish-apis-you-must-change-the-behavior-of-the-api-to-meet-the-following-requirements-support-alternative-input-parameters-remove-formatting-text-from-responses-provide-additional-context-to-back-end-services-which-types-of-policies-should-you-implement)
| 110   | [Your company is developing an Azure API. You need to implement authentication for the Azure API. You have the following requirements: All API calls must be secure. Callers to the API must not send credentials to the API. Which authentication mechanism should you use?](#your-company-is-developing-an-azure-api-you-need-to-implement-authentication-for-the-azure-api-you-have-the-following-requirements-all-api-calls-must-be-secure-callers-to-the-api-must-not-send-credentials-to-the-api-which-authentication-mechanism-should-you-use)
| 111   | [You are a developer for a SaaS company that offers many web services. All web services for the company must meet the following requirements: Use API Management to access the services Use OpenID Connect for authentication Prevent anonymous usage A recent security audit found that several web services can be called without any authentication. Which API Management policy should you implement?](#you-are-a-developer-for-a-saas-company-that-offers-many-web-services-all-web-services-for-the-company-must-meet-the-following-requirements-use-api-management-to-access-the-services-use-openid-connect-for-authentication-prevent-anonymous-usage-a-recent-security-audit-found-that-several-web-services-can-be-called-without-any-authentication-which-api-management-policy-should-you-implement)
| 112   | [You are developing an Azure App Service REST API. The API must be called by an Azure App Service web app. The API must retrieve and update user profile information stored in Microsoft Entra ID. You need to configure the API to make the updates. Which two tools should you use?](#you-are-developing-an-azure-app-service-rest-api-the-api-must-be-called-by-an-azure-app-service-web-app-the-api-must-retrieve-and-update-user-profile-information-stored-in-microsoft-entra-id-you-need-to-configure-the-api-to-make-the-updates-which-two-tools-should-you-use)
| 113   | [You develop a REST API. You implement a user delegation SAS token to communicate with Azure Blob storage. The token is compromised. You need to revoke the token. What are two possible ways to achieve this goal?](#you-develop-a-rest-api-you-implement-a-user-delegation-sas-token-to-communicate-with-azure-blob-storage-the-token-is-compromised-you-need-to-revoke-the-token-what-are-two-possible-ways-to-achieve-this-goal)
| 114   | [You are developing an Azure-hosted application that must use an on-premises hardware security module (HSM) key. The key must be transferred to your existing Azure Key Vault by using the Bring Your Own Key (BYOK) process. You need to securely transfer the key to Azure Key Vault. Which four actions should you perform in sequence?](#you-are-developing-an-azure-hosted-application-that-must-use-an-on-premises-hardware-security-module-hsm-key-the-key-must-be-transferred-to-your-existing-azure-key-vault-by-using-the-bring-your-own-key-byok-process-you-need-to-securely-transfer-the-key-to-azure-key-vault-which-four-actions-should-you-perform-in-sequence)
| 115   | [You develop and deploy an Azure Logic app that calls an Azure Function app. The Azure Function app includes an OpenAPI (Swagger) definition and uses an Azure Blob storage account. All resources are secured by using Microsoft Entra ID. The Azure Logic app must securely access the Azure Blob storage account. Microsoft Entra ID resources must remain if the Azure Logic app is deleted. You need to secure the Azure Logic app. What should you do?](#you-develop-and-deploy-an-azure-logic-app-that-calls-an-azure-function-app-the-azure-function-app-includes-an-openapi-swagger-definition-and-uses-an-azure-blob-storage-account-all-resources-are-secured-by-using-microsoft-entra-id-the-azure-logic-app-must-securely-access-the-azure-blob-storage-account-microsoft-entra-id-resources-must-remain-if-the-azure-logic-app-is-deleted-you-need-to-secure-the-azure-logic-app-what-should-you-do)
| 116   | [You manage several existing Logic Apps. You need to change definitions, add new logic, and optimize these apps on a regular basis. What should you use?](#you-manage-several-existing-logic-apps-you-need-to-change-definitions-add-new-logic-and-optimize-these-apps-on-a-regular-basis-what-should-you-use)
| 117   | [You are developing a solution that will use a multi-partitioned Azure Cosmos DB database. You plan to use the latest Azure Cosmos DB SDK for development. The solution must meet the following requirements: Send insert and update operations to an Azure Blob storage account. Process changes to all partitions immediately. Allow parallelization of change processing. You need to process the Azure Cosmos DB operations. What are two possible ways to achieve this goal?](#you-are-developing-a-solution-that-will-use-a-multi-partitioned-azure-cosmos-db-database-you-plan-to-use-the-latest-azure-cosmos-db-sdk-for-development-the-solution-must-meet-the-following-requirements-send-insert-and-update-operations-to-an-azure-blob-storage-account-process-changes-to-all-partitions-immediately-allow-parallelization-of-change-processing-you-need-to-process-the-azure-cosmos-db-operations-what-are-two-possible-ways-to-achieve-this-goal)
| 118   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 1: The code configures the lock duration for the queue.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-1-the-code-configures-the-lock-duration-for-the-queue)
| 119   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 2: The last message read remains in the queue after the code runs.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-2-the-last-message-read-remains-in-the-queue-after-the-code-runs)
| 120   | [You are developing an application that uses Azure Storage Queues. You have the following code. Question 3: The storage queue remains in the storage account after the code runs.](#you-are-developing-an-application-that-uses-azure-storage-queues-you-have-the-following-code-question-3-the-storage-queue-remains-in-the-storage-account-after-the-code-runs)
| 121   | [You develop software solutions for a mobile delivery service. You are developing a mobile app that users can use to order from a restaurant in their area. The app uses the following workflow: 1. A driver selects the restaurants for which they will deliver orders. 2. Orders are sent to all available drivers in an area. 3. Only orders for the selected restaurants will appear for the driver. 4. The first driver to accept an order removes it from the list of available orders. You need to implement an Azure Service Bus solution. Which three actions should you perform in sequence?](#you-develop-software-solutions-for-a-mobile-delivery-service-you-are-developing-a-mobile-app-that-users-can-use-to-order-from-a-restaurant-in-their-area-the-app-uses-the-following-workflow-1-a-driver-selects-the-restaurants-for-which-they-will-deliver-orders-2-orders-are-sent-to-all-available-drivers-in-an-area-3-only-orders-for-the-selected-restaurants-will-appear-for-the-driver-4-the-first-driver-to-accept-an-order-removes-it-from-the-list-of-available-orders-you-need-to-implement-an-azure-service-bus-solution-which-three-actions-should-you-perform-in-sequence)
| 122   | [You develop a news and blog content app for Windows devices. A notification must arrive on a user's device when there is a new article available for them to view. You need to implement push notifications. How should you complete the code segment?](#you-develop-a-news-and-blog-content-app-for-windows-devices-a-notification-must-arrive-on-a-users-device-when-there-is-a-new-article-available-for-them-to-view-you-need-to-implement-push-notifications-how-should-you-complete-the-code-segment)
| 123   | [You are developing an Azure messaging solution. You need to ensure that the solution meets the following requirements: Provide transactional support. Provide duplicate detection. Store the messages for an unlimited period of time. Which two technologies will meet the requirements?](#you-are-developing-an-azure-messaging-solution-you-need-to-ensure-that-the-solution-meets-the-following-requirements-provide-transactional-support-provide-duplicate-detection-store-the-messages-for-an-unlimited-period-of-time-which-two-technologies-will-meet-the-requirements)
| 124   | [You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and hosted in an Azure App Service instance. You need to configure back-end authentication for the API Management service instance. Which target and gateway credential type should you use?](#you-develop-a-gateway-solution-for-a-public-facing-news-api-the-news-api-back-end-is-implemented-as-a-restful-service-and-hosted-in-an-azure-app-service-instance-you-need-to-configure-back-end-authentication-for-the-api-management-service-instance-which-target-and-gateway-credential-type-should-you-use)
| 125   | [You are creating an app that uses Event Grid to connect with other services. Your app's event data will be sent to a serverless function that checks compliance. This function is maintained by your company. You write a new event subscription at the scope of your resource. The event must be invalidated after a specific period of time. You need to configure Event Grid. What should you do?](#you-are-creating-an-app-that-uses-event-grid-to-connect-with-other-services-your-apps-event-data-will-be-sent-to-a-serverless-function-that-checks-compliance-this-function-is-maintained-by-your-company-you-write-a-new-event-subscription-at-the-scope-of-your-resource-the-event-must-be-invalidated-after-a-specific-period-of-time-you-need-to-configure-event-grid-what-should-you-do)
| 126   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 1: The XML segment belongs in the `<inbound>` section of the policy.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-1-the-xml-segment-belongs-in-the-inbound-section-of-the-policy)
| 127   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 2: If the body size is >256k, an error will occur.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-2-if-the-body-size-is-256k-an-error-will-occur)
| 128   | [You are working for Contoso, Ltd. You define an API Policy object by using the following XML markup. Question 3: If the request is `<http://contoso.com/api/9.2/>`, the policy will retain the higher version.](#you-are-working-for-contoso-ltd-you-define-an-api-policy-object-by-using-the-following-xml-markup-question-3-if-the-request-is-httpcontosocomapi92-the-policy-will-retain-the-higher-version)
| 129   | [You develop a gateway solution for a public facing news API. The news API back end is implemented as a RESTful service and uses an OpenAPI specification. You need to ensure that you can access the news API by using an Azure API Management service instance. Which Azure PowerShell command should you run?](#you-develop-a-gateway-solution-for-a-public-facing-news-api-the-news-api-back-end-is-implemented-as-a-restful-service-and-uses-an-openapi-specification-you-need-to-ensure-that-you-can-access-the-news-api-by-using-an-azure-api-management-service-instance-which-azure-powershell-command-should-you-run)
| 130   | [You are developing an Azure function that connects to an Azure SQL Database instance. The function is triggered by an Azure Storage queue. You receive reports of numerous System.InvalidOperationExceptions with the following message: 'Timeout expired. The timeout period elapsed prior to obtaining a connection from the pool. This may have occurred because all pooled connections were in use and max pool size was reached.' You need to prevent the exception. What should you do?](#you-are-developing-an-azure-function-that-connects-to-an-azure-sql-database-instance-the-function-is-triggered-by-an-azure-storage-queue-you-receive-reports-of-numerous-systeminvalidoperationexceptions-with-the-following-message-timeout-expired-the-timeout-period-elapsed-prior-to-obtaining-a-connection-from-the-pool-this-may-have-occurred-because-all-pooled-connections-were-in-use-and-max-pool-size-was-reached-you-need-to-prevent-the-exception-what-should-you-do)
| 131   | [You are developing a REST web service. Customers will access the service by using an Azure API Management instance. The web service does not correctly handle conflicts. Instead of returning an HTTP status code of 409, the service returns a status code of 500. The body of the status message contains only the word conflict. You need to ensure that conflicts produce the correct response. How should you complete the policy?](#you-are-developing-a-rest-web-service-customers-will-access-the-service-by-using-an-azure-api-management-instance-the-web-service-does-not-correctly-handle-conflicts-instead-of-returning-an-http-status-code-of-409-the-service-returns-a-status-code-of-500-the-body-of-the-status-message-contains-only-the-word-conflict-you-need-to-ensure-that-conflicts-produce-the-correct-response-how-should-you-complete-the-policy)
| 132   | [You are a developer for a Software as a Service (SaaS) company. You develop solutions that provide the ability to send notifications by using Azure Notification Hubs. You need to create sample code that customers can use as a reference for how to send raw notifications to Windows Push Notification Services (WNS) devices. The sample code must not use external packages. How should you complete the code segment?](#you-are-a-developer-for-a-software-as-a-service-saas-company-you-develop-solutions-that-provide-the-ability-to-send-notifications-by-using-azure-notification-hubs-you-need-to-create-sample-code-that-customers-can-use-as-a-reference-for-how-to-send-raw-notifications-to-windows-push-notification-services-wns-devices-the-sample-code-must-not-use-external-packages-how-should-you-complete-the-code-segment)
| 133   | [You develop and deploy an ASP.NET web app to Azure App Service. You use Application Insights telemetry to monitor the app. You must test the app to ensure that the app is available and responsive from various points around the world and at regular intervals. If the app is not responding, you must send an alert to support staff. You need to configure a test for the web app. Which two test types can you use?](#you-develop-and-deploy-an-aspnet-web-app-to-azure-app-service-you-use-application-insights-telemetry-to-monitor-the-app-you-must-test-the-app-to-ensure-that-the-app-is-available-and-responsive-from-various-points-around-the-world-and-at-regular-intervals-if-the-app-is-not-responding-you-must-send-an-alert-to-support-staff-you-need-to-configure-a-test-for-the-web-app-which-two-test-types-can-you-use)
| 134   | [You are developing an Azure solution to collect inventory data from thousands of stores located around the world. Each store location will send the inventory data hourly to an Azure Blob storage account for processing. The solution must meet the following requirements: Begin processing when data is saved to Azure Blob storage. Filter data based on store location information. Trigger an Azure Logic App to process the data for output to Azure Cosmos DB. Enable high availability and geographic distribution. Allow 24-hours for retries. Implement an exponential back off data processing. You need to configure the solution. What should you implement?](#you-are-developing-an-azure-solution-to-collect-inventory-data-from-thousands-of-stores-located-around-the-world-each-store-location-will-send-the-inventory-data-hourly-to-an-azure-blob-storage-account-for-processing-the-solution-must-meet-the-following-requirements-begin-processing-when-data-is-saved-to-azure-blob-storage-filter-data-based-on-store-location-information-trigger-an-azure-logic-app-to-process-the-data-for-output-to-azure-cosmos-db-enable-high-availability-and-geographic-distribution-allow-24-hours-for-retries-implement-an-exponential-back-off-data-processing-you-need-to-configure-the-solution-what-should-you-implement)
| 135   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Enable Application Request Routing (ARR). Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-enable-application-request-routing-arr-does-the-solution-meet-the-goal)
| 136   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure an Azure Database for PostgreSQL. Update the web applications. Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-deploy-and-configure-an-azure-database-for-postgresql-update-the-web-applications-does-the-solution-meet-the-goal)
| 137   | [Determine whether the solution meets the stated goals. You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to save session state information and HTML output. You must use a storage mechanism with the following requirements: Share session state across all ASP.NET web applications. Support controlled, concurrent access to the same session state data for multiple readers and a single writer. Save full HTTP responses for concurrent requests. You need to store the information. Proposed Solution: Deploy and configure Azure Cache for Redis. Update the web applications. Does the solution meet the goal?](#determine-whether-the-solution-meets-the-stated-goals-you-are-developing-and-deploying-several-aspnet-web-applications-to-azure-app-service-you-plan-to-save-session-state-information-and-html-output-you-must-use-a-storage-mechanism-with-the-following-requirements-share-session-state-across-all-aspnet-web-applications-support-controlled-concurrent-access-to-the-same-session-state-data-for-multiple-readers-and-a-single-writer-save-full-http-responses-for-concurrent-requests-you-need-to-store-the-information-proposed-solution-deploy-and-configure-azure-cache-for-redis-update-the-web-applications-does-the-solution-meet-the-goal)
| 138   | [A company is developing a gaming platform. Users can join teams to play online and see leaderboards that include player statistics. The solution includes an entity named `Team`. You plan to implement an Azure Redis Cache instance to improve the efficiency of data operations for entities that rarely change. You need to invalidate the cache when team data is changed. How should you complete the code?](#a-company-is-developing-a-gaming-platform-users-can-join-teams-to-play-online-and-see-leaderboards-that-include-player-statistics-the-solution-includes-an-entity-named-team-you-plan-to-implement-an-azure-redis-cache-instance-to-improve-the-efficiency-of-data-operations-for-entities-that-rarely-change-you-need-to-invalidate-the-cache-when-team-data-is-changed-how-should-you-complete-the-code)
| 139   | [A company has multiple warehouses. Each warehouse contains IoT temperature devices which deliver temperature data to an Azure Service Bus queue. You need to send email alerts to facility supervisors immediately if the temperature at a warehouse goes above or below specified threshold temperatures. Which five actions should you perform in sequence?](#a-company-has-multiple-warehouses-each-warehouse-contains-iot-temperature-devices-which-deliver-temperature-data-to-an-azure-service-bus-queue-you-need-to-send-email-alerts-to-facility-supervisors-immediately-if-the-temperature-at-a-warehouse-goes-above-or-below-specified-threshold-temperatures-which-five-actions-should-you-perform-in-sequence)
| 140   | [You are creating a hazard notification system that has a single signaling server which triggers audio and visual alarms to start and stop. You implement Azure Service Bus to publish alarms. Each alarm controller uses Azure Service Bus to receive alarm signals as part of a transaction. Alarm events must be recorded for audit purposes. Each transaction record must include information about the alarm type that was activated. You need to implement a reply trail auditing solution. Which two actions should you perform?](#you-are-creating-a-hazard-notification-system-that-has-a-single-signaling-server-which-triggers-audio-and-visual-alarms-to-start-and-stop-you-implement-azure-service-bus-to-publish-alarms-each-alarm-controller-uses-azure-service-bus-to-receive-alarm-signals-as-part-of-a-transaction-alarm-events-must-be-recorded-for-audit-purposes-each-transaction-record-must-include-information-about-the-alarm-type-that-was-activated-you-need-to-implement-a-reply-trail-auditing-solution-which-two-actions-should-you-perform)
| 141   | [You are developing applications for a company. You plan to host the applications on Azure App Services. The company has the following requirements: Every five minutes verify that the websites are responsive. Verify that the websites respond within a specified time threshold. Dependent requests such as images and JavaScript files must load properly. Generate alerts if a website is experiencing issues. If a website fails to load, the system must attempt to reload the site three more times. You need to implement this process with the least amount of effort. What should you do?](#you-are-developing-applications-for-a-company-you-plan-to-host-the-applications-on-azure-app-services-the-company-has-the-following-requirements-every-five-minutes-verify-that-the-websites-are-responsive-verify-that-the-websites-respond-within-a-specified-time-threshold-dependent-requests-such-as-images-and-javascript-files-must-load-properly-generate-alerts-if-a-website-is-experiencing-issues-if-a-website-fails-to-load-the-system-must-attempt-to-reload-the-site-three-more-times-you-need-to-implement-this-process-with-the-least-amount-of-effort-what-should-you-do)
| 142   | [You develop and add several functions to an Azure Function app that uses the latest runtime host. The functions contain several REST API endpoints secured by using SSL. The Azure Function app runs in a Consumption plan. You must send an alert when any of the function endpoints are unavailable or responding too slowly. You need to monitor the availability and responsiveness of the functions. What should you do?](#you-develop-and-add-several-functions-to-an-azure-function-app-that-uses-the-latest-runtime-host-the-functions-contain-several-rest-api-endpoints-secured-by-using-ssl-the-azure-function-app-runs-in-a-consumption-plan-you-must-send-an-alert-when-any-of-the-function-endpoints-are-unavailable-or-responding-too-slowly-you-need-to-monitor-the-availability-and-responsiveness-of-the-functions-what-should-you-do)
| 143   | [You are developing an e-commerce solution that uses a microservice architecture. You need to design a communication backplane for communicating transactional messages between various parts of the solution. Messages must be communicated in first-in-first-out (FIFO) order. What should you use?](#you-are-developing-an-e-commerce-solution-that-uses-a-microservice-architecture-you-need-to-design-a-communication-backplane-for-communicating-transactional-messages-between-various-parts-of-the-solution-messages-must-be-communicated-in-first-in-first-out-fifo-order-what-should-you-use)
| 144   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Service Bus Queue from the mobile application. Create an Azure Function App that uses an Azure Service Bus Queue trigger. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-service-bus-queue-from-the-mobile-application-create-an-azure-function-app-that-uses-an-azure-service-bus-queue-trigger-does-the-solution-meet-the-goal)
| 145   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Notification Hub. Register all devices with the hub. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-notification-hub-register-all-devices-with-the-hub-does-the-solution-meet-the-goal)
| 146   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Service Bus. Configure a topic to receive the device data by using a correlation filter. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-service-bus-configure-a-topic-to-receive-the-device-data-by-using-a-correlation-filter-does-the-solution-meet-the-goal)
| 147   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure event filtering to evaluate the device identifier. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-grid-configure-event-filtering-to-evaluate-the-device-identifier-does-the-solution-meet-the-goal)
| 148   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure Function App that uses an Azure Storage Queue trigger. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-storage-queue-from-the-mobile-application-create-an-azure-function-app-that-uses-an-azure-storage-queue-trigger-does-the-solution-meet-the-goal)
| 149   | [You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure VM that is triggered from Azure Storage Queue events. Does the solution meet the goal?](#you-are-developing-an-azure-service-application-that-processes-queue-data-when-it-receives-a-message-from-a-mobile-application-messages-may-not-be-sent-to-the-service-consistently-you-have-the-following-requirements-queue-size-must-not-grow-larger-than-80-gigabytes-gb-use-first-in-first-out-fifo-ordering-of-messages-minimize-azure-costs-you-need-to-implement-the-messaging-solution-solution-use-the-net-api-to-add-a-message-to-an-azure-storage-queue-from-the-mobile-application-create-an-azure-vm-that-is-triggered-from-azure-storage-queue-events-does-the-solution-meet-the-goal)
| 150   | [You are developing a solution that will use Azure messaging services. You need to ensure that the solution uses a publish-subscribe model and eliminates the need for constant polling. What are two possible ways to achieve the goal?](#you-are-developing-a-solution-that-will-use-azure-messaging-services-you-need-to-ensure-that-the-solution-uses-a-publish-subscribe-model-and-eliminates-the-need-for-constant-polling-what-are-two-possible-ways-to-achieve-the-goal)
| 151   | [A company is implementing a publish-subscribe (Pub/Sub) messaging component by using Azure Service Bus. You are developing the first subscription application. In the Azure portal you see that messages are being sent to the subscription for each topic. You create and initialize a subscription client object by supplying the correct details, but the subscription application is still not consuming the messages. You need to ensure that the subscription client processes all messages. Which code segment should you use?](#a-company-is-implementing-a-publish-subscribe-pubsub-messaging-component-by-using-azure-service-bus-you-are-developing-the-first-subscription-application-in-the-azure-portal-you-see-that-messages-are-being-sent-to-the-subscription-for-each-topic-you-create-and-initialize-a-subscription-client-object-by-supplying-the-correct-details-but-the-subscription-application-is-still-not-consuming-the-messages-you-need-to-ensure-that-the-subscription-client-processes-all-messages-which-code-segment-should-you-use)
| 152   | [You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Hub. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?](#you-are-developing-an-azure-solution-to-collect-point-of-sale-pos-device-data-from-2000-stores-located-throughout-the-world-a-single-device-can-produce-2-megabytes-mb-of-data-every-24-hours-each-store-location-has-one-to-five-devices-that-send-data-you-must-store-the-device-data-in-azure-blob-storage-device-data-must-be-correlated-based-on-a-device-identifier-additional-stores-are-expected-to-open-in-the-future-you-need-to-implement-a-solution-to-receive-the-device-data-solution-provision-an-azure-event-hub-configure-the-machine-identifier-as-the-partition-key-and-enable-capture-does-the-solution-meet-the-goal)
| 153   | [A company is developing a solution that allows smart refrigerators to send temperature information to a central location. The solution must receive and store messages until they can be processed. You create an Azure Service Bus instance by providing a name, pricing tier, subscription, resource group, and location. You need to complete the configuration. Which Azure CLI or PowerShell command should you run?](#a-company-is-developing-a-solution-that-allows-smart-refrigerators-to-send-temperature-information-to-a-central-location-the-solution-must-receive-and-store-messages-until-they-can-be-processed-you-create-an-azure-service-bus-instance-by-providing-a-name-pricing-tier-subscription-resource-group-and-location-you-need-to-complete-the-configuration-which-azure-cli-or-powershell-command-should-you-run)
| 154   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Container` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-container-blade-does-the-solution-meet-the-goal)
| 155   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Virtual Machine` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-virtual-machine-blade-does-the-solution-meet-the-goal)
| 156   | [Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Resource Group` blade. Does the solution meet the goal?](#your-company-has-an-azure-subscription-that-includes-a-storage-account-a-resource-group-a-blob-container-and-a-file-share-a-fellow-administrator-named-jon-ross-used-an-azure-resource-manager-template-to-deploy-a-virtual-machine-and-an-azure-storage-account-you-need-to-identify-the-azure-resource-manager-template-the-jon-ross-used-solution-you-access-the-resource-group-blade-does-the-solution-meet-the-goal)
| 157   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then enable the Use for App service option. Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-open-the-azure-application-gateways-http-setting-and-set-the-override-backend-path-option-to-mywebapp1azurewebsitesnet-you-then-enable-the-use-for-app-service-option-does-this-meet-the-goal)
| 158   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You configure `mywebapp1` to run in an Azure App service environment (ASE). Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-configure-mywebapp1-to-run-in-an-azure-app-service-environment-ase-does-this-meet-the-goal)
| 159   | [You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then add an authentication certificate for `mywebapp1.azurewebsites.net`. Does this meet the goal?](#you-are-developing-a-web-app-named-mywebapp1-mywebapp1-uses-the-address-myapp1azurewebsitesnet-you-protect-mywebapp1-by-implementing-an-azure-web-application-firewall-waf-the-traffic-to-mywebapp1-is-routed-through-an-azure-application-gateway-instance-that-is-also-used-by-other-web-apps-you-want-to-secure-all-traffic-to-mywebapp1-by-using-ssl-solution-you-open-the-azure-application-gateways-http-setting-and-set-the-override-backend-path-option-to-mywebapp1azurewebsitesnet-you-then-add-an-authentication-certificate-for-mywebapp1azurewebsitesnet-does-this-meet-the-goal)
| 160   | [Your company has a web app named `WebApp1`. You use the WebJobs SDK to design a triggered App Service background task that automatically invokes a function in the code every time new data is received in a queue. You are preparing to configure the service processes a queue data item. Which of the following is the service you should use?](#your-company-has-a-web-app-named-webapp1-you-use-the-webjobs-sdk-to-design-a-triggered-app-service-background-task-that-automatically-invokes-a-function-in-the-code-every-time-new-data-is-received-in-a-queue-you-are-preparing-to-configure-the-service-processes-a-queue-data-item-which-of-the-following-is-the-service-you-should-use)
| 161   | [Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformFaultDomainCount` property?](#your-company-has-an-azure-subscription-you-need-to-deploy-a-number-of-azure-virtual-machines-to-the-subscription-by-using-azure-resource-manager-arm-templates-the-virtual-machines-will-be-included-in-a-single-availability-set-you-need-to-ensure-that-the-arm-template-allows-for-as-many-virtual-machines-as-possible-to-remain-accessible-in-the-event-of-fabric-failure-or-maintenance-which-of-the-following-is-the-value-that-you-should-configure-for-the-platformfaultdomaincount-property)
| 162   | [You have two Hyper-V hosts named `Host1` and `Host2`. Host1 has an Azure virtual machine named `VM1` that was deployed by using a custom Azure Resource Manager template. You need to move `VM1` to `Host2`. What should you do?](#you-have-two-hyper-v-hosts-named-host1-and-host2-host1-has-an-azure-virtual-machine-named-vm1-that-was-deployed-by-using-a-custom-azure-resource-manager-template-you-need-to-move-vm1-to-host2-what-should-you-do)
| 163   | [Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the Azure CLI on the device and run the `kubectl apply -f myapp.yaml` command. Does this meet the goal?](#your-company-has-an-azure-kubernetes-service-aks-cluster-that-you-manage-from-an-microsoft-entra-id-joined-device-the-cluster-is-located-in-a-resource-group-developers-have-created-an-application-named-myapp-myapp-was-packaged-into-a-container-image-you-need-to-deploy-the-yaml-manifest-file-for-the-application-solution-you-install-the-azure-cli-on-the-device-and-run-the-kubectl-apply--f-myappyaml-command-does-this-meet-the-goal)
| 164   | [Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the docker client on the device and run the `docker run -it microsoft/azure-cli:0.10.17` command. Does this meet the goal?](#your-company-has-an-azure-kubernetes-service-aks-cluster-that-you-manage-from-an-microsoft-entra-id-joined-device-the-cluster-is-located-in-a-resource-group-developers-have-created-an-application-named-myapp-myapp-was-packaged-into-a-container-image-you-need-to-deploy-the-yaml-manifest-file-for-the-application-solution-you-install-the-docker-client-on-the-device-and-run-the-docker-run--it-microsoftazure-cli01017-command-does-this-meet-the-goal)
| 165   | [Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformUpdateDomainCount` property?](#your-company-has-an-azure-subscription-you-need-to-deploy-a-number-of-azure-virtual-machines-to-the-subscription-by-using-azure-resource-manager-arm-templates-the-virtual-machines-will-be-included-in-a-single-availability-set-you-need-to-ensure-that-the-arm-template-allows-for-as-many-virtual-machines-as-possible-to-remain-accessible-in-the-event-of-fabric-failure-or-maintenance-which-of-the-following-is-the-value-that-you-should-configure-for-the-platformupdatedomaincount-property)
| 166   | [You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Triggered WebJob type. Does the solution meet the goal?](#you-are-designing-an-azure-webjob-that-will-run-on-the-same-instances-as-a-web-app-you-want-to-make-use-of-a-suitable-webjob-type-the-webjob-type-should-also-allow-for-the-option-to-restrict-the-webjob-to-a-single-instance-solution-you-configure-the-use-of-the-triggered-webjob-type-does-the-solution-meet-the-goal)
| 167   | [You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Continuous WebJob type. Does the solution meet the goal?](#you-are-designing-an-azure-webjob-that-will-run-on-the-same-instances-as-a-web-app-you-want-to-make-use-of-a-suitable-webjob-type-the-webjob-type-should-also-allow-for-the-option-to-restrict-the-webjob-to-a-single-instance-solution-you-configure-the-use-of-the-continuous-webjob-type-does-the-solution-meet-the-goal)
| 168   | [You company has an on-premises deployment of MongoDB, and an Azure Cosmos DB account that makes use of the MongoDB API. You need to devise a strategy to migrate MongoDB to the Azure Cosmos DB account. You include the [Data Management Gateway] tool in your migration strategy.](#you-company-has-an-on-premises-deployment-of-mongodb-and-an-azure-cosmos-db-account-that-makes-use-of-the-mongodb-api-you-need-to-devise-a-strategy-to-migrate-mongodb-to-the-azure-cosmos-db-account-you-include-the-data-management-gateway-tool-in-your-migration-strategy)
| 169   | [You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Event Grid with a subscriber Azure Function app. Does the solution meet the goal?](#you-are-developing-an-application-that-processes-azure-blob-storage-events-your-application-has-the-following-requirements-process-transaction-logs-asynchronously-for-changes-that-occur-to-the-blobs-and-the-blob-metadata-process-changes-in-the-order-in-which-they-occurred-retain-changes-for-compliance-reasons-solution-you-use-azure-event-grid-with-a-subscriber-azure-function-app-does-the-solution-meet-the-goal)
| 170   | [You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Monitor HTTP Data Collector API. Does the solution meet the goal?](#you-are-developing-an-application-that-processes-azure-blob-storage-events-your-application-has-the-following-requirements-process-transaction-logs-asynchronously-for-changes-that-occur-to-the-blobs-and-the-blob-metadata-process-changes-in-the-order-in-which-they-occurred-retain-changes-for-compliance-reasons-solution-you-use-azure-monitor-http-data-collector-api-does-the-solution-meet-the-goal)
| 171   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the follows transact-SQL statement: `ALTER TABLE [dbo].[Weyland].[Customers] ALTER COLUMN [email_address] ADD MASKED WITH (FUNCTION = 'email()')`. Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-follows-transact-sql-statement-alter-table-dboweylandcustomers-alter-column-email_address-add-masked-with-function--email-does-the-solution-meet-the-goal)
| 172   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'` Powershell cmdlet Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-set-azsqldatabasedatamaskingpolicy--databasename-weyland-powershell-cmdlet-does-the-solution-meet-the-goal)
| 173   | [You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingRule -DatabaseName 'Weyland' -SchemaName 'dbo' -TableName 'Customers' -ColumnName 'email_address' -MaskingFunction 'email'` Powershell cmdlet Does the solution meet the goal?](#you-are-developing-a-mobile-app-that-uses-an-azure-sql-database-named-weyland-the-database-contains-a-table-names-customers-that-has-a-field-named-email_address-you-want-to-implement-dynamic-data-masking-to-hide-the-data-in-the-email_address-field-solution-you-run-the-set-azsqldatabasedatamaskingrule--databasename-weyland--schemaname-dbo--tablename-customers--columnname-email_address--maskingfunction-email-powershell-cmdlet-does-the-solution-meet-the-goal)
| 174   | [You are developing an e-Commerce Web App. You want to use Azure Key Vault to ensure that sign-ins to the e-Commerce Web App are secured by using Azure App Service authentication and Microsoft Entra ID. What should you do on the e-Commerce Web App?](#you-are-developing-an-e-commerce-web-app-you-want-to-use-azure-key-vault-to-ensure-that-sign-ins-to-the-e-commerce-web-app-are-secured-by-using-azure-app-service-authentication-and-microsoft-entra-id-what-should-you-do-on-the-e-commerce-web-app)
| 175   | [You are developing a web app that uses Microsoft Entra ID for authentication. You want to configure the web app to use multifactor authentication. What should you do?](#you-are-developing-a-web-app-that-uses-microsoft-entra-id-for-authentication-you-want-to-configure-the-web-app-to-use-multifactor-authentication-what-should-you-do)
| 176   | [You are creating an Azure key vault using PowerShell. Objects deleted from the key vault must be kept for a set period of 90 days. Which two of the following parameters must be used in conjunction to meet the requirement? (Choose two.)](#you-are-creating-an-azure-key-vault-using-powershell-objects-deleted-from-the-key-vault-must-be-kept-for-a-set-period-of-90-days-which-two-of-the-following-parameters-must-be-used-in-conjunction-to-meet-the-requirement-choose-two)
| 177   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Azure Key Vault. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-azure-key-vault-does-the-solution-meet-the-goal)
| 178   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Identity Protection. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-microsoft-entra-id-identity-protection-does-the-solution-meet-the-goal)
| 179   | [Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Privileged Identity Management. Does the solution meet the goal?](#your-company-has-an-microsoft-entra-id-environment-users-occasionally-connect-to-microsoft-entra-id-via-the-internet-you-need-to-ensure-that-users-who-connect-to-microsoft-entra-id-via-the-internet-using-an-unidentified-ip-address-are-automatically-instructed-to-change-their-passwords-solution-you-configure-the-use-of-microsoft-entra-id-privileged-identity-management-does-the-solution-meet-the-goal)
| 180   | [You manage an Azure SQL database that allows for Microsoft Entra ID authentication. You need to make sure that database developers can connect to the SQL database via Microsoft SQL Server Management Studio (SSMS). You also need to make sure the developers use their on-premises Active Directory account for authentication. Your strategy should allow for authentication prompts to be kept to a minimum. Which of the following should you implement?](#you-manage-an-azure-sql-database-that-allows-for-microsoft-entra-id-authentication-you-need-to-make-sure-that-database-developers-can-connect-to-the-sql-database-via-microsoft-sql-server-management-studio-ssms-you-also-need-to-make-sure-the-developers-use-their-on-premises-active-directory-account-for-authentication-your-strategy-should-allow-for-authentication-prompts-to-be-kept-to-a-minimum-which-of-the-following-should-you-implement)
| 181   | [You are developing an application to transfer data between on-premises file servers and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault and makes use of the Azure Key Vault APIs. You want to configure the application to allow recovery of an accidental deletion of the key vault or key vault objects for 90 days after deletion. What should you do?](#you-are-developing-an-application-to-transfer-data-between-on-premises-file-servers-and-azure-blob-storage-the-application-stores-keys-secrets-and-certificates-in-azure-key-vault-and-makes-use-of-the-azure-key-vault-apis-you-want-to-configure-the-application-to-allow-recovery-of-an-accidental-deletion-of-the-key-vault-or-key-vault-objects-for-90-days-after-deletion-what-should-you-do)
| 182   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of Azure Redis Cache in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-azure-redis-cache-in-your-design-does-the-solution-meet-the-goal)
| 183   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of an Azure Content Delivery Network (CDN) in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-an-azure-content-delivery-network-cdn-in-your-design-does-the-solution-meet-the-goal)
| 184   | [You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of a Storage Area Network (SAN) in your design. Does the solution meet the goal?](#you-are-configuring-a-web-app-that-delivers-streaming-video-to-users-the-application-makes-use-of-continuous-integration-and-deployment-you-need-to-ensure-that-the-application-is-highly-available-and-that-the-users-streaming-experience-is-constant-you-also-want-to-configure-the-application-to-store-data-in-a-geographic-location-that-is-nearest-to-the-user-solution-you-include-the-use-of-a-storage-area-network-san-in-your-design-does-the-solution-meet-the-goal)
| 185   | [You develop a Web App on a tier D1 app service plan. You notice that page load times increase during periods of peak traffic. You want to implement automatic scaling when CPU load is above 80 percent. Your solution must minimize costs. What should you do first?](#you-develop-a-web-app-on-a-tier-d1-app-service-plan-you-notice-that-page-load-times-increase-during-periods-of-peak-traffic-you-want-to-implement-automatic-scaling-when-cpu-load-is-above-80-percent-your-solution-must-minimize-costs-what-should-you-do-first)
| 186   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the Azure resource. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-basic-gateway-credentials-for-the-azure-resource-does-the-solution-meet-the-goal)
| 187   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-client-cert-gateway-credentials-for-the-https-endpoint-does-the-solution-meet-the-goal)
| 188   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-basic-gateway-credentials-for-the-https-endpoint-does-the-solution-meet-the-goal)
| 189   | [You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the Azure resource. Does the solution meet the goal?](#you-are-developing-a-solution-for-a-public-facing-api-the-api-back-end-is-hosted-in-an-azure-app-service-instance-you-have-implemented-a-restful-service-for-the-api-back-end-you-must-configure-back-end-authentication-for-the-api-management-service-instance-solution-you-configure-client-cert-gateway-credentials-for-the-azure-resource-does-the-solution-meet-the-goal)
| 190   | [You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation venues. You want the application to list holiday accommodation venues that fall within a specific price range and are within a specified distance to an airport. What should you do?](#you-are-developing-a-net-core-mvc-application-that-allows-customers-to-research-independent-holiday-accommodation-providers-you-want-to-implement-azure-search-to-allow-the-application-to-search-the-index-by-using-various-criteria-to-locate-documents-related-to-accommodation-venues-you-want-the-application-to-list-holiday-accommodation-venues-that-fall-within-a-specific-price-range-and-are-within-a-specified-distance-to-an-airport-what-should-you-do)
| 191   | [You are a developer at your company. You need to edit the workflows for an existing Logic App. What should you use?](#you-are-a-developer-at-your-company-you-need-to-edit-the-workflows-for-an-existing-logic-app-what-should-you-use)
| 192   | [You are developing an application that applies a set of governance policies for internal and external services, as well as for applications. You develop a stateful ASP.NET Core 2.1 web application named `PolicyApp` and deploy it to an Azure App Service Web App. The `PolicyApp` reacts to events from Azure Event Grid and performs policy actions based on those events. You have the following requirements: Authentication events must be used to monitor users when they sign in and sign out. All authentication events must be processed by `PolicyApp`. Sign outs must be processed as fast as possible. What should you do?](#you-are-developing-an-application-that-applies-a-set-of-governance-policies-for-internal-and-external-services-as-well-as-for-applications-you-develop-a-stateful-aspnet-core-21-web-application-named-policyapp-and-deploy-it-to-an-azure-app-service-web-app-the-policyapp-reacts-to-events-from-azure-event-grid-and-performs-policy-actions-based-on-those-events-you-have-the-following-requirements-authentication-events-must-be-used-to-monitor-users-when-they-sign-in-and-sign-out-all-authentication-events-must-be-processed-by-policyapp-sign-outs-must-be-processed-as-fast-as-possible-what-should-you-do)
| 193   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM09 to ensure that users can review content using ContentAnalysisService. How should you complete the code?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-code-at-line-am09-to-ensure-that-users-can-review-content-using-contentanalysisservice-how-should-you-complete-the-code)
| 194   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM10 of the application manifest to ensure that the requirement for manually reviewing content can be met. How should you complete the code?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-code-at-line-am10-of-the-application-manifest-to-ensure-that-the-requirement-for-manually-reviewing-content-can-be-met-how-should-you-complete-the-code)
| 195   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that network security policies are met. How should you configure network security?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-ensure-that-network-security-policies-are-met-how-should-you-configure-network-security)
| 196   | [You are building a website to access project data related to teams within your organization. The website does not allow anonymous access. Authentication is performed using an Microsoft Entra ID app named internal. The website has the following authentication requirements: Microsoft Entra ID users must be able to login to the website. Personalization of the website must be based on membership in Active Directory groups. You need to configure the application's manifest to meet the authentication requirements. How should you configure the manifest?](#you-are-building-a-website-to-access-project-data-related-to-teams-within-your-organization-the-website-does-not-allow-anonymous-access-authentication-is-performed-using-an-microsoft-entra-id-app-named-internal-the-website-has-the-following-authentication-requirements-microsoft-entra-id-users-must-be-able-to-login-to-the-website-personalization-of-the-website-must-be-based-on-membership-in-active-directory-groups-you-need-to-configure-the-applications-manifest-to-meet-the-authentication-requirements-how-should-you-configure-the-manifest)
| 197   | [You are developing an Azure solution. You need to develop code to access a secret stored in Azure Key Vault. How should you complete the code segment?](#you-are-developing-an-azure-solution-you-need-to-develop-code-to-access-a-secret-stored-in-azure-key-vault-how-should-you-complete-the-code-segment)
| 198   | [You are developing a web application that makes calls to the Microsoft Graph API. You register the application in the Azure portal and upload a valid `X509` certificate. You create an appsettings.json file containing the certificate name, client identifier for the application, and the tenant identifier of the Microsoft Entra ID. You create a method named `ReadCertificate` to return the `X509` certificate by name. You need to implement code that acquires a token by using the certificate. How should you complete the code segment?](#you-are-developing-a-web-application-that-makes-calls-to-the-microsoft-graph-api-you-register-the-application-in-the-azure-portal-and-upload-a-valid-x509-certificate-you-create-an-appsettingsjson-file-containing-the-certificate-name-client-identifier-for-the-application-and-the-tenant-identifier-of-the-microsoft-entra-id-you-create-a-method-named-readcertificate-to-return-the-x509-certificate-by-name-you-need-to-implement-code-that-acquires-a-token-by-using-the-certificate-how-should-you-complete-the-code-segment)
| 199   | [You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server. You need to ensure that dependency tracking works for calls to the third-party database. Which two dependency telemetry properties should you use?](#you-are-developing-an-aspnet-core-web-api-web-service-the-web-service-uses-azure-application-insights-for-all-telemetry-and-dependency-tracking-the-web-service-reads-and-writes-data-to-a-database-other-than-microsoft-sql-server-you-need-to-ensure-that-dependency-tracking-works-for-calls-to-the-third-party-database-which-two-dependency-telemetry-properties-should-you-use)
| 200   | [You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`. All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node. You need to configure Azure CDN caching rules. Which options should you use?](#you-are-developing-an-azure-app-service-hosted-aspnet-core-web-app-to-deliver-video-on-demand-streaming-media-you-enable-an-azure-content-delivery-network-cdn-standard-for-the-web-endpoint-customer-videos-are-downloaded-from-the-web-app-by-using-the-following-example-url-httpwwwcontosocomcontentmp4quality1-all-media-content-must-expire-from-the-cache-after-one-hour-customer-videos-with-varying-quality-must-be-delivered-to-the-closest-regional-point-of-presence-pop-node-you-need-to-configure-azure-cdn-caching-rules-which-options-should-you-use)
| 201   | [You develop a web app that uses tier D1 app service plan by using the Web Apps feature of Microsoft Azure App Service. Spikes in traffic have caused increases in page load times. You need to ensure that the web app automatically scales when CPU load is about 85 percent and minimize costs. Which four actions should you perform in sequence?](#you-develop-a-web-app-that-uses-tier-d1-app-service-plan-by-using-the-web-apps-feature-of-microsoft-azure-app-service-spikes-in-traffic-have-caused-increases-in-page-load-times-you-need-to-ensure-that-the-web-app-automatically-scales-when-cpu-load-is-about-85-percent-and-minimize-costs-which-four-actions-should-you-perform-in-sequence)
| 202   | [A company backs up all manufacturing data to Azure Blob Storage. Admins move blobs from hot storage to archive tier storage every month. You must automatically move blobs to Archive tier after they have not been modified within 180 days. The path for any item that is not archived must be placed in an existing queue. This operation must be performed automatically once a month. You set the value of TierAgeInDays to -180. How should you configure the Logic App?](#a-company-backs-up-all-manufacturing-data-to-azure-blob-storage-admins-move-blobs-from-hot-storage-to-archive-tier-storage-every-month-you-must-automatically-move-blobs-to-archive-tier-after-they-have-not-been-modified-within-180-days-the-path-for-any-item-that-is-not-archived-must-be-placed-in-an-existing-queue-this-operation-must-be-performed-automatically-once-a-month-you-set-the-value-of-tierageindays-to--180-how-should-you-configure-the-logic-app)
| 203   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 1: The minimum throughput for the container is 400 R/Us.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-1-the-minimum-throughput-for-the-container-is-400-rus)
| 204   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 2: The first query statement is an in-partition query.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-2-the-first-query-statement-is-an-in-partition-query)
| 205   | [You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 3: The second query statement is a cross-partition query.](#you-have-an-azure-web-app-that-uses-cosmos-db-as-a-data-store-you-create-a-cosmosdb-container-by-running-the-following-powershell-script-resourcegroupname--testresourcegroup-accountname--testcosmosaccount-databasename--testdatabase-containername--testcontainer-partitionkeypath--employeeid-autoscalemaxthroughput--5000-new-azcosmosdbsqlcontainer----resourcegroupname-resourcegroupname--accountname-accountname--databasename-databasename--name-containername--partitionkeykind-hash--partitionkeypath-partitionkeypath--autoscalemaxthroughput-autoscalemaxthroughput-you-create-the-following-queries-that-target-the-container-select--from-c-where-cemployeeid--12345-select--from-c-where-cuserid--12345-question-3-the-second-query-statement-is-a-cross-partition-query)
| 206   | [Your Microsoft Entra ID tenant has an Azure subscription linked to it. Your developer has created a mobile application that obtains Microsoft Entra ID access tokens using the OAuth 2 implicit grant type. The mobile application must be registered in Microsoft Entra ID. You require [a redirect URI] from the developer for registration purposes.](#your-microsoft-entra-id-tenant-has-an-azure-subscription-linked-to-it-your-developer-has-created-a-mobile-application-that-obtains-microsoft-entra-id-access-tokens-using-the-oauth-2-implicit-grant-type-the-mobile-application-must-be-registered-in-microsoft-entra-id-you-require-a-redirect-uri-from-the-developer-for-registration-purposes)
| 207   | [You develop an ASP.NET Core MVC application. You configure the application to track webpages and custom events. You need to identify trends in application usage. Which Azure Application Insights Usage Analysis features should you use?](#you-develop-an-aspnet-core-mvc-application-you-configure-the-application-to-track-webpages-and-custom-events-you-need-to-identify-trends-in-application-usage-which-azure-application-insights-usage-analysis-features-should-you-use)
| 208   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 1: Block blobs prefixed with container1/salesorders or container2/inventory which have not been modified in over 60 days are moved to cool storage. Blobs that have not been modified in 120 days are moved to the archive tier.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-1-block-blobs-prefixed-with-container1salesorders-or-container2inventory-which-have-not-been-modified-in-over-60-days-are-moved-to-cool-storage-blobs-that-have-not-been-modified-in-120-days-are-moved-to-the-archive-tier)
| 209   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 2: Blobs are moved to cool storage if they have not been accessed for 30 days.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-2-blobs-are-moved-to-cool-storage-if-they-have-not-been-accessed-for-30-days)
| 210   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 3: Blobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-3-blobs-will-automatically-be-tiered-from-cool-back-to-hot-if-accessed-again-after-being-tiered-to-cool)
| 211   | [You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 4: All block blobs older than 730 days will be deleted.](#you-are-developing-an-application-that-uses-a-premium-block-blob-storage-account-you-are-optimizing-costs-by-automating-azure-blob-storage-access-tiers-you-apply-the-following-policy-rules-to-the-storage-account-you-must-determine-the-implications-of-applying-the-rules-to-the-data-line-numbers-are-included-for-reference-only-question-4-all-block-blobs-older-than-730-days-will-be-deleted)
| 212   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to store the user agreements. Where should you store the agreement after it is completed?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-store-the-user-agreements-where-should-you-store-the-agreement-after-it-is-completed)
| 213   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to monitor `ContentUploadService` according to the requirements. Which command should you use?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-monitor-contentuploadservice-according-to-the-requirements-which-command-should-you-use)
| 214   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to investigate the http server log output to resolve the issue with the `ContentUploadService`. Which command should you use first?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-investigate-the-http-server-log-output-to-resolve-the-issue-with-the-contentuploadservice-which-command-should-you-use-first)
| 215   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to implement the bindings for the CheckUserContent function. How should you complete the code segment?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-implement-the-bindings-for-the-checkusercontent-function-how-should-you-complete-the-code-segment)
| 216   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add markup at line AM04 to implement the ContentReview role. How should you complete the markup?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-markup-at-line-am04-to-implement-the-contentreview-role-how-should-you-complete-the-markup)
| 217   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add YAML markup at line CS17 to ensure that the `ContentUploadService` can access Azure Storage access keys. How should you complete the YAML markup?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-add-yaml-markup-at-line-cs17-to-ensure-that-the-contentuploadservice-can-access-azure-storage-access-keys-how-should-you-complete-the-yaml-markup)
| 218   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to deploy the CheckUserContent Azure Function. The solution must meet the security and cost requirements. Which hosting model should you use?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-deploy-the-checkusercontent-azure-function-the-solution-must-meet-the-security-and-cost-requirements-which-hosting-model-should-you-use)
| 219   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that validation testing is triggered per the requirements. How should you complete the code segment?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-ensure-that-validation-testing-is-triggered-per-the-requirements-how-should-you-complete-the-code-segment)
| 220   | [You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to configure the `ContentUploadService` deployment. Which two actions should you perform?](#you-are-a-developer-for-contoso-ltd-the-company-has-a-social-networking-website-that-is-developed-as-a-single-page-application-spa-the-main-web-application-for-the-social-networking-website-loads-user-uploaded-content-from-blob-storage-you-are-developing-a-solution-to-monitor-uploaded-data-for-inappropriate-content-the-following-process-occurs-when-users-upload-content-by-using-the-spa-messages-are-sent-to-contentuploadservice-content-is-processed-by-contentanalysisservice-after-processing-is-complete-the-content-is-posted-to-the-social-network-or-a-rejection-message-is-posted-in-its-place-the-contentanalysisservice-is-deployed-with-azure-container-instances-from-a-private-azure-container-registry-named-contosoimages-the-solution-will-use-eight-cpu-cores-microsoft-entra-id-contoso-ltd-uses-microsoft-entra-id-for-both-internal-and-guest-accounts-requirements-contentanalysisservice---the-companys-data-science-group-built-contentanalysisservice-which-accepts-user-generated-content-as-a-string-and-returns-a-probable-value-for-inappropriate-content-any-values-over-a-specific-threshold-must-be-reviewed-by-an-employee-of-contoso-ltd-you-must-create-an-azure-function-named-checkusercontent-to-perform-the-content-checks-costs-you-must-minimize-costs-for-all-azure-services-manual-review-to-review-content-the-user-must-authenticate-to-the-website-portion-of-the-contentanalysisservice-using-their-microsoft-entra-id-credentials-the-website-is-built-using-react-and-all-pages-and-api-endpoints-require-authentication-in-order-to-review-content-a-user-must-be-part-of-a-contentreviewer-role-all-completed-reviews-must-include-the-reviewers-email-address-for-auditing-purposes-high-availability-all-services-must-run-in-multiple-regions-the-failure-of-any-service-in-a-region-must-not-impact-overall-application-availability-monitoring-an-alert-must-be-raised-if-the-contentuploadservice-uses-more-than-80-percent-of-available-cpu-cores-security-you-have-the-following-security-requirements-any-web-service-accessible-over-the-internet-must-be-protected-from-cross-site-scripting-attacks-all-websites-and-services-must-use-ssl-from-a-valid-root-certificate-authority-azure-storage-access-keys-must-only-be-stored-in-memory-and-must-be-available-only-to-the-service-all-internal-services-must-only-be-accessible-from-internal-virtual-networks-vnets-all-parts-of-the-system-must-support-inbound-and-outbound-traffic-restrictions-all-service-calls-must-be-authenticated-by-using-microsoft-entra-id-user-agreements-when-a-user-submits-content-they-must-agree-to-a-user-agreement-the-agreement-allows-employees-of-contoso-ltd-to-review-content-store-cookies-on-user-devices-and-track-users-ip-addresses-information-regarding-agreements-is-used-by-multiple-divisions-within-contoso-ltd-user-responses-must-not-be-lost-and-must-be-available-to-all-parties-regardless-of-individual-service-uptime-the-volume-of-agreements-is-expected-to-be-in-the-millions-per-hour-validation-testing-when-a-new-version-of-the-contentanalysisservice-is-available-the-previous-seven-days-of-content-must-be-processed-with-the-new-version-to-verify-that-the-new-version-does-not-significantly-deviate-from-the-old-version-issues-users-of-the-contentuploadservice-report-that-they-occasionally-see-http-502-responses-on-specific-pages-code---contentuploadservice---applicationmanifest-you-need-to-configure-the-contentuploadservice-deployment-which-two-actions-should-you-perform)

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Service Bus. Configure a topic to receive the device data by using a correlation filter. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

>  **不满足目标**：
> Service Bus 设计用于企业级消息传递场景，**并不适合处理大规模设备遥测数据**（如 IoT 场景）。吞吐能力有限，难以支撑每天 20GB 数据、上万设备并发的情况.

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Grid. Configure event filtering to evaluate the device identifier. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ❌ **不满足目标**：
>  Azure Event Grid 是事件通知系统，并非为高吞吐设备数据摄取场景设计，无法有效接收、处理并存储来自数千台设备的数据。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure Function App that uses an Azure Storage Queue trigger. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Azure **Storage Queue** 本质上不保证严格的 FIFO 顺序，只是**尽最大可能按插入顺序处理**，但并非严格 FIFO。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure Service application that processes queue data when it receives a message from a mobile application. Messages may not be sent to the service consistently. You have the following requirements: Queue size must not grow larger than 80 gigabytes (GB). Use first-in-first-out (FIFO) ordering of messages. Minimize Azure costs. You need to implement the messaging solution. Solution: Use the .Net API to add a message to an Azure Storage Queue from the mobile application. Create an Azure VM that is triggered from Azure Storage Queue events. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution that will use Azure messaging services. You need to ensure that the solution uses a publish-subscribe model and eliminates the need for constant polling. What are two possible ways to achieve the goal?

- [x] Service Bus.
- [ ] Event Hub.
- [x] Event Grid.
- [ ] Queue.

> **Azure Service Bus** 是一个功能非常强大的消息服务，它既支持传统的 **队列（Queue）** 模式，也支持 **发布-订阅（Publish-Subscribe）** 模式，具体如下：
>
> ------
>
> ### ✅ **1. Azure Service Bus Queue**
>
> - **模型**：点对点（Point-to-Point）
> - **发送者**：将消息发送到队列中。
> - **接收者**：一个接收者从队列中读取并处理消息。
> - **特点**：
>   - FIFO（先进先出）支持
>   - 支持重复检测、事务、死信队列（DLQ）
>   - 类似 Azure Storage Queue，但更强大（例如支持复杂消息类型、事务、消息会话）
>
> ------
>
> ### ✅ **2. Azure Service Bus Topic + Subscription**
>
> - **模型**：发布-订阅（Publish-Subscribe）
>
> - **发送者**：向 Topic 发布消息
>
> - **接收者**：多个 Subscription 可以各自独立接收同一条消息副本
>
> - **特点**：
>
>   - 每个 Subscription 都像一个独立的队列
>
>   - 支持 **过滤器**（Filter）和 **动作（Action）**，可以根据消息属性将消息分发给不同订阅
>
>   - 一条消息可以送达多个订阅者，无需轮询（可绑定 Azure Function 等自动触发处理）
>
>     
>
> **Azure Service Bus更像邮局，Event Grid更像新闻社，但是他们都支持 publish-subscribe model， 以及是事件驱动，无需像Azure Storage Queue那样自己去轮询**

**[⬆ Back to Top](#table-of-contents)**

### A company is implementing a publish-subscribe (Pub/Sub) messaging component by using Azure Service Bus. You are developing the first subscription application. In the Azure portal you see that messages are being sent to the subscription for each topic. You create and initialize a subscription client object by supplying the correct details, but the subscription application is still not consuming the messages. You need to ensure that the subscription client processes all messages. Which code segment should you use?

- [ ] `await subscriptionClient.AddRuleAsync(new RuleDescription(RuleDescription.DefaultRuleName, new TrueFilter()));`.
- [ ] `subscriptionClient = new SubscriptionClient(ServiceBusConnectionString, TopicName, SubscriptionName);`.
- [ ] `await subscriptionClient.CloseAsync();`.
- [x] `subscriptionClient.RegisterMessageHandler(ProcessMessagesAsync, messageHandlerOptions);`.

> ### 注意：
>
> 你提到“subscription client 仍然没有消费消息”，这可能是因为**缺少 StartProcessingAsync** 或 **没有注册 message handler**。
>
> ------
>
> ### 如果你用的是旧的 `Microsoft.Azure.ServiceBus` SDK，则应使用：
>
> ```C#
> SubscriptionClient client = new SubscriptionClient(connectionString, topicName, subscriptionName);
> 
> client.RegisterMessageHandler(
>     async (message, token) =>
>     {
>         string body = Encoding.UTF8.GetString(message.Body);
>         Console.WriteLine($"Received: {body}");
> 
>         await client.CompleteAsync(message.SystemProperties.LockToken);
>     },
>     new MessageHandlerOptions(args =>
>     {
>         Console.WriteLine(args.Exception);
>         return Task.CompletedTask;
>     })
> );
> ```
>
> ### 结论：
>
> 你需要添加或修正的是这一句核心代码：
>
> > ✅ `RegisterMessageHandler(...)`（旧 SDK）
> >  ✅ `processor.ProcessMessageAsync += ...` 并调用 `StartProcessingAsync()`（新 SDK）
>
> 这才是真正**开始消费订阅消息**的关键。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution to collect point-of-sale (POS) device data from 2,000 stores located throughout the world. A single device can produce 2 megabytes (MB) of data every 24 hours. Each store location has one to five devices that send data. You must store the device data in Azure Blob storage. Device data must be correlated based on a device identifier. Additional stores are expected to open in the future. You need to implement a solution to receive the device data. Solution: Provision an Azure Event Hub. Configure the machine identifier as the partition key and enable capture. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> | 需求                      | 是否满足 | 说明                                                         |
> | ------------------------- | -------- | ------------------------------------------------------------ |
> | 高吞吐量写入              | ✅        | Event Hub 专为高吞吐量设计（百万级事件/秒）                  |
> | 可扩展性                  | ✅        | 支持数千个设备/生产者，未来扩展无忧                          |
> | 数据持久化到 Blob Storage | ✅        | 启用 **Event Hub Capture**，可将数据自动写入 Azure Blob Storage 或 Data Lake |
> | 基于设备ID聚合            | ✅        | 设置 **partition key 为 device ID**，这样可以确保同一个设备的事件进入同一个分区，便于按设备聚合和分析 |
> | 多设备多地区支持          | ✅        | 没有地理或设备数量限制                                       |
> | 成本效率                  | ✅        | 相比 Event Grid 或 IoT Hub，Event Hub 更适合**大批量、顺序性要求低**的事件数据 |

**[⬆ Back to Top](#table-of-contents)**

### A company is developing a solution that allows smart refrigerators to send temperature information to a central location. The solution must receive and store messages until they can be processed. You create an Azure Service Bus instance by providing a name, pricing tier, subscription, resource group, and location. You need to complete the configuration. Which Azure CLI or PowerShell command should you run?

- [ ] `az group create --name fridge-rg --location fridge-loc`.
- [ ] `New-AzureRmServiceBusNamespace -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Location fridge-loc`.
- [x] `New-AzureRmServiceBusQueue -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Name fridge-q -EnablePartitioning $False`.
- [ ] `az servicebus namespace create --resource-group fridge-rg --name fridge-rg --location fridge-loc`.

> ### 选项分析：
>
> 1. `az group create --name fridge-rg --location fridge-loc`
>    - 这是创建 **资源组** 的命令，不是配置 Service Bus。
>    - **不正确**，这是基础资源组创建。
> 2. `New-AzureRmServiceBusNamespace -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Location fridge-loc`
>    - 这是 PowerShell 命令，用于**创建 Service Bus 命名空间（Namespace）**。
>    - 这步是必需的，但题目说“已经创建了 Service Bus 实例”，所以可能已经完成。
>    - **不完全符合题目要求**（完成配置），但如果没有命名空间的话必须执行。
> 3. `New-AzureRmServiceBusQueue -ResourceGroupName fridge-rg -NamespaceName fridge-ns -Name fridge-q -EnablePartitioning $False`
>    - 这是 PowerShell 命令，用于**创建 Service Bus 队列**。
>    - 这一步才是“完成配置”的关键：创建用于接收消息的队列。
>    - **正确答案**。
> 4. `az servicebus namespace create --resource-group fridge-rg --name fridge-rg --location fridge-loc`
>    - 这是用 Azure CLI 创建 Service Bus 命名空间的命令。
>    - 注意这里 `--name fridge-rg`，和资源组名相同，实际应是命名空间名称，不一定是资源组名。
>    - 同样这是创建命名空间，跟题意“完成配置”中创建队列相比，不是最终目标。
>    - **不是关键答案**。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Container` blade. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 问题回顾
>
> - 你想**识别 Jon Ross 使用的 Azure Resource Manager (ARM) 模板**，用于部署虚拟机和存储账户。
> - 你的操作是**访问了 Storage Account 里的 Container（容器）面板**。
>
> ------
>
> ### 为什么不满足目标？
>
> - **Container blade（容器面板）只是显示 Blob 存储容器内容**，与 ARM 模板无关。
> - ARM 模板是部署资源的 JSON 文件，通常存储在源码管理、模板库或部署历史中。
> - 通过 Container 面板，无法查看或追踪到哪个 ARM 模板被用来部署资源。
>
> ------
>
> ### 如何正确识别 ARM 模板？
>
> 你可以：
>
> 1. **查看部署历史（Deployments）**
>    - 在 Azure Portal 中，进入对应的 **资源组**，然后点击 **Deployments（部署）**。
>    - 这里会列出所有通过 ARM 模板或其他方式部署的记录，可以看到模板文件或参数。
> 2. **询问 Jon Ross**
>    - 直接联系他获取模板文件或源码仓库地址。
> 3. **查看版本控制系统**
>    - 如果团队使用 Git 或其他版本管理工具，ARM 模板通常会存储在仓库中。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Virtual Machine` blade. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### Your company has an azure subscription that includes a storage account, a resource group, a blob container and a file share. A fellow administrator named `Jon Ross` used an Azure Resource Manager template to deploy a virtual machine and an Azure Storage account. You need to identify the Azure Resource Manager template the Jon Ross used. Solution: You access the `Resource Group` blade. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ### 为什么访问 Resource Group 可以达成目的？
>
> 在 Azure Portal 中，**Resource Group（资源组）blade** 包含以下内容：
>
> - 已部署的所有资源清单（包括虚拟机、存储账户等）
> - 一个名为 **Deployments（部署）** 的子菜单
>   - 在这里你可以：
>     - 查看所有通过 ARM 模板进行的部署记录
>     - 查看每次部署中使用的模板（包括模板文件、参数、输出）
>     - 下载或导出模板文件

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then enable the Use for App service option. Does this meet the goal?

- [x] Yes.
- [ ] No.

> ### ✅ 正确的做法应包括：
>
> - 在 App Gateway 中添加一个 **HTTPS Listener**
> - 上传并绑定一个有效的 **SSL 证书**
> - 配置一个 Rule 使用该 HTTPS Listener，指向 `mywebapp1.azurewebsites.net`
> - 设置 HTTP 设置时启用 **“Use for App Service”**
> - 如果需要，开启 **SSL termination 或 end-to-end SSL**
>
> ------
>
> ### ✅ 补充说明：Override backend path 和 Use for App service 是做什么的？
>
> | 设置                      | 说明                                                         |
> | ------------------------- | ------------------------------------------------------------ |
> | **Override backend path** | 替换 Application Gateway 发送到后端的路径。例如路径重写。    |
> | **Use for App service**   | 启用 Application Gateway 与 Azure App Service 之间的专用集成通道（自动处理主机头、SNI、健康探测等）。 |
>
> 
>
> 它们只是**配置连接 App Service 的选项**，**本身并不启用 HTTPS 或实现加密通信**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You configure `mywebapp1` to run in an Azure App service environment (ASE). Does this meet the goal?

- [ ] Yes.
- [x] No.

> 将 Web App 部署到 **App Service Environment (ASE)** 本身：
>
> - ✅ 提供更高的网络隔离（运行在你自己的虚拟网络中）
> - ✅ 支持高级网络配置
> - ❌ **但它本身并不会启用或强制 HTTPS/SSL 通信**
>
> 你仍然需要：

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app named `mywebapp1`. `Mywebapp1` uses the address myapp1.azurewebsites.net. You protect `mywebapp1` by implementing an Azure Web Application Firewall (WAF). The traffic to `mywebapp1` is routed through an Azure Application Gateway instance that is also used by other web apps. You want to secure all traffic to `mywebapp1` by using SSL. Solution: You open the Azure Application Gateway's HTTP setting and set the Override backend path option to `mywebapp1.azurewebsites.net`. You then add an authentication certificate for `mywebapp1.azurewebsites.net`. Does this meet the goal?

- [ ] Yes.
- [x] No.

> ### ❌ 为什么这个方案**不满足目标**：
>
> 虽然你添加了后端身份验证证书，这有助于：
>
> - 让 Application Gateway 与 App Service（mywebapp1）之间建立**受信任的 HTTPS 通信**
>
> 但这**只是保护了 Application Gateway → Web App 的流量**
>
> > ✅ “后端”是安全的
> >  ❌ “客户端（用户）→ Application Gateway”的那一段**仍然可能是 HTTP**

**[⬆ Back to Top](#table-of-contents)**

### Your company has a web app named `WebApp1`. You use the WebJobs SDK to design a triggered App Service background task that automatically invokes a function in the code every time new data is received in a queue. You are preparing to configure the service processes a queue data item. Which of the following is the service you should use?

- [ ] Logic Apps.
- [x] WebJobs.
- [ ] Flow.
- [ ] Functions.

> | 选项                       | 描述                                                         | 是否适合          |
> | -------------------------- | ------------------------------------------------------------ | ----------------- |
> | **✅ WebJobs**              | Azure App Service 的后台作业服务，**支持使用 WebJobs SDK**，可与队列（如 Azure Storage Queue）绑定，适合处理触发式任务 | ✅ 正确答案        |
> | **Azure Functions**        | 虽然也可以处理队列触发器，而且功能比 WebJobs 更现代化，但题干明确说使用了 “WebJobs SDK” | ❌（不是本题重点） |
> | **Logic Apps**             | 用于低代码自动化流程，适合业务流程编排，不是代码级触发任务的首选 | ❌                 |
> | **Flow（Power Automate）** | 旧称 Flow，面向业务用户的自动化工具，不适合后台服务开发      | ❌                 |

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformFaultDomainCount` property?

- [ ] 10.
- [ ] 30.
- [ ] Min Value.
- [x] Max Value.

> `platformFaultDomainCount` 控制可用性集跨越多少个物理故障域。
>
> 要在出现机架、电源或网络故障时仍保持最多虚拟机可用，你应选择该属性的 **最大可支持值**（通常为 3，部分地区为 2）。
>
> **选择 "Max Value"** 意味着你告诉 Azure：请尽可能地将虚拟机分布在多个故障域中。
>
> ### 🔧 Fault Domain 是什么？
>
> - 通常是 **不同的物理服务器机架（rack）**。
> - 每个 rack 有独立的：
>   - 电源
>   - 网络交换设备
>   - 冷却系统
>
> Azure 会将你的虚拟机**分布在多个 Fault Domain 中**，以确保：
>
> - 即使某个 rack 的硬件、电源或网络故障，
> - 其他 rack 上的 VM 仍然可以继续运行，
> - 从而提高你的应用高可用性。

**[⬆ Back to Top](#table-of-contents)**

### You have two Hyper-V hosts named `Host1` and `Host2`. Host1 has an Azure virtual machine named `VM1` that was deployed by using a custom Azure Resource Manager template. You need to move `VM1` to `Host2`. What should you do?

- [ ] From the `Update management` blade, click Enable.
- [ ] From the `Overview` blade, move `VM1` to a different subscription.
- [x] From the `Redeploy` blade, click Redeploy.
- [ ] From the `Profile` blade, modify the usage location.

> **Hyper-V** 是微软提供的一个虚拟化平台，允许你在一台物理计算机上运行多个虚拟机。每个虚拟机都像是一台独立的计算机，有自己的操作系统、内存、存储、网络等资源。
>
> - `Host1` 和 `Host2` 都是物理服务器，安装了 Windows Server，并启用了 Hyper-V。
> - `VM1` 是运行在 `Host1` 上的一个虚拟机，你可以把它迁移到 `Host2`。
>
> | 选项                                              | 作用                                                         | 是否满足目标 |
> | ------------------------------------------------- | ------------------------------------------------------------ | ------------ |
> | ✅ `Update management` → Enable                    | 这是启用自动更新管理，与 VM 迁移无关。                       | ❌            |
> | ✅ `Overview` → move VM1 to different subscription | 这是在 Azure 订阅之间移动资源，而不是在本地 Hyper-V 主机间迁移。 | ❌            |
> | ✅ `Redeploy` → click Redeploy                     | 在 Azure 中重新部署 VM 到另一个计算节点，但依然在 Azure 云中，不是本地迁移。 | ❌            |
> | ✅ `Profile` → modify usage location               | 用于设置计费相关的地理位置，与 VM 迁移完全无关。             | ❌            |

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the Azure CLI on the device and run the `kubectl apply -f myapp.yaml` command. Does this meet the goal?

- [x] Yes.
- [ ] No.

> ### ✅ 最完整的步骤：
>
> ```shell
> # 1. 登录 Azure
> az login
> 
> # 2. 安装 kubectl（如果还没装）
> az aks install-cli
> 
> # 3. 获取 AKS 集群凭据
> az aks get-credentials --resource-group <your-rg> --name <your-aks-name>
> 
> # 4. 部署 YAML 文件
> kubectl apply -f myapp.yaml
> ```

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure Kubernetes Service (AKS) cluster that you manage from an Microsoft Entra ID-joined device. The cluster is located in a resource group. Developers have created an application named `MyApp`. `MyApp` was packaged into a container image. You need to deploy the YAML manifest file for the application. Solution: You install the docker client on the device and run the `docker run -it microsoft/azure-cli:0.10.17` command. Does this meet the goal?

- [ ] Yes.
- [x] No.

> 你需要将一个已打包的容器镜像（`MyApp`）通过 **YAML manifest 文件** 部署到 AKS 集群中。
>
> 而题目中提供的操作：
>
> ```
> docker run -it microsoft/azure-cli:0.10.17
> ```
>
> 这只是 **在 Docker 容器中运行了一个旧版本的 Azure CLI**，并没有：
>
> - 部署 YAML 文件
> - 获取 AKS 集群凭据（`az aks get-credentials`）
> - 使用 `kubectl` 命令部署资源

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Azure subscription. You need to deploy a number of Azure virtual machines to the subscription by using Azure Resource Manager (ARM) templates. The virtual machines will be included in a single availability set. You need to ensure that the ARM template allows for as many virtual machines as possible to remain accessible in the event of fabric failure or maintenance. Which of the following is the value that you should configure for the `platformUpdateDomainCount` property?

- [ ] 10.
- [x] 20.
- [ ] 30.
- [ ] 40.

> `platformUpdateDomainCount` 是一个用于 **Availability Set** 的属性，用于指定 Azure 在执行维护或升级时使用多少个更新域（Update Domains，UD）。
>
> 默认值是 `5`，最大值通常为 `20`（根据区域和订阅有细微差别）。
>
> 
>
> 一个 **更新域** 是一个**逻辑分组**，Azure 会**一次只更新一个更新域中的虚拟机**。
>
> ------
>
> ### 🔍 举个例子：
>
> 你有一个 Availability Set 中的 6 台虚拟机，设置 `platformUpdateDomainCount: 3`。
>
> Azure 会将它们分成 3 个更新域：
>
> | 更新域编号 | 包含的虚拟机 |
> | ---------- | ------------ |
> | UD0        | VM1, VM4     |
> | UD1        | VM2, VM5     |
> | UD2        | VM3, VM6     |
>
> 当 Azure 进行维护时，比如打补丁重启主机，会这样执行：
>
> 1. 首先只对 **UD0** 的机器做维护；
> 2. 然后等待完成，再对 **UD1** 做维护；
> 3. 最后是 **UD2**。
>
> ✅ 这样就不会一次性把所有 VM 全部重启，能保持服务连续性。

**[⬆ Back to Top](#table-of-contents)**

### You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Triggered WebJob type. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Azure WebJob 是 Azure App Service 中的一种后台任务功能，允许你在 Web 应用（Web App）所属的 App Service 环境中运行后台程序。你可以把它想象成一种“跟网站一起部署和运行的脚本/任务处理器”。
>
> | 类型                       | 描述                                           | 场景                                  |
> | -------------------------- | ---------------------------------------------- | ------------------------------------- |
> | **Continuous（持续运行）** | 应用启动后持续运行，适合监听型任务，如队列监控 | 如监听 Azure Storage Queue 中的新消息 |
> | **Triggered（触发运行）**  | 通过时间计划（cron）或手动调用                 | 如每天晚上运行清理脚本、定期数据导入  |
>
> | 项目     | WebJobs                        | Azure Functions                |
> | -------- | ------------------------------ | ------------------------------ |
> | 部署方式 | 与 Web App 一起部署            | 独立部署（Serverless）         |
> | 托管模式 | App Service Plan               | Consumption 或 Premium Plan    |
> | 成本     | 固定（取决于 App Service）     | 按需计费                       |
> | 推荐场景 | Web App 需要紧密集成的后台任务 | 独立、弹性、事件驱动的任务处理 |
>
> 要在 **Azure Web App** 中设计一个 **WebJob**，并满足以下两个条件：
>
> 1. ✅ 与 Web App **部署在同一实例**（共用资源）
> 2. ✅ 能够 **限制 WebJob 仅在一个实例上运行**
>
> 你应该选择的 **WebJob 类型** 是：
>
> ------
>
> ### ✅ **Continuous WebJob（持续运行型 WebJob）**
>
> **原因：**
>
> - Continuous WebJob 是与 Web App 一起持续运行的后台任务，常用于队列监听或持续执行的逻辑。
> - Azure 支持为 Continuous WebJob **配置“Always On”并限制只在一个实例上运行**。

**[⬆ Back to Top](#table-of-contents)**

### You are designing an Azure WebJob that will run on the same instances as a web app. You want to make use of a suitable WebJob type. The webjob type should also allow for the option to restrict the WebJob to a single instance. Solution: You configure the use of the Continuous WebJob type. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

**[⬆ Back to Top](#table-of-contents)**

### You company has an on-premises deployment of MongoDB, and an Azure Cosmos DB account that makes use of the MongoDB API. You need to devise a strategy to migrate MongoDB to the Azure Cosmos DB account. You include the [Data Management Gateway] tool in your migration strategy.

- [ ] No change required.
- [x] mongorestore.
- [ ] Azure Storage Explorer.
- [ ] `AzCopy`.

> ## ✅ 推荐迁移策略
>
> 可以使用以下方法之一：
>
> ### 方法 1：Azure Data Factory + Self-hosted Integration Runtime
>
> 1. 在本地安装 **Self-hosted Integration Runtime（即 Data Management Gateway）**
> 2. 使用 Azure Data Factory：
>    - 源：本地 MongoDB
>    - 目标：Azure Cosmos DB（MongoDB API）
> 3. 创建数据迁移管道，进行一次性或定期同步迁移。
>
> ### 方法 2：MongoDB 原生工具（适用于一次性迁移）
>
> 使用如下工具：
>
> - `mongodump` + `mongorestore`（通过 Cosmos 提供的连接字符串）
> - `mongoimport` / `mongoexport`
>
> 但这类方法不适合定期同步或处理大型数据量。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Event Grid with a subscriber Azure Function app. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 这个解决方案并**不**能完全满足所有要求。
>
> 以下是详细分析：
>
> - **处理异步事件和元数据更改：** Azure Event Grid 非常适合这个需求。当 Azure Blob 存储中发生更改时，Event Grid 会立即发布事件，你的 Azure Function 应用作为订阅者可以异步地处理这些事件。这部分要求是满足的。
> - **按事件发生的顺序处理更改：** Event Grid **不保证**事件的顺序。虽然它通常会按照顺序发送事件，但在高负载或系统故障的情况下，事件可能会无序到达。因此，仅仅依赖 Event Grid 无法保证按顺序处理。
> - **保留更改以用于合规性：** Event Grid 的核心功能是传递事件，而不是持久化事件以供长期保留。Event Grid 事件在被传递给订阅者后，其生命周期就结束了。如果订阅者无法及时处理事件，Event Grid 会进行重试，但如果重试失败，事件可能会丢失。为了合规性，你需要一个单独的机制来持久化这些事件或处理结果，例如将事件写入一个持久性存储（如 Azure Blob 存储、Azure Cosmos DB）或者使用具有消息持久化能力的服务（如 Azure Service Bus 或 Azure Event Hubs）。仅仅使用 Event Grid 和 Azure Function 无法满足长期保留的要求。
>
> ##  满足该场景的推荐方式：
>
> - 使用 **Azure Event Grid + Azure Function** 来处理事件
> - 使用 **Service Bus Queue (with sessions)** 或 **Event Hubs** 保证事件顺序
> - 使用 **Cosmos DB / Azure Data Lake / Blob Archive Tier** 来做合规性数据持久存储

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that processes Azure Blob storage events. Your application has the following requirements: Process transaction logs asynchronously for changes that occur to the blobs and the blob metadata. Process changes in the order in which they occurred. Retain changes for compliance reasons. Solution: You use Azure Monitor HTTP Data Collector API. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the follows transact-SQL statement: `ALTER TABLE [dbo].[Weyland].[Customers] ALTER COLUMN [email_address] ADD MASKED WITH (FUNCTION = 'email()')`. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> Dynamic Data Masking 是 Azure SQL Database 的一项功能，可以**防止对敏感数据的非授权访问**，通过在查询结果中“掩码”数据来实现，比如邮箱、信用卡等字段。
>
> ```sql
> ALTER TABLE [dbo].[Customers]
> ALTER COLUMN [email_address] 
> ADD MASKED WITH (FUNCTION = 'email()');
> ```
>
> 在 `[dbo].[Customers]` 表中的 `email_address` 列上应用掩码函数 `email()`，使其在查询时自动显示为 `aXXX@XXXX.com` 这种形式（掩盖大部分 email 地址）。 
>
> =>题干中[dbo].[Weyland].[Customers]虽然有小错误，但推测是抄录笔误

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'` Powershell cmdlet Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 你运行的 PowerShell 命令 `Set-AzSqlDatabaseDataMaskingPolicy -DatabaseName 'Weyland'`
>  这个命令只是在数据库层面**启用或禁用动态数据掩码策略**，
>  并**没有配置具体哪个表、哪个字段需要掩码**。
>
> 实现对 `Customers` 表中 `email_address` 字段的动态数据掩码，必须为该**特定列单独添加掩码规则**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a mobile app that uses an Azure SQL Database named `Weyland`. The database contains a table names Customers that has a field named `email_address`. You want to implement dynamic data masking to hide the data in the `email_address` field. Solution: You run the `Set-AzSqlDatabaseDataMaskingRule -DatabaseName 'Weyland' -SchemaName 'dbo' -TableName 'Customers' -ColumnName 'email_address' -MaskingFunction 'email'` Powershell cmdlet Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 关于在 Azure SQL 数据库中实现 **动态数据掩码（Dynamic Data Masking, DDM）**，主要有以下几种常见方式：
>
> ------
>
> ## 1. **使用 T-SQL 语句直接在数据库中配置**
>
> - 通过 `ALTER TABLE` 语句给指定列添加掩码规则：
>
> ```sql
> ALTER TABLE dbo.Customers
> ALTER COLUMN email_address
> ADD MASKED WITH (FUNCTION = 'email()');
> ```
>
> - 适合直接在数据库中操作，也可以放入迁移脚本。
>
> ------
>
> ## 2. **通过 Azure PowerShell 命令配置**
>
> - **启用数据库级别掩码策略**（可选，默认一般已启用）：
>
> ```
> Set-AzSqlDatabaseDataMaskingPolicy -ResourceGroupName "rg" -ServerName "server" -DatabaseName "Weyland" -DataMaskingState Enabled
> ```
>
> - **为具体字段添加掩码规则**：
>
> ```
> New-AzSqlDatabaseDataMaskingRule -ResourceGroupName "rg" -ServerName "server" -DatabaseName "Weyland" `
>   -SchemaName "dbo" -TableName "Customers" -ColumnName "email_address" -MaskingFunction "Email"
> ```
>
> - 或用 `Set-AzSqlDatabaseDataMaskingRule` 修改已存在规则。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an e-Commerce Web App. You want to use Azure Key Vault to ensure that sign-ins to the e-Commerce Web App are secured by using Azure App Service authentication and Microsoft Entra ID. What should you do on the e-Commerce Web App?

- [ ] Run the `az keyvault secret` command.
- [ ] Enable Microsoft Entra ID Connect.
- [x] Enable Managed Service Identity (MSI).
- [ ] Create an Microsoft Entra ID service principal.

> ### 关键点：
>
> - Azure App Service Authentication（也叫 Easy Auth）本身支持集成 Microsoft Entra ID 进行用户认证。
> - 使用 **Azure Key Vault** 的主要目的是安全地管理和存储敏感信息（如客户端机密 `client secret`），避免在应用配置中直接暴露。
> - 你需要将 Key Vault 中存储的机密（比如 Azure AD 应用的客户端机密）与 App Service 的认证配置集成起来。
>
> ------
>
> ### 应该做的步骤：
>
> 1. **在 Azure Key Vault 中存储 Microsoft Entra ID 应用的机密**（Client Secret）。
> 2. **为 Azure App Service 启用托管身份（Managed Identity）**，允许它访问 Key Vault。
> 3. **在 Azure Key Vault 访问策略中授权该托管身份，允许读取机密**。
> 4. **配置 e-Commerce Web App 的身份验证设置**，使其使用托管身份从 Key Vault 获取客户端机密，或通过配置将机密引用为应用设置中的 Key Vault 机密引用。
> 5. **在 Azure App Service 的应用设置中，通过 Key Vault 引用配置敏感信息**
> 6. **启用并配置 Azure App Service Authentication，选择 Microsoft Entra ID 作为身份提供者。**
>
> 如果只回答针对“**在 e-Commerce Web App 上你应该做什么**”，最核心的动作是：
>
> > **启用托管身份（Managed Identity），并在应用设置中通过 Key Vault 机密引用方式来使用 Azure AD 应用的客户端机密。**
>
> =>“Managed Service Identity”（MSI）和“Managed Identity”（MI）其实指的是同一个概念，Microsoft 后来正式将名称统一成了 **Managed Identity**。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web app that uses Microsoft Entra ID for authentication. You want to configure the web app to use multifactor authentication. What should you do?

- [ ] Enable mobile app authentication.
- [ ] In Microsoft Entra ID conditional access, enable the baseline policy.
- [x] In Microsoft Entra ID, create a conditional access policy.
- [ ] Install the Azure Multi-Factor Authentication Server.

> 要为使用 **Microsoft Entra ID（原 Azure AD）进行身份验证** 的 **Web 应用** 配置 **多重身份验证（MFA）**，你应该从 **Entra ID（Azure AD）配置 MFA 策略**，而不是直接在 Web App 中配置。以下是推荐的做法：
>
> ------
>
> ### ✅ **解决方案步骤**
>
> 1. **在 Microsoft Entra ID 中启用 MFA 策略**：
>    - 登录 Microsoft Entra 管理中心。
>    - 进入 `Protection` > `Conditional Access`。
>    - 创建新的 **条件访问策略**，指定：
>      - **分配对象**：要启用 MFA 的用户或组（例如 Web 应用使用者）。
>      - **云应用或操作**：选择你的 Web 应用（或 All cloud apps）。
>      - **授予控制**：选择 **Require multifactor authentication**。
> 2. **确保用户已注册 MFA**：
>    - 用户需要在第一次登录时完成 MFA 注册（手机验证、认证器 App、FIDO2 密钥等方式）。
> 3. （可选）**确保 Web 应用启用了 Microsoft Entra ID 认证**：
>    - 在 Azure Portal 中进入 Web App。
>    - 选择 **Authentication** > 启用身份验证。
>    - 添加身份提供者，选择 **Microsoft Entra ID**，配置客户端 ID 和重定向 URI。
>
> ### ✅ 正确选项（多选题场景中）
>
> -  **Create a Conditional Access policy in Microsoft Entra ID that requires MFA for the app**

**[⬆ Back to Top](#table-of-contents)**

### You are creating an Azure key vault using PowerShell. Objects deleted from the key vault must be kept for a set period of 90 days. Which two of the following parameters must be used in conjunction to meet the requirement? (Choose two.)

- [ ] `EnabledForDeployment`.
- [x] `EnablePurgeProtection`.
- [ ] `EnabledForTemplateDeployment`.
- [x] `EnableSoftDelete`.

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Azure Key Vault. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 要达到这个目的，你应该使用 **Microsoft Entra Conditional Access（条件访问）策略** 搭配 **风险策略（Risk-based policies）** 或 **Identity Protection**。

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Identity Protection. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ### 正确的解决方案：
>
> #### ✔ 使用 **Microsoft Entra ID Identity Protection**
>
> 它可以：
>
> - 识别**未知或可疑 IP 地址**的登录（例如匿名代理、旅行时间不可能等）
> - 判断登录风险等级（Low / Medium / High）
> - 配置策略，在风险较高时：
>   - 要求用户重置密码 ✅
>   - 阻止访问
>   - 强制 MFA

**[⬆ Back to Top](#table-of-contents)**

### Your company has an Microsoft Entra ID environment. Users occasionally connect to Microsoft Entra ID via the Internet. You need to ensure that users who connect to Microsoft Entra ID via the internet using an unidentified IP address, are automatically instructed to change their passwords. Solution: You configure the use of Microsoft Entra ID Privileged Identity Management. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Microsoft Entra ID Privileged Identity Management 的作用是：
>
> - **管理和审核**管理员权限（例如全局管理员、用户管理员等）
> - 提供临时的“按需分配”权限
> - 设置激活审批、多因素身份验证、访问期限等
>
> 👉 PIM 关注的是 **权限角色** 的生命周期管理，不具备：
>
> - 识别风险登录来源（例如未知 IP）
> - 自动触发密码更改操作的能力

**[⬆ Back to Top](#table-of-contents)**

### You manage an Azure SQL database that allows for Microsoft Entra ID authentication. You need to make sure that database developers can connect to the SQL database via Microsoft SQL Server Management Studio (SSMS). You also need to make sure the developers use their on-premises Active Directory account for authentication. Your strategy should allow for authentication prompts to be kept to a minimum. Which of the following should you implement?

- [ ] Microsoft Entra ID token.
- [ ] Azure Multi-Factor authentication.
- [ ] Active Directory integrated authentication.
- [ ] OATH software tokens.

> ###  **正确答案：**
>
> **✔️ Active Directory integrated authentication**
>
> ------
>
> ### 原因：
>
> - **Active Directory integrated authentication** 允许使用本地 Active Directory 登录。
> - 如果开发者的机器加入了域，并与域控制器连接，他们可以使用 **单点登录（SSO）** 连接 Azure SQL，无需重复输入用户名/密码。
> - 它通过 SSMS 使用 `Active Directory - Integrated` 模式，认证流程无缝对接，**认证提示最少**。
> - 前提是已配置好 Microsoft Entra Connect（Azure AD Connect）并启用了适当的身份验证桥接。
>
> ------
>
> ### ❌ 其他选项说明：
>
> | 选项                                  | 是否符合 | 原因                                                         |
> | ------------------------------------- | -------- | ------------------------------------------------------------ |
> | **Microsoft Entra ID token**          | ❌        | SSMS 不支持使用 token 直接连接 Azure SQL，需借助 CLI 工具等中转。 |
> | **Azure Multi-Factor Authentication** | ❌        | 增强安全性但会增加提示频率，与“认证提示最少”目标冲突。       |
> | **OATH software tokens**              | ❌        | 用于 MFA，不适用于主要身份验证，且增加操作步骤。             |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application to transfer data between on-premises file servers and Azure Blob storage. The application stores keys, secrets, and certificates in Azure Key Vault and makes use of the Azure Key Vault APIs. You want to configure the application to allow recovery of an accidental deletion of the key vault or key vault objects for 90 days after deletion. What should you do?

- [ ] Run the `Add-AzKeyVaultKey` cmdlet.
- [x] Run the `az keyvault update --enable-soft-delete true --enable-purge-protection true` CLI.
- [ ] Implement virtual network service endpoints for Azure Key Vault.
- [ ] Run the `az keyvault update --enable-soft-delete false` CLI.

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of Azure Redis Cache in your design. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ###  为什么 Azure Redis Cache **不满足目标**？
>
> Azure Redis Cache 用于：
>
> - 提高应用程序的数据读取速度
> - 缓存数据库查询结果或 session 数据
> - 适合用于频繁访问的“小型数据对象”（如键值对）
>
> 但它**不是用于视频流媒体传输**，也**不具备地理分布式内容分发的能力**，也**无法提升视频播放的流畅度**。

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of an Azure Content Delivery Network (CDN) in your design. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> ###  使用 Azure CDN 的效果：
>
> | 要求                     | Azure CDN 是否满足 | 说明                                                         |
> | ------------------------ | ------------------ | ------------------------------------------------------------ |
> | 高可用性                 | ✅ 是               | CDN 的 POP 节点遍布全球，避免单点故障                        |
> | 流畅播放体验（低延迟）   | ✅ 是               | 靠近用户分发内容，减少网络延迟                               |
> | 靠近用户地理位置存储数据 | ✅ 是               | CDN 自动缓存内容到离用户最近的边缘节点                       |
> | CI/CD                    | ⚠️ 需另外配置       | CDN 本身不提供 CI/CD，需要配合 Azure DevOps、GitHub Actions 等工具实现 |

**[⬆ Back to Top](#table-of-contents)**

### You are configuring a web app that delivers streaming video to users. The application makes use of continuous integration and deployment. You need to ensure that the application is highly available and that the users' streaming experience is constant. You also want to configure the application to store data in a geographic location that is nearest to the user. Solution: You include the use of a Storage Area Network (SAN) in your design. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> **Storage Area Network (SAN)** 是一种高速专用网络，用于连接存储设备和服务器，主要用于企业内部数据存储，提供块级存储访问。
>
> 它适合于数据中心内部的存储需求，比如数据库服务器的磁盘存储。

**[⬆ Back to Top](#table-of-contents)**

### You develop a Web App on a tier D1 app service plan. You notice that page load times increase during periods of peak traffic. You want to implement automatic scaling when CPU load is above 80 percent. Your solution must minimize costs. What should you do first?

- [ ] Enable autoscaling on the Web App.
- [ ] Switch to the Premium App Service tier plan.
- [x] Switch to the Standard App Service tier plan.
- [ ] Switch to the Azure App Services consumption plan.

> App Service tier plan
>
> | 层级                       | 自动扩展能力（含实例上限）        | 部署槽支持         | 备份   | VNet 集成支持                   | 关键特性补充说明                         |
> | -------------------------- | --------------------------------- | ------------------ | ------ | ------------------------------- | ---------------------------------------- |
> | **Free (F1)**              | ❌ 不支持（每天 60 分钟 CPU 限制） | ❌ 不支持           | ❌ 无   | ❌ 无                            | 无法绑定自定义域名，仅用于学习测试       |
> | **Shared (D1)**            | ❌ 不支持（固定资源，低优先）      | ❌ 不支持           | ❌ 无   | ❌ 无                            | 与他人共享资源，功能受限                 |
> | **Basic (B1~B3)**          | ✅ 支持（最多 3 实例）             | ❌ 不支持           | ✅ 支持 | ❌ 无                            | 支持自定义域名与 SSL                     |
> | **Standard (S1~S3)**       | ✅ 支持（最多 10 实例）            | ✅ 支持最多 5 个槽  | ✅ 支持 | ✅ 支持基础集成                  | 适合中等流量应用，性价比高               |
> | **Premium v2 (P1v2~P3v2)** | ✅ 支持（最多 20 实例）            | ✅ 支持最多 20 个槽 | ✅ 支持 | ✅ 强化集成                      | 更高性能、更大内存、SSD 存储             |
> | **Premium v3 (P1v3~P3v3)** | ✅ 支持（最多 30+ 实例）           | ✅ 支持最多 30 个槽 | ✅ 支持 | ✅ 支持 Zone 冗余                | 高性能与企业级功能，推荐生产使用         |
> | **Isolated (I1~I3)**       | ✅ 支持（最多 100 实例）           | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ App Service Environment (ASE) | 网络完全隔离，适合高合规需求             |
> | **Isolated v2**            | ✅ 支持（最多 100 实例，按需扩展） | ✅ 支持最多 100 槽  | ✅ 支持 | ✅ ASEv3，支持私有 IP            | 最强隔离性与性能，适合大型企业或政府项目 |

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the Azure resource. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> 你需要为 Azure API Management (APIM) 配置后端身份验证，以确保 APIM 调用你 Azure App Service 中托管的 API 时，能够通过身份验证。
>
> ### 解析：
>
> - **Basic Gateway Credentials** 指的是在 Azure API Management (APIM) 中为后端服务配置的基本身份验证（用户名和密码）。
> - 如果你的 Azure App Service 托管的 API 后端要求使用 Basic Authentication，这种配置能确保 APIM 调用时携带正确的认证信息，从而完成身份验证。
>
> 
>
> ------
>
> ## 常见方案及步骤：
>
> ### 1. **选择认证类型**
>
> 后端认证常见类型有：
>
> - **基本认证（Basic Authentication）**：用户名+密码    =>**Basic Gateway Credentials** 是 APIM 配置后端 Basic Authentication 的一种具体实现。
> - **客户端证书认证（Client Certificate）**：APIM 用证书与后端建立 TLS 连接
> - **OAuth 2.0 / JWT 令牌认证**：APIM 作为客户端获取访问令牌，调用后端
>
> ------
>
> ### 2. **配置 APIM 后端身份验证**
>
> #### 示例：设置基本认证
>
> 在 APIM 中：
>
> - 进入 API Management 实例 > APIs > 选择对应 API > Settings
> - 找到 **“Backend”** 部分的 **Authentication Settings**
> - 启用 Basic Authentication，填写用户名和密码
>
> ------
>
> #### 示例：使用客户端证书
>
> - 在 APIM 的“安全性”部分上传客户端证书
> - 绑定客户端证书到后端 API 调用配置
> - 后端 API 要配置为接受该客户端证书
>
> ------
>
> ### 3. **在 API 中配置策略（Policy）**
>
> 可在 APIM API 的 Inbound 或 Backend 节点配置策略，比如添加 Authorization header：
>
> ```
> xmlCopyEdit<inbound>
>   <base />
>   <set-header name="Authorization" exists-action="override">
>     <value>Bearer @{your_access_token}</value>
>   </set-header>
> </inbound>
> ```
>
> ------
>
> ## 总结
>
> - **确保后端 API 支持你配置的认证方式**（如Basic、证书或OAuth）
> - **在 APIM 中配置相应的身份验证信息**
> - **通过策略动态注入身份验证令牌或头部**

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> ### 解析：
>
> - **Client cert gateway credentials** 是指在 Azure API Management (APIM) 中配置客户端证书，APIM 在调用后端 HTTPS 服务时，会使用该证书完成双向 TLS（mutual TLS）认证。
> - 适用于后端服务需要通过客户端证书来验证调用方身份的场景。
> - 这样可以确保 APIM 与后端之间的通信安全，且满足后端认证要求。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Basic gateway credentials for the HTTP(s) endpoint. Does the solution meet the goal?

- [ ] Yes.
- [x] No.

> Basic gateway credentials for the HTTP(s) endpoint” 是指 APIM 为调用 HTTPS（支持安全传输）的后端 API 时，配置的 Basic Authentication 凭据。它是建立在 HTTPS 安全传输基础上的身份认证机制
>
> =>这么看来也可以...

**[⬆ Back to Top](#table-of-contents)**

### You are developing a solution for a public facing API. The API back end is hosted in an Azure App Service instance. You have implemented a RESTful service for the API back end. You must configure back-end authentication for the API Management service instance. Solution: You configure Client cert gateway credentials for the Azure resource. Does the solution meet the goal?

- [x] Yes.
- [ ] No.

> 非要挑刺，只能说**“for the Azure resource”** 的措辞不准确...

**[⬆ Back to Top](#table-of-contents)**

### You are developing a .NET Core MVC application that allows customers to research independent holiday accommodation providers. You want to implement Azure Search to allow the application to search the index by using various criteria to locate documents related to accommodation venues. You want the application to list holiday accommodation venues that fall within a specific price range and are within a specified distance to an airport. What should you do?

- [ ] Configure the `SearchMode` property of the `SearchParameters` class.
- [ ] Configure the `QueryType` property of the `SearchParameters` class.
- [ ] Configure the `Facets` property of the `SearchParameters` class.
- [x] Configure the `Filter` property of the `SearchParameters` class.

> ### 选项解析：
>
> **SearchMode**：控制是匹配任何词还是全部词，主要影响全文搜索的匹配行为，不适合范围或距离筛选。
>
> **QueryType**：控制查询的解析方式，支持简单查询（simple）和全文查询（full，支持 Lucene 查询语法，如布尔运算符、字段搜索和通配符），但不影响筛选条件。
>
> **Facets**：用于对结果做分面聚合，比如统计某个字段的值的分布，也不是筛选条件。
>
> **Filter**：用于根据条件筛选文档，比如数值范围、布尔值、地理距离等，是实现价格范围和距离筛选的正确属性。
>
> ------
>
> ### 答案：
>
> -  配置 `SearchParameters` 类的 **`Filter`** 属性。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer at your company. You need to edit the workflows for an existing Logic App. What should you use?

- [ ] The Enterprise Integration Pack (EIP).
- [ ] The Logic App Code View.
- [ ] The API Connections.
- [x] The Logic Apps Designer.

> ### ✅ 解释：
>
> 如果你要**编辑 Logic App 的工作流（workflow）**，以下是两种主要方式：
>
> 1. **Logic Apps Designer**：
>     图形化界面，可以通过拖放操作编辑工作流步骤。最适合大多数开发者和业务人员使用。
>     👉 **这是最常用、推荐的方式。**
> 2. **Logic App Code View**：
>     直接编辑工作流的 JSON 定义（Logic App 是以 ARM JSON 模板形式存在的）。适合高级用户或需要精细控制的情况。
>
> ✅ **Logic App Code View 也可以用来编辑 workflows**，但它不是**最适合大多数开发者**的方式，尤其是在**图形工作流设计**场景中。
>
> ## 🧠 示例说明：
>
> 比如你想编辑这样一个工作流：
>
> - Step 1: HTTP trigger
> - Step 2: Parse JSON
> - Step 3: 条件判断
> - Step 4: 写入到 SharePoint
>
> 在 **Logic App Designer** 中，你只需点击几下、拖动、配置字段，就可以完成。
>  在 **Code View** 中，你需要写出完整的 JSON 表达。
>
> 
>
> ## ✅ **适合使用 Code View 的典型场景**
>
> ### 1. **DevOps / CI/CD 自动化部署**
>
> - **使用代码管理工作流定义（Infrastructure as Code）**
> - 在 CI/CD pipeline 中将 Logic App JSON 文件部署到多个环境（Dev / QA / Prod）
> - 易于版本控制（在 Git 中查看变更差异）
>
> 🛠 推荐工具：
>
> - ARM templates 或 Bicep + Logic App workflow JSON
> - Azure CLI / PowerShell 自动部署
>
> ------
>
> ### 2. **复杂逻辑微调 / 定制语法**
>
> 有些 Logic App Designer 无法完全支持的复杂语法只能手动写 JSON，例如：
>
> - 使用 `@equals(triggerBody()?['status'], 'Success')` 这种复杂表达式
> - 自定义 `splitOn` 语法、循环控制条件、嵌套表达式等

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that applies a set of governance policies for internal and external services, as well as for applications. You develop a stateful ASP.NET Core 2.1 web application named `PolicyApp` and deploy it to an Azure App Service Web App. The `PolicyApp` reacts to events from Azure Event Grid and performs policy actions based on those events. You have the following requirements: Authentication events must be used to monitor users when they sign in and sign out. All authentication events must be processed by `PolicyApp`. Sign outs must be processed as fast as possible. What should you do?

- [ ] Create a new Azure Event Grid subscription for all authentication events. Use the subscription to process sign-out events.
- [ ] Create a separate Azure Event Grid handler for sign-in and sign-out events.
- [ ] Create separate Azure Event Grid topics and subscriptions for sign-in and sign-out events.
- [x] Add a subject prefix to sign-out events. Create an Azure Event Grid subscription. Configure the subscription to use the subjectBeginsWith filter.

> #### ✅ **选项 D：Add a subject prefix to sign-out events. Create an Azure Event Grid subscription. Configure the subscription to use the subjectBeginsWith filter.**
>
> - **优势：**
>   - 你可以把 sign-out 事件打上特定的前缀，例如 `"signout/"`。
>   - 然后使用 `subjectBeginsWith` 过滤器，只让带这个前缀的事件触发这个订阅。
>   - 这样可以为 **sign-out** 单独开辟一个 **高优先级处理通道**，**加速处理登出事件**。
> - **同时可以搭配另一个订阅处理所有事件**，确保 “all events are processed”。
>
> ✅ **这是最符合题意的答案。**

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM09 to ensure that users can review content using ContentAnalysisService. How should you complete the code?

![Question 193 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 193 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 193 part 3](images/question193.jpeg)

- [ ] Box 1: `"oauth2Permissions": ["login"]`. Box 2: `"oauth2AllowImplicitFlow": true`.
- [x] Box 1: `"oauth2AllowIdTokenImplicitFlow": true`. Box 2: `"oauth2AllowImplicitFlow": true`.
- [ ] Box 1: `"allowPublicClient": true`. Box 2: `"knownClientApplications": ["ContentAnalysisService"]`.
- [ ] Box 1: `"oauth2Permissions": ["login"]`. Box 2: `"preAuthorizedApplications": ["SPA"]`.

> 这四组选项中，针对 SPA 和内容审核服务的 Azure AD 应用配置，最合适的是：
>
> - **Box 1:** `"oauth2AllowIdTokenImplicitFlow": true`
> - **Box 2:** `"oauth2AllowImplicitFlow": true`
>
> 理由：
>
> - `oauth2AllowImplicitFlow` 和 `oauth2AllowIdTokenImplicitFlow` 两个配置一起，表示允许使用 OAuth 2.0 的隐式授权流，并且允许 ID Token 通过隐式流返回，这对单页应用（SPA）非常重要，用于客户端进行无缝登录认证。
> - 这是针对 SPA 最常用的设置，能够保证前端认证顺利进行。
>
> 其他选项：
>
> - `"allowPublicClient": true` 和 `"knownClientApplications"` 主要用在公有客户端和其他受信任客户端，但缺少隐式流配置，可能不完整。
> - `"oauth2Permissions": ["login"]` 是定义权限范围，但单独使用无法保证隐式流的支持。
> - `"preAuthorizedApplications"` 是用于预授权其他客户端的，不是最核心配置。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add code at line AM10 of the application manifest to ensure that the requirement for manually reviewing content can be met. How should you complete the code?

![Question 194 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 194 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 194 part 3](images/question194.jpeg)

- [x] Box 1: `sid`. Box 2: `email`.
- [ ] Box 1: `platf`. Box 2: `sid`.
- [ ] Box 1: `tenant_ctry`. Box 2: `upn`.
- [ ] Box 1: `sid`. Box 2: `enfpolids`.

> ### optionalClaims 作用简介
>
> `optionalClaims` 用于 Azure AD 应用注册的 manifest 中，定义应用期望从令牌（ID token 或 Access token）中获取的额外声明（Claims），例如用户的邮箱（email）、安全标识符（sid）、帐户类型（acct）等。
>
> Box 1: `sid`，Box 2: `email`
>
> - `sid`（会话ID）对追踪用户会话有帮助，`email`是必须的，满足审计要求。
> - 这是最合理的组合，既包含了用户身份追踪（sid），又包含邮箱（email）用于审核。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that network security policies are met. How should you configure network security?

![Question 195 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 195 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 195 part 3](images/question195.jpeg)

- [ ] SSL certificate: Self-signed certificate. Proxy type: nginx.
- [ ] SSL certificate: Self-signed certificate. Proxy type: Azure Application Gateway.
- [ ] SSL certificate: Valid root certificate. Proxy type: nginx.
- [x] SSL certificate: Valid root certificate. Proxy type: Azure Application Gateway.

> 基于题目中对安全性的要求：
>
> - **所有网站和服务都必须使用由有效根证书颁发的 SSL 证书**，所以 SSL certificate 应该选择 **Valid root certificate**，而非自签名证书。
> - **网络层面要保护 Web 服务，且题目中提到已用 Azure Web Application Firewall (WAF)**，而 Azure Application Gateway 本身集成了 WAF 功能，是 Azure 上的标准 Web 反向代理服务，适合保护 Web App。

**[⬆ Back to Top](#table-of-contents)**

### You are building a website to access project data related to teams within your organization. The website does not allow anonymous access. Authentication is performed using an Microsoft Entra ID app named internal. The website has the following authentication requirements: Microsoft Entra ID users must be able to login to the website. Personalization of the website must be based on membership in Active Directory groups. You need to configure the application's manifest to meet the authentication requirements. How should you configure the manifest?

![Question 196](images/question196.png)

- [ ] Box 1: "optionalClaims". Box 2: "allowPublicClient".
- [ ] Box 1: "optionalClaims". Box 2: "requiredResourceAccess".
- [ ] Box 1: "groupMembershipClaims". Box 2: "oauth2Permissions".
- [x] Box 1: "groupMembershipClaims". Box 2: "oauth2AllowimplicitFlow".

> ### ✅【解决方案目标】
>
> 通过配置应用的 Manifest（应用程序清单），确保：
>
> - 应用在用户登录后可以**获取用户的组成员信息**；
> - 正确设置必要的权限字段
>
> 你需要修改 Entra 应用的 manifest（清单），重点是下面两个属性：
>
> #### 1. `"groupMembershipClaims"` 属性
>
> 这是 **关键字段**，用于告诉 Entra ID 在发出的 ID 令牌或访问令牌中，是否应包含用户所属的组。
>
> **解释**：设置为 `"SecurityGroup"` 表示包含用户所属于的所有 **安全组** 的 Object ID。
>
> 其他选项：
>
> - `"All"`：包含安全组和Office 365组
> - `null` 或省略：不返回组信息（默认）
>
> #### 2. （可选）设置 `requiredResourceAccess` 权限
>
> 虽然主问题重点在 manifest，但为了能让网站读取用户组信息，还需要：
>
> - 向 Entra 应用授予 Microsoft Graph 的相关权限，如：
>
> ```json
> "requiredResourceAccess": [
>   {
>     "resourceAppId": "00000003-0000-0000-c000-000000000000", // Microsoft Graph 的 appId
>     "resourceAccess": [
>       {
>         "id": "e1fe6dd8-ba31-4d61-89e7-88639da4683d", // User.Read
>         "type": "Scope"
>       },
>       {
>         "id": "5b567255-7703-4780-807c-7be8301ae99b", // GroupMember.Read.All
>         "type": "Role"
>       }
>     ]
>   }
> ]
> ```
>
> 但第二个 Dropdown 后面是 `true`，而 `"requiredResourceAccess"` 无法赋值为 `true`
>
> ###  分析两个可选字段的含义：
>
> 1. `"allowPublicClient": true`
>    - 含义：允许此应用作为**公共客户端**使用（例如：原生客户端、移动应用等）。
>    - 用于场景：桌面或移动 app，通过授权码流交互 Entra ID。
> 2. `"oauth2AllowImplicitFlow": true`
>    - 含义：允许使用 OAuth2 隐式授权流（现在已不推荐，但有些老的 SPA 使用它）。
>    - 用于场景：单页应用（SPA）直接从 URL 中获取令牌，不通过后端。
>
> 题干回顾：网站为组织内访问，不允许匿名访问；
>
> ### ✅ 最终答案：
>
> | 填空项     | 答案                      |
> | ---------- | ------------------------- |
> | Dropdown 1 | `groupMembershipClaims`   |
> | Dropdown 2 | `oauth2AllowImplicitFlow` |

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure solution. You need to develop code to access a secret stored in Azure Key Vault. How should you complete the code segment?

![Question 197](images/question197.png)

- [ ] Box 1: `DefaultAzureCredential`. Box 2: `ClientSecretCredential`.
- [ ] Box 1: `CloudClients`. Box 2: `ClientSecretCredential`.
- [ ] Box 1: `ClientSecretCredential`. Box 2: `SecretClient`.
- [x] Box 1: `SecretClient`. Box 2: `DefaultAzureCredential`.

> ## ✅ C# 示例（.NET Azure SDK）
>
> ```C#
> using Azure.Identity;
> using Azure.Security.KeyVault.Secrets;
> 
> var keyVaultName = "<your-key-vault-name>";
> var kvUri = $"https://{keyVaultName}.vault.azure.net/";
> 
> var client = new SecretClient(new Uri(kvUri), new DefaultAzureCredential());
> 
> // Fill in the blank
> KeyVaultSecret secret = client.GetSecret("<secret-name>");
> Console.WriteLine(secret.Value);
> ```
>
> ## ✅【选项分析】
>
> 题目提供的四个选项：
>
> 1. `DefaultAzureCredential` ✅
>     → 用于身份认证的默认推荐方式，适配开发环境 & Azure 托管环境。
> 2. `ClientSecretCredential` ✅
>     → 另一种身份认证方式，使用客户端ID/密钥，需要更多配置。
> 3. `CloudClients` ❌
>     → 错误项，不是 Azure SDK 的类名。
> 4. `SecretClient` ✅
>     → 连接 Azure Key Vault 的客户端类，用于操作 secrets。

**[⬆ Back to Top](#table-of-contents)**

### You are developing a web application that makes calls to the Microsoft Graph API. You register the application in the Azure portal and upload a valid `X509` certificate. You create an appsettings.json file containing the certificate name, client identifier for the application, and the tenant identifier of the Microsoft Entra ID. You create a method named `ReadCertificate` to return the `X509` certificate by name. You need to implement code that acquires a token by using the certificate. How should you complete the code segment?

![Question 198](images/question198.jpg)

- [ ] Box 1: `ConfidentialClientApplicationBuilder`. Box 2: `app`.
- [x] Box 1: `ConfidentialClientApplicationBuilder`. Box 2: `scopes`.
- [ ] Box 1: `GetAccountAsync()`. Box 2: `scopes`.
- [ ] Box 1: `ConfidentialClientApplication`. Box 2: `config`.

> 我们要完成的代码结构类似这样（C# 伪代码）：
>
> ```C#
> var cert = ReadCertificate("myCertName");
> //创建客户端应用
> var clientApp = ConfidentialClientApplicationBuilder
>     .Create(clientId)
>     .WithCertificate(cert)
>     .WithTenantId(tenantId)
>     .Build();
> // 定义作用域
> string[] scopes = new[] { "https://graph.microsoft.com/.default" };
> // 获取访问令牌
> var result = await clientApp.AcquireTokenForClient(scopes).ExecuteAsync();
> ```
>
> 因为访问令牌是有“权限范围”的，定义 scope 就是告诉授权服务器：我这个令牌要用来访问哪个资源、要干什么事。
>
> ## 🧠 类比理解：
>
> 想象你去政府办事，需要办“驾照”或“护照”：
>
> - 你提交申请（相当于：AcquireToken）
> - 要说明你想要哪种证件（相当于：scope = 驾照 或 护照）
> - 系统就会给你一张对应用途的证件（access token）

**[⬆ Back to Top](#table-of-contents)**

### You are developing an ASP.NET Core Web API web service. The web service uses Azure Application Insights for all telemetry and dependency tracking. The web service reads and writes data to a database other than Microsoft SQL Server. You need to ensure that dependency tracking works for calls to the third-party database. Which two dependency telemetry properties should you use?

- [ ] `Telemetry.Context.Cloud.RoleInstance`.
- [x] `Telemetry.Id`.
- [ ] `Telemetry.Name`.
- [x] `Telemetry.Context.Operation.Id`.
- [ ] `Telemetry.Context.Session.Id`.

> ## 【重点术语：Dependency Telemetry】
>
> Application Insights 会自动或手动收集对外部服务的调用，称为 **DependencyTelemetry**。
>
> 在 **Azure Application Insights** 中对 **第三方（非 SQL Server）数据库** 的依赖项进行跟踪时，为了让依赖项调用和父级请求正确关联，你需要在发送依赖项遥测数据时包含两个关键属性：
>
> ------
>
> **✅ `Telemetry.Id`**
>
> - 唯一标识该依赖项调用的实例。
>- Application Insights 会用它将依赖项遥测与对应的请求遥测关联起来。
> - 是端到端事务诊断所必需的。
>
> **✅ `Telemetry.Context.Operation.Id`**
>
> - 表示整个操作/请求的**关联 ID**（Correlation ID）。
>- 确保所有相关遥测项（请求、依赖项、日志等）被绑定在同一个分布式追踪中。
> 
>------
> 
>**为什么不是其他选项？**
> 
> - **`Telemetry.Context.Cloud.RoleInstance`** → 标识主机实例（机器名、VM、Pod 等），与特定依赖项调用的关联无关。
>- **`Telemetry.Name`** → 用来给依赖项命名（例如 `"GET /customers"`），方便查看，但不是保证依赖跟踪的必要条件。
> - **`Telemetry.Context.Session.Id`** → 用于将遥测按用户会话分组，不是请求/依赖项相关性所必需的。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an Azure App Service hosted ASP.NET Core web app to deliver video-on-demand streaming media. You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint. Customer videos are downloaded from the web app by using the following example URL: `http://www.contoso.com/content.mp4?quality=1`. All media content must expire from the cache after one hour. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node. You need to configure Azure CDN caching rules. Which options should you use?

![Question 200](images/question200.jpeg)

- [x] Caching behavior: Override. Cache expiration duration: 1 hour. Query string caching behavior: Cache every unique URL.
- [ ] Caching behavior: Bypass cache. Cache expiration duration: 1 day. Query string caching behavior: Bypass caching for query strings.
- [ ] Caching behavior: Set if missing. Cache expiration duration: 1 second. Query string caching behavior: Ignore query strings.
- [ ] Caching behavior: Override. Cache expiration duration: 1 hour. Query string caching behavior: Ignore query strings.

> #### ✅ 选项 1（正确）
>
> > - **Caching behavior**: Override
> > - **Cache expiration duration**: 1 hour
> > - **Query string caching behavior**: Cache every unique URL
>
> 📌 **分析：**
>
> - 覆盖缓存设置为 **1小时** ✅
> - **每一个不同的 query string URL 都单独缓存**，例如 `content.mp4?quality=1` 和 `content.mp4?quality=2` 是两个缓存对象 ✅
> - 完全符合题目“缓存1小时 + 区分不同质量视频”的需求 ✅

**[⬆ Back to Top](#table-of-contents)**

### You develop a web app that uses tier D1 app service plan by using the Web Apps feature of Microsoft Azure App Service. Spikes in traffic have caused increases in page load times. You need to ensure that the web app automatically scales when CPU load is about 85 percent and minimize costs. Which four actions should you perform in sequence?

![Question 201](images/question201.jpg)

- [x] Box 1: Configure the web app to the Standard App Service tier. Box 2: Enable autoscaling on the web app. Box 3: Add a Scale rule. Box 4: Configure a Scale condition.
- [ ] Box 1: Enable autoscaling on the web app. Box 2: Add a Scale rule. Box 3:Configure a Scale condition. Box 4:Switch to an Azure App Services consumption plan.
- [ ] Box 1: Configure the web app to the Standard App Service tier. Box 2: Enable autoscaling on the web app. Box 3: Configure a Scale condition. Box 4: SecretClient.
- [ ] Box 1: Switch to an Azure App Services consumption plan. Box 2: Configure the web app to the Premium App Service tier. Box 3: Enable autoscaling on the web app. Box 4: Configure a Scale condition.

> 1. ### 解析如下：
>
>    #### 🔹 Box 1: Configure the web app to the Standard App Service tier
>
>    - 当前是 D1（Shared）层，不支持 Autoscale。
>    - **Standard** 层是支持自动缩放的最低成本层。
>
>    #### 🔹 Box 2: Enable autoscaling on the web app
>
>    - 开启自动缩放功能（AutoScale）。
>
>    #### 🔹 Box 3: Add a Scale rule
>
>    - 设置缩放的**触发条件**，例如：
>      - CPU > 85% → 增加实例
>      - CPU < 50% → 减少实例
>
>    #### 🔹 Box 4: Configure a Scale condition
>
>    - 配置完整的缩放条件组（如：最小实例数、最大实例数、冷却时间等）。

**[⬆ Back to Top](#table-of-contents)**

### A company backs up all manufacturing data to Azure Blob Storage. Admins move blobs from hot storage to archive tier storage every month. You must automatically move blobs to Archive tier after they have not been modified within 180 days. The path for any item that is not archived must be placed in an existing queue. This operation must be performed automatically once a month. You set the value of TierAgeInDays to -180. How should you configure the Logic App?

![Question 202](images/question202.jpeg)

- [ ] Box 1: Put a message on a queue. Box 2: Recurrence. Box 3: Condition. Box 4: When there are messages in a queue. Box 5: List blobs 2.
- [ ] Box 1: Recurrence. Box 2: Condition. Box 3: When there are messages in a queue. Box 4: Tier blob. Box 5: List blobs 2.
- [ ] Box 1: Recurrence. Box 2: Condition. Box 3: Put a message on a queue. Box 4: When there are messages in a queue. Box 5: Tier blob.
- [x] Box 1: Recurrence. Box 2: Condition. Box 3: Put a message on a queue. Box 4: Tier blob. Box 5: List blobs 2.

> 好的，这是一个关于如何使用 Azure Logic Apps 自动化管理 Blob Storage 数据的配置方案。
>
> **任务目标：**
>
> - 每月自动将超过 180 天未修改的 Blob 从热存储（hot storage）移动到归档层（archive tier）。
> - 对于不符合归档条件的 Blob，将其路径信息放入一个名为 `processing` 的现有队列中。
>
> **Logic App 配置步骤：**
>
> 以下是按照正确的顺序和配置，将每个逻辑应用块拖放到画布中的方式：
>
> 
>
> ### 1. **触发器：每月执行一次**
>
> 
>
> - **块：Recurrence (重复)**
> - **作用：** 这是整个工作流的起点。它将确保这个逻辑应用每月自动运行一次。
> - **配置：**
>   - **Interval (间隔)：** 1
>   - **Frequency (频率)：** Month (月)
>
> 
>
> ### 2. **操作：设置归档年龄变量**
>
> 
>
> - **块：Set tier age variable (设置分层年龄变量)**
> - **作用：** 在执行检查之前，计算一个时间戳，这个时间戳代表着“180天前的日期”。这样，后面的步骤就可以用这个时间戳来判断一个 Blob 是否足够旧。
> - **配置：**
>   - **值 (Value)：** `addDays(utcNow(), variables('TierAgeInDays'))`
>   - **解释：** `utcNow()` 获取当前时间，`variables('TierAgeInDays')` 是你预设的 `-180` 天，所以这个表达式会计算出当前日期减去 180 天的日期。
>
> 
>
> ### 3. **操作：列出所有 Blob**
>
> 
>
> - **块：List blobs (列出 Blob)**
> - **作用：** 获取指定存储容器或路径下的所有 Blob 列表。
> - **配置：**
>   - **Folder (文件夹)：** `Path X` (或你实际存储数据的路径)
>
> 
>
> ### 4. **操作：遍历每一个 Blob**
>
> 
>
> - **块：For each (对于每一个)**
> - **作用：** 这是一个循环，它会遍历上一步获取到的所有 Blob，并对每个 Blob 执行后续的检查和操作。
> - **配置：**
>   - **选择一个输出：** `value` (这是来自 `List blobs` 步骤的 Blob 列表)
>
> 
>
> ### 5. **操作：检查修改日期**
>
> 
>
> - **块：Condition (条件)**
> - **作用：** 这是工作流中的一个决策点。它会检查当前循环到的 Blob 的“上次修改时间”是否早于我们之前设置的“180天前的日期”。
> - **配置：**
>   - **左侧：** `ticks(items('For_each')?['LastModified'])`
>   - **比较器：** `is less than` (小于)
>   - **右侧：** `ticks(addDays(utcNow(), variables('TierAgeInDays')))`
>   - **解释：** 这个表达式将 Blob 的上次修改时间转换为一个数字（ticks），然后与 180 天前的日期转换的数字进行比较。如果 Blob 的修改时间戳小于 180 天前的时间戳，那么条件为 `True`。
>
> 
>
> ### 6. **操作：根据条件执行不同的任务**
>
> 
>
> - **块：Tier blob (分层 Blob)**
> - **作用：** 如果上一步的条件为 **`True`**（即 Blob 超过 180 天未修改），则执行此操作。
> - **配置：**
>   - **Blob path (Blob 路径)：** `Path X` (当前循环到的 Blob 的路径)
>   - **Blob tier (Blob 层级)：** `Archive` (归档)
> - **块：Put a message on a queue (将消息放入队列)**
> - **作用：** 如果上一步的条件为 **`False`**（即 Blob 在 180 天内被修改过），则执行此操作。
> - **配置：**
>   - **Queue Name (队列名称)：** `processing`
>   - **Message (消息)：** `Path X` (当前循环到的 Blob 的路径)

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 1: The minimum throughput for the container is 400 R/Us.

- [ ] Yes.
- [x] No.

> ### 🔹**容器创建脚本回顾**
>
> ```shell
> $resourceGroupName = 'testResourceGroup'
> $accountName = 'testCosmosAccount'
> $databaseName = 'testDatabase'
> $containerName = 'testContainer'
> $partitionKeyPath = '/EmployeeId'
> $autoscaleMaxThroughput = 5000
> 
> New-AzCosmosDBSqlContainer `
>   -ResourceGroupName $resourceGroupName `
>   -AccountName $accountName `
>   -DatabaseName $databaseName `
>   -Name $containerName `
>   -PartitionKeyKind Hash `
>   -PartitionKeyPath $partitionKeyPath `
>   -AutoscaleMaxThroughput $autoscaleMaxThroughput
> ```
>
> - 使用了 **Autoscale**，最大吞吐量为 `5000 RU/s`。
> - 使用了 **分区键为 `/EmployeeId`**。
> - 创建的是 **SQL API 的容器（Cosmos DB）**。
>
> ### 🔹**Autoscale 相关重点**
>
> 启用 autoscale 时，Cosmos DB 会根据负载自动调整吞吐量，**其最小吞吐量为 `max throughput` 的 10%**。
>
> > 🚩 所以：
> >  **5000 RU/s × 10% = 500 RU/s**
>
> ⚠️ **不是 400 RU/s**，所以题中说“最小吞吐量为 400 RU/s”这个说法是 **❌错误** 的。

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 2: The first query statement is an in-partition query.

- [ ] Yes.
- [x] No.

> ## ✅ 定义：什么是 In-Partition Query？
>
> **In-partition query（单分区查询）** 的意思是：查询只会命中某一个具体分区，而不会跨多个分区读取数据。
>
> 要做到这一点，必须满足以下条件之一：
>
> 1. 查询的 **过滤条件中包含具体的分区键值**，例如：
>
>    ```sql
>    SELECT * FROM c WHERE c.EmployeeId = '12345'
>    ```
>
>    → 明确告诉 Cosmos DB 要查哪个分区。
>
> 2. 使用 SDK 查询时，**在代码中提供 partition key 的值**。
>
> ## ❌ 为什么题目中的查询 *不是* In-Partition Query？
>
> 你的查询是：
>
> ```
> sql
> 
> 
> CopyEdit
> SELECT * FROM c WHERE c.EmployeeId > '12345'
> ```
>
> ### 分析：
>
> - ✅ 使用了分区键字段（`EmployeeId`），这是一个好的开始。
> - ❌ 但是是 **范围查询**，并没有指定一个具体的 `EmployeeId` 值。
>
> > Cosmos DB 不知道你想查哪一个分区，因为它无法根据 `> '12345'` 判断唯一分区 —— 所以必须 **检查所有分区** 才能返回结果。
>
> 这就会触发所谓的 **跨分区查询（cross-partition query）**。

**[⬆ Back to Top](#table-of-contents)**

### You have an Azure Web app that uses Cosmos DB as a data store. You create a CosmosDB container by running the following PowerShell script: `$resourceGroupName = 'testResourceGroup' $accountName = 'testCosmosAccount' $databaseName = 'testDatabase' $containerName = 'testContainer' $partitionKeyPath = '/EmployeeId' $autoscaleMaxThroughput = 5000 New-AzCosmosDBSqlContainer - -ResourceGroupName $resourceGroupName -AccountName $accountName -DatabaseName $databaseName -Name $containerName -PartitionKeyKind Hash -PartitionKeyPath $partitionKeyPath -AutoscaleMaxThroughput $autoscaleMaxThroughput`. You create the following queries that target the container: `SELECT * FROM c WHERE c.EmployeeId > '12345' SELECT * FROM c WHERE c.UserID = '12345'`. Question 3: The second query statement is a cross-partition query.

- [x] Yes.
- [ ] No.

> ## 🔍 Cosmos DB 查询是否为跨分区（cross-partition）的判断逻辑
>
> 如果查询中 **没有使用容器的分区键字段 `EmployeeId`**，那 Cosmos DB 就无法通过查询直接确定要访问哪一个分区，**必须扫描所有分区** —— 也就是说：
>
> > ✅ **只要查询里没包含分区键字段，就一定是 cross-partition query。**
>
> ------
>
> ## ✅ 分析当前这个查询
>
> 查询：
>
> ```sql
> SELECT * FROM c WHERE c.UserID = '12345'
> ```
>
> - 它使用了 `UserID`，但你的容器是按 `/EmployeeId` 分区的。
> - **没有使用分区键字段 `EmployeeId`**。
> - 因此，**Cosmos DB 无法推断出具体目标分区**，只能执行 **cross-partition 查询**。

**[⬆ Back to Top](#table-of-contents)**

### Your Microsoft Entra ID tenant has an Azure subscription linked to it. Your developer has created a mobile application that obtains Microsoft Entra ID access tokens using the OAuth 2 implicit grant type. The mobile application must be registered in Microsoft Entra ID. You require [a redirect URI] from the developer for registration purposes.

- [x] No change required.
- [ ] a secret.
- [ ] a login hint.
- [ ] a client ID.

> ## 🔄 背景：OAuth 2.0 Implicit Grant Type 是什么？
>
> 这是 OAuth 的一种授权模式，**专门为客户端（如SPA、移动应用）设计**，这些客户端 **无法安全存储机密（client secret）**。
>
> - 这种模式下，客户端**直接从浏览器地址栏**中获得 `access_token`。
> - 适合浏览器运行或运行在不安全环境中的应用程序（如 JS 单页应用、移动 App）。
> - 现在推荐用 Authorization Code + PKCE 代替，但一些老项目仍然使用 implicit flow。
>
> ## 🧭 整体流程图
>
> ```
> [用户打开App] 
>      ↓
> [App 重定向用户到 Entra ID 登录页面]
>      ↓
> [用户登录成功 → Entra ID 重定向回注册的 Redirect URI]
>      ↓
> [重定向 URI 上附带 access_token]
>      ↓
> [App 拿到 access_token，调用受保护API]
> ```
>
> ### ✅ 为什么选 `No change required`
>
> 在使用 implicit grant 时：
>
> - **注册应用时必须提供 redirect URI**
> - 所以要求开发者提供 redirect URI 是 **完全合理且必要的**
> - 因此：**No change required** ✅
>
> ------
>
> ### ❌ 为什么其他选项错：
>
> | 选项           | 是否需要 | 原因                                                         |
> | -------------- | -------- | ------------------------------------------------------------ |
> | `a secret`     | ❌ 不需要 | 移动应用为 public client，不能安全存储 secret                |
> | `a login hint` | ❌ 不需要 | login_hint 是优化登录体验的参数，不用于注册                  |
> | `a client ID`  | ❌ 不需要 | client ID 是你注册应用之后**平台生成**的，不是开发者提前提供的 |

**[⬆ Back to Top](#table-of-contents)**

### You develop an ASP.NET Core MVC application. You configure the application to track webpages and custom events. You need to identify trends in application usage. Which Azure Application Insights Usage Analysis features should you use?

![Question 207](images/question207.png)

- [x] Box 1: Funnels. Box 2: Impact. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Impact. Box 2: Funnels. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Users. Box 2: Impact. Box 3: Retention. Box 4: User Flows.
- [ ] Box 1: Impact. Box 2: Users. Box 3: User Flows. Box 4: Funnels.

> | 需求描述                                           | 功能（Feature）            |
> | -------------------------------------------------- | -------------------------- |
> | 用户访问哪些页面最常与产品购买有关？               | **Funnels（转化漏斗）**    |
> | 产品展示页面的加载时间如何影响用户购买产品的决策？ | **Impact（影响分析）**     |
> | 哪些事件最能影响用户决定继续使用该应用程序？       | **Retention（用户留存）**  |
> | 应用中是否存在用户经常执行重复操作的位置？         | **User Flows（用户路径）** |
>
> ###  功能解释：
>
> - **Funnels（转化漏斗）**：用来分析用户完成某个目标（如购买）前所经过的页面或步骤，有助于找出哪些页面与转化相关。
> - **Impact（影响分析）**：用于分析性能指标（如加载时间）如何影响用户行为，比如是否决定购买。
> - **Retention（用户留存）**：帮助识别哪些行为或事件有助于用户持续使用你的应用。
> - **User Flows（用户路径）**：可视化用户在应用中的点击路径，识别用户常走的路线和重复操作的区域。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 1: Block blobs prefixed with container1/salesorders or container2/inventory which have not been modified in over 60 days are moved to cool storage. Blobs that have not been modified in 120 days are moved to the archive tier.

![Question 208](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> ### ✅ 1. `agingDataRule`：老化数据分层规则
>
> ```json
> {
>   "name": "agingDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   ...
> }
> ```
>
> #### **规则目标：**
>
> - 仅适用于 `"container1/salesorders"` 和 `"container2/inventory"` 目录中的 **blockBlob**
> - 如果 blob 被修改超过 60 天：移至 **Cool** 层（较低频访问）
> - 如果 blob 被修改超过 120 天：移至 **Archive** 层（极少访问）
>
> #### **用途：**
>
> 适用于处理不再频繁访问的销售订单或库存文件，通过自动冷/归档降低存储成本。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 2: Blobs are moved to cool storage if they have not been accessed for 30 days.

![Question 209](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> ### ✅ 2. `lastAccessedDataRule`：访问频率分层规则
>
> ```json
> {
>   "name": "lastAccessedDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   ...
> }
> ```
>
> #### **规则目标：**
>
> - 适用于所有的 **blockBlob**
> - 如果 **30 天未被访问**：移至 Cool 层
> - 如果之后又被访问，支持 **自动从 Cool 层升回 Hot 层**
>
> #### **用途：**
>
> 自动调整 blob 的访问层级（Hot↔Cool）以提高性能与成本效率，适合动态访问的数据。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 3: Blobs will automatically be tiered from cool back to hot if accessed again after being tiered to cool.

![Question 210](images/question208_209_210_211.png)

- [x] Yes.
- [ ] No.

> 你在规则 `lastAccessedDataRule` 中设置了以下策略：
>
> ```
> jsonCopyEdit"baseBlob": {
>   "enableAutoTierToHotFromCool": true,
>   "tierToCool": { "daysAfterLastAccessTimeGreaterThan": 30 }
> }
> ```
>
> - `tierToCool`: 如果 **30 天未访问**，Blob 会被自动转为 **Cool 层**。
> - `enableAutoTierToHotFromCool: true`：表示如果某个 Blob **再次被访问**，它会被自动从 **Cool 层提升回 Hot 层**。
>
> 这个功能用于 **Premium block blob 存储账户**，并且前提是启用了 **“最后访问时间追踪（last access time tracking）”** 功能。

**[⬆ Back to Top](#table-of-contents)**

### You are developing an application that uses a premium block blob storage account. You are optimizing costs by automating Azure Blob Storage access tiers. You apply the following policy rules to the storage account. You must determine the implications of applying the rules to the data. (Line numbers are included for reference only.) Question 4: All block blobs older than 730 days will be deleted.

![Question 211](images/question208_209_210_211.png)

- [ ] Yes.
- [x] No.

> ### 解析：
>
> 来看你的第三条规则 `expirationDataRule`：
>
> ```json
> {
>   "name": "expirationDataRule",
>   "enabled": true,
>   "type": "Lifecycle",
>   "definition": {
>     "filters": {
>       "blobTypes": [ "blockBlob" ]
>     },
>     "actions": {
>       "baseBlob": {
>         "delete": { "daysAfterModificationGreaterThan": 730 }
>       }
>     }
>   }
> }
> ```
>
> #### ✔ 意义如下：
>
> - 这个规则表示：**“当 block blob 的最后修改时间超过 730 天”**，就会被 **自动删除**。
> - 也就是说：
>   - 如果 blob 仍在 730 天内被修改过，则不会删除。
>   - 如果是 appendBlob 或 pageBlob，也不会被处理（因为只针对 blockBlob）。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to store the user agreements. Where should you store the agreement after it is completed?

![Question 212 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 212 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] Azure Storage queue.
- [x] Azure Event Hub.
- [ ] Azure Service Bus topic.
- [ ] Azure Event Grid topic.

> 这四个选项都不适合作为“存储用户协议”的方案。
>
> 存储用户协议用数据库，如Azure Cosmos DB或Azure SQL。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to monitor `ContentUploadService` according to the requirements. Which command should you use?

![Question 213 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 213 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "avg Percentage CPU > 8"`.
- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "avg Percentage CPU > 800"`.
- [x] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "CPU Usage > 800"`.
- [ ] `az monitor metrics alert create Cn alert Cg … - -scopes … - -condition "CPU Usage > 8"`.

> 正确选项是：
>
> -  `az monitor metrics alert create Cn alert Cg … --scopes … --condition "avg Percentage CPU > 8"`
>
> **解析：**
>
> - **指标名称是 `Percentage CPU`**，不是 `CPU Usage`。
> - 命令中的条件表达式一般是类似 `"avg Percentage CPU > 80"`（注意阈值应为 80，题中 8 可能是笔误）。
> - 选项中正确指标名是 `Percentage CPU`，用法是 `avg Percentage CPU > 80`（这里给出的8应是80）。
> - 其他选项要么指标名错，要么阈值不合理（800% 这种值不可能）。
>
> 如果题目中只有给出的选项，可以选择第一个，但应确认阈值是否应该是80。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to investigate the http server log output to resolve the issue with the `ContentUploadService`. Which command should you use first?

![Question 214 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 214 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] `az webapp log`.
- [ ] `az ams live-output`.
- [ ] `az monitor activity-log`.
- [x] `az container attach`.

> 调查 ACI 中容器的日志，排查 HTTP 502 问题，第一步用 `az container logs` 等命令。
>
> 正确答案是：
>
> -  `az container attach`
>
> 原因：
>
> - `az container attach` 可以实时连接到 Azure Container Instance（ACI）运行的容器的控制台输出流，适合用来查看容器的标准输出和错误日志，帮助排查问题，包括 HTTP 502 错误。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to implement the bindings for the CheckUserContent function. How should you complete the code segment?

![Question 215 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 215 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 215 part 3](images/question215.jpeg)

- [ ] Box 1: [CosmosDBTrigger("content", "userContent")]. Box 2: [Table("content", "userContent", "{name}")].
- [ ] Box 1: [CosmosDBTrigger("content", "userContent")]. Box 2: [Queue("userContent")].
- [ ] Box 1: [BlobTrigger("userContent/{name}")]. Box 2: [Blob("userContent/{name}", FileAccess.Write)].
- [x] Box 1: [QueueTrigger("userContent")]. Box 2: [Blob("userContent/{name}", FileAccess.Write)].

> #### Box 1: `[QueueTrigger("userContent")]`
>
> - 当用户上传内容信息后，由 `ContentUploadService` 把元数据（如内容名称、路径、用户 ID）发送到名为 `"userContent"` 的 Azure Storage Queue。
> - 使用 Storage Queue 的优势：**极低成本**，适合处理**大量异步任务**，**支持大规模并发触发** Azure Functions。
>
> #### Box 2: `[Blob("userContent/{name}", FileAccess.Write)]`
>
> - 函数审核内容后，可以将结果写入 blob 存储（如审核状态报告、审查标记、结果文件等）。
> - `{name}` 变量来自触发器中传入的消息体，具有一致性。
> - Blob 输出绑定同样**便宜可靠**，可以存储结构化或非结构化数据（例如 JSON、图像标签结果等）。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add markup at line AM04 to implement the ContentReview role. How should you complete the markup?

![Question 216 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 216 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 216 part 3](images/question216.jpeg)

- [ ] Box 1: allowedAccountTypes. Box 2: User. Box 3: value.
- [ ] Box 1: role. Box 2: User. Box 3: value.
- [x] Box 1: allowedMemberTypes. Box 2: User. Box 3: value.
- [ ] Box 1: allowedMemberTypes. Box 2: value. Box 3: User.

> 要在 `ApplicationManifest` 中实现 `ContentReview` 角色（即：将用户加入名为 `ContentReviewer` 的 Microsoft Entra ID 角色），你需要在 AM04 添加标记，使该 SPA 应用能够识别和授权该角色的成员。
>
> ```json
> "appRoles": [
>   {
>     "allowedMemberTypes": [
>       "User"
>     ],
>     "description": "Allows the user to review flagged content",
>     "displayName": "ContentReviewer",
>     "id": "GUID",  // 使用实际的 GUID
>     "isEnabled": true,
>     "value": "ContentReviewer"
>   }
> ]
> ```
>
> ### 中文解释：
>
> 这是在 Azure AD 应用注册的 **manifest** 中添加 **应用角色 (App Roles)** 的格式：
>
> | 字段                 | 说明                                                         |
> | -------------------- | ------------------------------------------------------------ |
> | `allowedMemberTypes` | 表示哪些类型的主体可以分配此角色，常见值是 `"User"`。        |
> | `description`        | 角色的描述，用于 Azure 门户中的提示信息。                    |
> | `displayName`        | 角色的显示名称。                                             |
> | `id`                 | 每个角色必须有唯一的 GUID。你可以用工具（如 `uuidgen`）生成一个。 |
> | `isEnabled`          | 是否启用此角色。必须为 `true`。                              |
> | `value`              | 角色的程序使用值（用于 `roles` claim 中）。                  |
>
> 
>
> ### 使用建议：
>
> 1. **添加后保存 manifest** 并重新加载应用注册页面。
> 2. 在 Enterprise Applications 里将用户分配到 `ContentReviewer` 角色。
> 3. 用户登录时，会从 token 中获取 `roles` claim，其中会包含 `ContentReviewer`。
>
> 
>
> 这个 **`ApplicationManifest`（应用清单 / manifest）** 是 Azure 中**应用注册（App registration）**的一部分，主要存在于 Microsoft Entra ID（原 Azure AD）中，用于描述和配置你的应用的身份验证和授权行为。
>
> ### ✅ **它存在在哪里？**
>
> 它存在于：
>  **Azure Portal > Microsoft Entra ID > App registrations > 你的应用 > Manifest**
>
> 或通过 Azure CLI / Microsoft Graph API 访问。
>
> ### 🧾 **这个 Manifest 是给谁用的？**
>
> | 使用者             | 说明                                                         |
> | ------------------ | ------------------------------------------------------------ |
> | **Azure 系统本身** | 解析此 manifest 来配置应用的权限、角色、安全性行为等。       |
> | **管理员/开发者**  | 你（开发者/管理员）通过编辑这个 JSON 文件定义应用角色（如 `ContentReviewer`）、API 权限、重定向 URI 等。 |
> | **前端/后端应用**  | 当用户登录后，其 JWT token 中会包含你定义的角色（如 `roles: ["ContentReviewer"]`），供你的应用做授权检查。 |

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to add YAML markup at line CS17 to ensure that the `ContentUploadService` can access Azure Storage access keys. How should you complete the YAML markup?

![Question 217 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 217 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 217 part 3](images/question217.jpeg)

- [ ] Box 1: volumes. Box 2: volumeMounts. Box 3: secret.
- [x] Box 1: volumeMounts. Box 2: volumes. Box 3: secret.
- [ ] Box 1: envVar. Box 2: secretValues. Box 3: environmentVariables.
- [ ] Box 1: secret. Box 2: environmentVariables. Box 3: secretValues.

> - ### ✅ 完整示例：挂载 Secret 到容器 `/mnt/secrets` 路径
>
>   ```yaml
>   apiVersion: v1
>   kind: Pod
>   metadata:
>     name: secret-volume-pod
>   spec:
>     containers:
>     - name: myapp
>       image: nginx
>       volumeMounts:
>       - mountPath: /mnt/secrets
>         name: accesskey   # Box 2: volumeMounts
>     volumes:
>     - name: accesskey       # Box 1: volumes
>       secret:
>         secretName: my-secret   # 这个名字必须和下面 Secret 定义的 metadata.name 一致
>               
>   ---
>               
>   apiVersion: v1
>   kind: Secret
>   metadata:
>     name: my-secret
>   type: Opaque
>   data:
>     key: TXkgZmljY3Qgc2VjcmV0IEZPTwo=   # Box 3: secret（base64 编码的 secret 值）
>   ```

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to deploy the CheckUserContent Azure Function. The solution must meet the security and cost requirements. Which hosting model should you use?

![Question 218 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 218 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [ ] Premium plan.
- [x] App Service plan.
- [ ] Consumption plan.

> Consumption Plan不支持 VNet 集成, 无法连接 ContentAnalysisService，违反“**所有内部服务必须只能通过 VNet 访问**”这一关键安全要求
>
> 题干内容看不出已有 App Service plan 可复用,  并且App Service plan 虽然部分 SKU 可以 VNet 集成，但缺点是 **不支持自动扩展 Function 实例数量**，需要你手动设定 instance 数量。

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to ensure that validation testing is triggered per the requirements. How should you complete the code segment?

![Question 219 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 219 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)
![Question 219 part 3](images/question219.jpeg)

- [x] Box 1: ImagePushed. Box 2: repository. Box 3: topic.
- [ ] Box 1: ImageDeployed. Box 2: service. Box 3: imageCollection.
- [ ] Box 1: RepositoryUpdated. Box 2: service. Box 3: imageCollection.
- [ ] Box 1: RepositoryItem. Box 2: aci. Box 3: topic.

> 结合题干里说的 **当 ContentAnalysisService 有新版本时触发**，
> 这个版本其实是从 **Azure Container Registry (contosoimages)** 部署的容器镜像。
> 
>在 Azure Container Registry 的事件类型里：
> 
>- **ImagePushed** → 表示有新的镜像版本被 push 到 registry（意味着新版本可用，符合题干触发条件）
> - **ImageDeployed** → 表示镜像被部署，但并不是镜像新版本发布的最佳触发点
>- **RepositoryUpdated** → 泛指仓库有更新，不够精确
> - **RepositoryItem** → 不是有效事件类型
> 
>------
> 
> **第二个空**：
>  事件的 `target` 对象表示触发事件的目标资源字段名，在 ACR 事件模式中，`target.repository` 才是镜像所在的仓库名（这里要等于 `contentanalysisservice`）。
> 
> ------
>
> **第三个空**：
> 要检查事件来源是否来自 `contosoimages`，在事件结构中来源会在 `topic` 字段（topic 是事件源的资源 ID，包含注册表名称）。
> 
>------
> 
> 所以填空应该是：
>
> ```
>var event = getEvent();
> if (event.eventType === ImagePushed
>  && event.data.target.repository === 'contentanalysisservice'
>   && event.topic.contains('contosoimages'))
>  {
>     startValidationTesting();
>   }
>```
> 
>✅ **答案**：
> 
>1. **ImagePushed**
> 2. **repository**
>3. **topic**

**[⬆ Back to Top](#table-of-contents)**

### You are a developer for Contoso, Ltd. The company has a social networking website that is developed as a Single Page Application (SPA). The main web application for the social networking website loads user uploaded content from blob storage. You are developing a solution to monitor uploaded data for inappropriate content. The following process occurs when users upload content by using the SPA: Messages are sent to `ContentUploadService`. Content is processed by ContentAnalysisService. After processing is complete, the content is posted to the social network or a rejection message is posted in its place. The `ContentAnalysisService` is deployed with Azure Container Instances from a private Azure Container Registry named `contosoimages`. The solution will use eight CPU cores. Microsoft Entra ID: Contoso, Ltd. uses Microsoft Entra ID for both internal and guest accounts. Requirements: `ContentAnalysisService` - The company's data science group built `ContentAnalysisService` which accepts user generated content as a string and returns a probable value for inappropriate content. Any values over a specific threshold must be reviewed by an employee of Contoso, Ltd. You must create an Azure Function named `CheckUserContent` to perform the content checks. Costs: You must minimize costs for all Azure services. Manual review: To review content, the user must authenticate to the website portion of the `ContentAnalysisService` using their Microsoft Entra ID credentials. The website is built using React and all pages and API endpoints require authentication. In order to review content a user must be part of a ContentReviewer role. All completed reviews must include the reviewer's email address for auditing purposes. High availability: All services must run in multiple regions. The failure of any service in a region must not impact overall application availability. Monitoring: An alert must be raised if the `ContentUploadService` uses more than 80 percent of available CPU cores. Security: You have the following security requirements: Any web service accessible over the Internet must be protected from cross site scripting attacks. All websites and services must use SSL from a valid root certificate authority. Azure Storage access keys must only be stored in memory and must be available only to the service. All Internal services must only be accessible from internal Virtual Networks (VNets). All parts of the system must support inbound and outbound traffic restrictions. All service calls must be authenticated by using Microsoft Entra ID. User agreements: When a user submits content, they must agree to a user agreement. The agreement allows employees of Contoso, Ltd. to review content, store cookies on user devices, and track user's IP addresses. Information regarding agreements is used by multiple divisions within Contoso, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime. The volume of agreements is expected to be in the millions per hour. Validation testing: When a new version of the `ContentAnalysisService` is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version. Issues: Users of the `ContentUploadService` report that they occasionally see HTTP `502` responses on specific pages. Code - `ContentUploadService` - `ApplicationManifest`. You need to configure the `ContentUploadService` deployment. Which two actions should you perform?

![Question 220 part 1](images/question193_194_195_212_213_214_215_216_217_218_219_220_1.jpeg)
![Question 220 part 2](images/question193_194_195_212_213_214_215_216_217_218_219_220_2.jpeg)

- [x] Add the following markup to line CS23: `type: Private`.
- [ ] Add the following markup to line CS24: `osType: Windows`.
- [x] Add the following markup to line CS24: `osType: Linux`.
- [ ] Add the following markup to line CS23: `type: Public`.

> | 选项                | 分析                                                         |
> | ------------------- | ------------------------------------------------------------ |
> | ❌ `type: Public`    | **错误**，因为题干要求服务应为**内部服务**，只能通过内部虚拟网络访问。Public 会暴露给互联网，不安全。 |
> | ✅ `type: Private`   | **正确**，符合“只能从内部虚拟网络访问”的要求。               |
> | ❌ `osType: Windows` | **错误**，题干没有任何地方提到使用 Windows 容器，反而因为使用了 Azure Container Instances（通常为 Linux 镜像），应该是 Linux。 |
> | ✅ `osType: Linux`   | **正确**，考虑到 `ContentAnalysisService` 是数据科学团队构建的分析服务，且部署于 Azure Container Instances 上，**通常使用 Linux 容器镜像**，成本也更低。 |

**[⬆ Back to Top](#table-of-contents)**
